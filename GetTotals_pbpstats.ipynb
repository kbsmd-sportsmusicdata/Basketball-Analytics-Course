{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHBWQxjhQiiZ8NKsrXy/nx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kbsmd-sportsmusicdata/Basketball-Analytics-Course/blob/main/GetTotals_pbpstats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nP8GI9BcEM",
        "outputId": "04a5a154-913e-4e8f-b665-d0dc2fc8849f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved raw JSON snapshot: /content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/raw_json_data/pbpstats_totals_wnba_player_20251225_194555Z.json\n",
            "Saved raw JSON latest:   /content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/raw_json_data/pbpstats_totals_wnba_player_latest.json\n",
            "multi_row_table_data rows: 257\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import requests\n",
        "\n",
        "def fetch_pbpstats_totals_wnba(\n",
        "    seasons: str = \"2023,2024,2025\",\n",
        "    season_type: str = \"Regular Season\",\n",
        "    data_type: str = \"Player\",\n",
        "    timeout: int = 60\n",
        ") -> dict:\n",
        "    url = \"https://api.pbpstats.com/get-totals/wnba\"\n",
        "    params = {\n",
        "        \"Season\": seasons,\n",
        "        \"SeasonType\": season_type,\n",
        "        \"Type\": data_type\n",
        "    }\n",
        "    r = requests.get(url, params=params, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def save_raw_json(payload: dict, output_dir: str | Path) -> tuple[Path, Path]:\n",
        "    \"\"\"\n",
        "    Saves:\n",
        "      1) timestamped file (immutable snapshot)\n",
        "      2) latest.json (overwritten each run)\n",
        "    Returns (snapshot_path, latest_path)\n",
        "    \"\"\"\n",
        "    output_dir = Path(output_dir).expanduser().resolve()\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
        "    snapshot_path = output_dir / f\"pbpstats_totals_wnba_player_{ts}.json\"\n",
        "    latest_path = output_dir / \"pbpstats_totals_wnba_player_latest.json\"\n",
        "\n",
        "    # write snapshot\n",
        "    snapshot_path.write_text(\n",
        "        json.dumps(payload, ensure_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "    # write latest\n",
        "    latest_path.write_text(\n",
        "        json.dumps(payload, ensure_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "    return snapshot_path, latest_path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    payload = fetch_pbpstats_totals_wnba(\n",
        "        seasons=\"2023,2024,2025\",\n",
        "        season_type=\"Regular Season\",\n",
        "        data_type=\"Player\"\n",
        "    )\n",
        "\n",
        "    # ✅ Option A: if you run this *from within the repo*, use a relative path:\n",
        "    # repo_relative_dir = Path(\"scripts/wnba_scripts/pbpstats/raw_json_data\")\n",
        "\n",
        "    # ✅ Option B: hard-point to your local repo clone (edit this once):\n",
        "    repo_relative_dir = Path(\"/content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/raw_json_data\")\n",
        "\n",
        "    snap, latest = save_raw_json(payload, repo_relative_dir)\n",
        "\n",
        "    # Access the table data if you want it after saving:\n",
        "    player_stats = payload.get(\"multi_row_table_data\", [])\n",
        "    print(f\"Saved raw JSON snapshot: {snap}\")\n",
        "    print(f\"Saved raw JSON latest:   {latest}\")\n",
        "    print(f\"multi_row_table_data rows: {len(player_stats)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "RAW_JSON_PATH = Path(\"/content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/raw_json_data/pbpstats_totals_wnba_player_latest.json\")\n",
        "OUT_DIR = Path(\"/content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/processed\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "payload = json.loads(RAW_JSON_PATH.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "# Core table\n",
        "rows = payload.get(\"multi_row_table_data\", [])\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"✅ df shape:\", df.shape)\n",
        "print(\"✅ first 25 columns:\", df.columns[:25].tolist())\n",
        "display(df.head(10))\n",
        "\n",
        "# Save for inspection\n",
        "out_csv = OUT_DIR / \"pbpstats_totals_player_raw_from_json.csv\"\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(\"✅ wrote:\", out_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "gsXgQrfSQ1Lq",
        "outputId": "da91d469-2219-4c16-a745-d44e82ec5fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ df shape: (257, 249)\n",
            "✅ first 25 columns: ['EntityId', 'TeamId', 'Name', 'ShortName', 'RowId', 'TeamAbbreviation', 'SecondsPlayed', 'GamesPlayed', 'Minutes', 'PlusMinus', 'OffPoss', 'DefPoss', 'PenaltyOffPoss', 'PenaltyDefPoss', 'SecondChanceOffPoss', 'TotalPoss', 'AtRimFGM', 'AtRimFGA', 'SecondChanceAtRimFGM', 'SecondChanceAtRimFGA', 'PenaltyAtRimFGM', 'PenaltyAtRimFGA', 'ShortMidRangeFGM', 'ShortMidRangeFGA', 'LongMidRangeFGM']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  EntityId      TeamId              Name         ShortName    RowId  \\\n",
              "0  1628276  1611661320       Kelsey Plum       Kelsey Plum  1628276   \n",
              "1  1628277  1611661330      Allisha Gray      Allisha Gray  1628277   \n",
              "2  1628909  1611661325   Kelsey Mitchell   Kelsey Mitchell  1628909   \n",
              "3   203826  1611661317     Alyssa Thomas     Alyssa Thomas   203826   \n",
              "4  1629481  1611661321  Arike Ogunbowale  Arike Ogunbowale  1629481   \n",
              "5   204319  1611661319       Jewell Loyd       Jewell Loyd   204319   \n",
              "6  1641648  1611661325     Aliyah Boston     Aliyah Boston  1641648   \n",
              "7  1629498  1611661319      Jackie Young      Jackie Young  1629498   \n",
              "8  1628932  1611661319       A'ja Wilson       A'ja Wilson  1628932   \n",
              "9   204324  1611661320     Dearica Hamby     Dearica Hamby   204324   \n",
              "\n",
              "  TeamAbbreviation  SecondsPlayed  GamesPlayed  Minutes  PlusMinus  ...  \\\n",
              "0              LAS       241920.0          119   4032.0      687.0  ...   \n",
              "1              ATL       239667.0          120   3994.0      207.0  ...   \n",
              "2              IND       238787.0          124   3980.0      -12.0  ...   \n",
              "3              PHX       236590.9          119   3943.0      610.0  ...   \n",
              "4              DAL       233447.0          107   3891.0     -219.0  ...   \n",
              "5              LVA       229481.9          119   3825.0      161.0  ...   \n",
              "6              IND       228116.0          124   3802.0      101.0  ...   \n",
              "7              LVA       225993.0          120   3767.0      891.0  ...   \n",
              "8              LVA       225519.0          117   3759.0      961.0  ...   \n",
              "9              LAS       220821.4          124   3680.0     -296.0  ...   \n",
              "\n",
              "   BlockedLongMidRange  Defensive 3 Seconds Violations  Period2Fouls3Minutes  \\\n",
              "0                  NaN                             NaN                   NaN   \n",
              "1                  5.0                             1.0                   7.0   \n",
              "2                  3.0                             1.0                   NaN   \n",
              "3                  4.0                             2.0                  11.0   \n",
              "4                  5.0                             NaN                   5.0   \n",
              "5                  1.0                             1.0                   1.0   \n",
              "6                  2.0                             5.0                   5.0   \n",
              "7                  1.0                             NaN                   5.0   \n",
              "8                 11.0                             1.0                   NaN   \n",
              "9                  1.0                             4.0                   1.0   \n",
              "\n",
              "   Clear Path Fouls  3SecondViolations  Period3Fouls5Minutes  \\\n",
              "0               NaN                NaN                   NaN   \n",
              "1               NaN                NaN                   NaN   \n",
              "2               1.0                NaN                   NaN   \n",
              "3               NaN                2.0                   NaN   \n",
              "4               1.0                NaN                   1.0   \n",
              "5               NaN                1.0                   NaN   \n",
              "6               NaN                5.0                   NaN   \n",
              "7               NaN                1.0                   NaN   \n",
              "8               1.0                5.0                   NaN   \n",
              "9               NaN                4.0                   NaN   \n",
              "\n",
              "   OffensiveGoaltends  Period1Fouls3Minutes  DefensiveGoaltends  \\\n",
              "0                 NaN                   NaN                 NaN   \n",
              "1                 NaN                   NaN                 NaN   \n",
              "2                 NaN                   NaN                 NaN   \n",
              "3                 NaN                   NaN                 NaN   \n",
              "4                 NaN                   NaN                 NaN   \n",
              "5                 NaN                   NaN                 NaN   \n",
              "6                 NaN                   NaN                 NaN   \n",
              "7                 NaN                   NaN                 NaN   \n",
              "8                 NaN                   NaN                 NaN   \n",
              "9                 NaN                   NaN                 NaN   \n",
              "\n",
              "   Period2Fouls4Minutes  \n",
              "0                   NaN  \n",
              "1                   NaN  \n",
              "2                   NaN  \n",
              "3                   NaN  \n",
              "4                   NaN  \n",
              "5                   NaN  \n",
              "6                   NaN  \n",
              "7                   NaN  \n",
              "8                   NaN  \n",
              "9                   NaN  \n",
              "\n",
              "[10 rows x 249 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce0e8b20-ac1b-46a2-bda6-a411d9209cd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EntityId</th>\n",
              "      <th>TeamId</th>\n",
              "      <th>Name</th>\n",
              "      <th>ShortName</th>\n",
              "      <th>RowId</th>\n",
              "      <th>TeamAbbreviation</th>\n",
              "      <th>SecondsPlayed</th>\n",
              "      <th>GamesPlayed</th>\n",
              "      <th>Minutes</th>\n",
              "      <th>PlusMinus</th>\n",
              "      <th>...</th>\n",
              "      <th>BlockedLongMidRange</th>\n",
              "      <th>Defensive 3 Seconds Violations</th>\n",
              "      <th>Period2Fouls3Minutes</th>\n",
              "      <th>Clear Path Fouls</th>\n",
              "      <th>3SecondViolations</th>\n",
              "      <th>Period3Fouls5Minutes</th>\n",
              "      <th>OffensiveGoaltends</th>\n",
              "      <th>Period1Fouls3Minutes</th>\n",
              "      <th>DefensiveGoaltends</th>\n",
              "      <th>Period2Fouls4Minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1628276</td>\n",
              "      <td>1611661320</td>\n",
              "      <td>Kelsey Plum</td>\n",
              "      <td>Kelsey Plum</td>\n",
              "      <td>1628276</td>\n",
              "      <td>LAS</td>\n",
              "      <td>241920.0</td>\n",
              "      <td>119</td>\n",
              "      <td>4032.0</td>\n",
              "      <td>687.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1628277</td>\n",
              "      <td>1611661330</td>\n",
              "      <td>Allisha Gray</td>\n",
              "      <td>Allisha Gray</td>\n",
              "      <td>1628277</td>\n",
              "      <td>ATL</td>\n",
              "      <td>239667.0</td>\n",
              "      <td>120</td>\n",
              "      <td>3994.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1628909</td>\n",
              "      <td>1611661325</td>\n",
              "      <td>Kelsey Mitchell</td>\n",
              "      <td>Kelsey Mitchell</td>\n",
              "      <td>1628909</td>\n",
              "      <td>IND</td>\n",
              "      <td>238787.0</td>\n",
              "      <td>124</td>\n",
              "      <td>3980.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>203826</td>\n",
              "      <td>1611661317</td>\n",
              "      <td>Alyssa Thomas</td>\n",
              "      <td>Alyssa Thomas</td>\n",
              "      <td>203826</td>\n",
              "      <td>PHX</td>\n",
              "      <td>236590.9</td>\n",
              "      <td>119</td>\n",
              "      <td>3943.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1629481</td>\n",
              "      <td>1611661321</td>\n",
              "      <td>Arike Ogunbowale</td>\n",
              "      <td>Arike Ogunbowale</td>\n",
              "      <td>1629481</td>\n",
              "      <td>DAL</td>\n",
              "      <td>233447.0</td>\n",
              "      <td>107</td>\n",
              "      <td>3891.0</td>\n",
              "      <td>-219.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>204319</td>\n",
              "      <td>1611661319</td>\n",
              "      <td>Jewell Loyd</td>\n",
              "      <td>Jewell Loyd</td>\n",
              "      <td>204319</td>\n",
              "      <td>LVA</td>\n",
              "      <td>229481.9</td>\n",
              "      <td>119</td>\n",
              "      <td>3825.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1641648</td>\n",
              "      <td>1611661325</td>\n",
              "      <td>Aliyah Boston</td>\n",
              "      <td>Aliyah Boston</td>\n",
              "      <td>1641648</td>\n",
              "      <td>IND</td>\n",
              "      <td>228116.0</td>\n",
              "      <td>124</td>\n",
              "      <td>3802.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1629498</td>\n",
              "      <td>1611661319</td>\n",
              "      <td>Jackie Young</td>\n",
              "      <td>Jackie Young</td>\n",
              "      <td>1629498</td>\n",
              "      <td>LVA</td>\n",
              "      <td>225993.0</td>\n",
              "      <td>120</td>\n",
              "      <td>3767.0</td>\n",
              "      <td>891.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1628932</td>\n",
              "      <td>1611661319</td>\n",
              "      <td>A'ja Wilson</td>\n",
              "      <td>A'ja Wilson</td>\n",
              "      <td>1628932</td>\n",
              "      <td>LVA</td>\n",
              "      <td>225519.0</td>\n",
              "      <td>117</td>\n",
              "      <td>3759.0</td>\n",
              "      <td>961.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>204324</td>\n",
              "      <td>1611661320</td>\n",
              "      <td>Dearica Hamby</td>\n",
              "      <td>Dearica Hamby</td>\n",
              "      <td>204324</td>\n",
              "      <td>LAS</td>\n",
              "      <td>220821.4</td>\n",
              "      <td>124</td>\n",
              "      <td>3680.0</td>\n",
              "      <td>-296.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 249 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce0e8b20-ac1b-46a2-bda6-a411d9209cd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce0e8b20-ac1b-46a2-bda6-a411d9209cd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce0e8b20-ac1b-46a2-bda6-a411d9209cd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7b570eec-9266-4e32-a0f5-357a128f49a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b570eec-9266-4e32-a0f5-357a128f49a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7b570eec-9266-4e32-a0f5-357a128f49a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ wrote: /content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/processed/pbpstats_totals_player_raw_from_json.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_totals_for_season(season: int, season_type=\"Regular Season\", data_type=\"Player\") -> pd.DataFrame:\n",
        "    url = \"https://api.pbpstats.com/get-totals/wnba\"\n",
        "    params = {\"Season\": str(season), \"SeasonType\": season_type, \"Type\": data_type}\n",
        "    r = requests.get(url, params=params, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    payload = r.json()\n",
        "    df_season = pd.DataFrame(payload.get(\"multi_row_table_data\", []))\n",
        "    df_season[\"Season\"] = season\n",
        "    return df_season\n",
        "\n",
        "seasons = [2023, 2024, 2025]\n",
        "dfs = [fetch_totals_for_season(s) for s in seasons]\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(\"✅ combined shape:\", df_all.shape)\n",
        "display(df_all.head(10))\n",
        "\n",
        "out_csv = OUT_DIR / \"pbpstats_totals_player_by_season.csv\"\n",
        "df_all.to_csv(out_csv, index=False)\n",
        "print(\"✅ wrote:\", out_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "bGRU0gspSA--",
        "outputId": "955d73ff-98c3-45d4-a2d6-d29fa202d98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ combined shape: (495, 250)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  EntityId      TeamId              Name         ShortName    RowId  \\\n",
              "0  1629481  1611661321  Arike Ogunbowale  Arike Ogunbowale  1629481   \n",
              "1   203826  1611661323     Alyssa Thomas     Alyssa Thomas   203826   \n",
              "2  1627668  1611661313   Breanna Stewart   Breanna Stewart  1627668   \n",
              "3  1628909  1611661325   Kelsey Mitchell   Kelsey Mitchell  1628909   \n",
              "4   204319  1611661328       Jewell Loyd       Jewell Loyd   204319   \n",
              "5  1629496  1611661328      Ezi Magbegor      Ezi Magbegor  1629496   \n",
              "6   203827  1611661321    Natasha Howard    Natasha Howard   203827   \n",
              "7   203833  1611661319      Chelsea Gray      Chelsea Gray   203833   \n",
              "8  1631009  1611661330      Rhyne Howard      Rhyne Howard  1631009   \n",
              "9  1628276  1611661319       Kelsey Plum       Kelsey Plum  1628276   \n",
              "\n",
              "  TeamAbbreviation  SecondsPlayed  GamesPlayed  Minutes  PlusMinus  ...  \\\n",
              "0              DAL        89341.0           40   1489.0      141.0  ...   \n",
              "1              CON        86738.0           40   1446.0      224.0  ...   \n",
              "2              NYL        81920.0           40   1365.0      357.0  ...   \n",
              "3              IND        80912.0           40   1349.0      -95.0  ...   \n",
              "4              SEA        80612.9           38   1344.0     -146.0  ...   \n",
              "5              SEA        78232.8           40   1304.0     -120.0  ...   \n",
              "6              DAL        77327.0           39   1289.0      115.0  ...   \n",
              "7              LVA        77260.0           40   1288.0      436.0  ...   \n",
              "8              ATL        76972.0           39   1283.0      -13.0  ...   \n",
              "9              LVA        75892.0           39   1265.0      554.0  ...   \n",
              "\n",
              "   OffensiveGoaltends  PeriodOTFouls4Minutes  PeriodOTFouls5Minutes  \\\n",
              "0                 NaN                    NaN                    NaN   \n",
              "1                 NaN                    NaN                    NaN   \n",
              "2                 1.0                    1.0                    9.0   \n",
              "3                 NaN                    5.0                    NaN   \n",
              "4                 NaN                    NaN                    NaN   \n",
              "5                 NaN                    2.0                    1.0   \n",
              "6                 NaN                    1.0                    1.0   \n",
              "7                 NaN                    NaN                    NaN   \n",
              "8                 NaN                    1.0                    1.0   \n",
              "9                 NaN                    NaN                    NaN   \n",
              "\n",
              "   Corner3PctBlocked  Clear Path Fouls  Period3Fouls5Minutes  \\\n",
              "0                NaN               NaN                   NaN   \n",
              "1                NaN               NaN                   NaN   \n",
              "2           0.023810               NaN                   NaN   \n",
              "3                NaN               1.0                   NaN   \n",
              "4                NaN               NaN                   NaN   \n",
              "5           0.083333               NaN                   NaN   \n",
              "6                NaN               NaN                   NaN   \n",
              "7                NaN               NaN                   NaN   \n",
              "8           0.022222               1.0                   NaN   \n",
              "9                NaN               NaN                   NaN   \n",
              "\n",
              "   Period1Fouls3Minutes  Period2Fouls4Minutes  Season  DefensiveGoaltends  \n",
              "0                   NaN                   NaN    2023                 NaN  \n",
              "1                   NaN                   NaN    2023                 NaN  \n",
              "2                   NaN                   NaN    2023                 NaN  \n",
              "3                   NaN                   NaN    2023                 NaN  \n",
              "4                   NaN                   NaN    2023                 NaN  \n",
              "5                   NaN                   NaN    2023                 NaN  \n",
              "6                   NaN                   NaN    2023                 NaN  \n",
              "7                   NaN                   NaN    2023                 NaN  \n",
              "8                   NaN                   NaN    2023                 NaN  \n",
              "9                   NaN                   NaN    2023                 NaN  \n",
              "\n",
              "[10 rows x 250 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e22df4a-00cb-4c69-9ae9-976f6e43b738\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EntityId</th>\n",
              "      <th>TeamId</th>\n",
              "      <th>Name</th>\n",
              "      <th>ShortName</th>\n",
              "      <th>RowId</th>\n",
              "      <th>TeamAbbreviation</th>\n",
              "      <th>SecondsPlayed</th>\n",
              "      <th>GamesPlayed</th>\n",
              "      <th>Minutes</th>\n",
              "      <th>PlusMinus</th>\n",
              "      <th>...</th>\n",
              "      <th>OffensiveGoaltends</th>\n",
              "      <th>PeriodOTFouls4Minutes</th>\n",
              "      <th>PeriodOTFouls5Minutes</th>\n",
              "      <th>Corner3PctBlocked</th>\n",
              "      <th>Clear Path Fouls</th>\n",
              "      <th>Period3Fouls5Minutes</th>\n",
              "      <th>Period1Fouls3Minutes</th>\n",
              "      <th>Period2Fouls4Minutes</th>\n",
              "      <th>Season</th>\n",
              "      <th>DefensiveGoaltends</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1629481</td>\n",
              "      <td>1611661321</td>\n",
              "      <td>Arike Ogunbowale</td>\n",
              "      <td>Arike Ogunbowale</td>\n",
              "      <td>1629481</td>\n",
              "      <td>DAL</td>\n",
              "      <td>89341.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1489.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>203826</td>\n",
              "      <td>1611661323</td>\n",
              "      <td>Alyssa Thomas</td>\n",
              "      <td>Alyssa Thomas</td>\n",
              "      <td>203826</td>\n",
              "      <td>CON</td>\n",
              "      <td>86738.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1446.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1627668</td>\n",
              "      <td>1611661313</td>\n",
              "      <td>Breanna Stewart</td>\n",
              "      <td>Breanna Stewart</td>\n",
              "      <td>1627668</td>\n",
              "      <td>NYL</td>\n",
              "      <td>81920.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1365.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1628909</td>\n",
              "      <td>1611661325</td>\n",
              "      <td>Kelsey Mitchell</td>\n",
              "      <td>Kelsey Mitchell</td>\n",
              "      <td>1628909</td>\n",
              "      <td>IND</td>\n",
              "      <td>80912.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1349.0</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>204319</td>\n",
              "      <td>1611661328</td>\n",
              "      <td>Jewell Loyd</td>\n",
              "      <td>Jewell Loyd</td>\n",
              "      <td>204319</td>\n",
              "      <td>SEA</td>\n",
              "      <td>80612.9</td>\n",
              "      <td>38</td>\n",
              "      <td>1344.0</td>\n",
              "      <td>-146.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1629496</td>\n",
              "      <td>1611661328</td>\n",
              "      <td>Ezi Magbegor</td>\n",
              "      <td>Ezi Magbegor</td>\n",
              "      <td>1629496</td>\n",
              "      <td>SEA</td>\n",
              "      <td>78232.8</td>\n",
              "      <td>40</td>\n",
              "      <td>1304.0</td>\n",
              "      <td>-120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>203827</td>\n",
              "      <td>1611661321</td>\n",
              "      <td>Natasha Howard</td>\n",
              "      <td>Natasha Howard</td>\n",
              "      <td>203827</td>\n",
              "      <td>DAL</td>\n",
              "      <td>77327.0</td>\n",
              "      <td>39</td>\n",
              "      <td>1289.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>203833</td>\n",
              "      <td>1611661319</td>\n",
              "      <td>Chelsea Gray</td>\n",
              "      <td>Chelsea Gray</td>\n",
              "      <td>203833</td>\n",
              "      <td>LVA</td>\n",
              "      <td>77260.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1288.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1631009</td>\n",
              "      <td>1611661330</td>\n",
              "      <td>Rhyne Howard</td>\n",
              "      <td>Rhyne Howard</td>\n",
              "      <td>1631009</td>\n",
              "      <td>ATL</td>\n",
              "      <td>76972.0</td>\n",
              "      <td>39</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1628276</td>\n",
              "      <td>1611661319</td>\n",
              "      <td>Kelsey Plum</td>\n",
              "      <td>Kelsey Plum</td>\n",
              "      <td>1628276</td>\n",
              "      <td>LVA</td>\n",
              "      <td>75892.0</td>\n",
              "      <td>39</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 250 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e22df4a-00cb-4c69-9ae9-976f6e43b738')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e22df4a-00cb-4c69-9ae9-976f6e43b738 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e22df4a-00cb-4c69-9ae9-976f6e43b738');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1b5bc2b1-7264-4bc6-a253-9f2161d38138\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b5bc2b1-7264-4bc6-a253-9f2161d38138')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1b5bc2b1-7264-4bc6-a253-9f2161d38138 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ wrote: /content/processed_positions/pbpstats_totals_player_by_season.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = str(s).strip().lower()\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def norm_team_abbr(s: str) -> str:\n",
        "    return str(s).strip().upper()\n",
        "\n",
        "# ✅ Update this path to your position-mapping CSV (must contain Name + Position + Team_Abbreviation)\n",
        "POS_MAP_PATH = Path(\"import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    # strip accents safely: Koné -> kone\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    # keep letters, spaces, hyphen, apostrophe\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def norm_team_abbr(s: str) -> str:\n",
        "    return \"\" if pd.isna(s) else str(s).strip().upper()\n",
        "\n",
        "# ---- paths ----\n",
        "POS_MAP_PATH = Path(\"/content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/mapping_player_team_id_seasons.csv\")\n",
        "\n",
        "pos = pd.read_csv(POS_MAP_PATH)\n",
        "pos.columns = [c.strip() for c in pos.columns]\n",
        "\n",
        "# required mapping columns\n",
        "required = {\"Name\", \"Team_Abbreviation\"}\n",
        "missing = required - set(pos.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Mapping CSV missing required columns: {missing}. Found: {pos.columns.tolist()}\")\n",
        "\n",
        "pos_col = next((c for c in pos.columns if c.lower() in {\"position\", \"pos\"}), None)\n",
        "if not pos_col:\n",
        "    raise ValueError(f\"Mapping CSV must include Position or Pos. Found: {pos.columns.tolist()}\")\n",
        "\n",
        "# choose totals dataframe\n",
        "df_use = df_all if \"df_all\" in globals() and isinstance(df_all, pd.DataFrame) else df\n",
        "\n",
        "if \"TeamAbbreviation\" not in df_use.columns:\n",
        "    raise ValueError(f\"PBP DF missing TeamAbbreviation. Found: {df_use.columns.tolist()[:50]}\")\n",
        "\n",
        "# normalize keys\n",
        "df_use = df_use.copy()\n",
        "df_use[\"Name_norm\"] = df_use[\"Name\"].apply(norm_name)\n",
        "df_use[\"TeamAbbr_norm\"] = df_use[\"TeamAbbreviation\"].apply(norm_team_abbr)\n",
        "\n",
        "pos = pos.copy()\n",
        "pos[\"Name_norm\"] = pos[\"Name\"].apply(norm_name)\n",
        "pos[\"TeamAbbr_norm\"] = pos[\"Team_Abbreviation\"].apply(norm_team_abbr)\n",
        "\n",
        "# --- 1) Merge on Name + Team ---\n",
        "pos_team = (\n",
        "    pos[[\"Name_norm\", \"TeamAbbr_norm\", pos_col]]\n",
        "    .dropna(subset=[\"Name_norm\"])\n",
        "    .drop_duplicates(subset=[\"Name_norm\", \"TeamAbbr_norm\"])\n",
        ")\n",
        "m1 = df_use.merge(pos_team, on=[\"Name_norm\", \"TeamAbbr_norm\"], how=\"left\").rename(columns={pos_col: \"Position_team\"})\n",
        "\n",
        "# --- 2) Fallback merge on Name only (mode position per player) ---\n",
        "pos_name = (\n",
        "    pos.dropna(subset=[\"Name_norm\"])\n",
        "      .groupby(\"Name_norm\")[pos_col]\n",
        "      .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0])\n",
        "      .reset_index()\n",
        "      .rename(columns={pos_col: \"Position_name\"})\n",
        ")\n",
        "\n",
        "m2 = m1.merge(pos_name, on=\"Name_norm\", how=\"left\")\n",
        "\n",
        "# combine: prefer team-specific, else name-only\n",
        "m2[\"Position\"] = m2[\"Position_team\"].combine_first(m2[\"Position_name\"])\n",
        "\n",
        "print(\"Missing after Name+Team:\", m1[\"Position_team\"].isna().mean())\n",
        "print(\"Missing after fallback Name-only:\", m2[\"Position\"].isna().mean())\n",
        "\n",
        "# sanity display\n",
        "display(m2[[\"Name\", \"TeamAbbreviation\", \"Position\", \"Position_team\", \"Position_name\"]].head(20))\n",
        "\n",
        "# show a sample of still-missing\n",
        "display(\n",
        "    m2.loc[m2[\"Position\"].isna(), [\"Name\", \"TeamAbbreviation\"]]\n",
        "      .drop_duplicates()\n",
        "      .h\n",
        "\")\n",
        "\n",
        "pos = pd.read_csv(POS_MAP_PATH)\n",
        "pos.columns = [c.strip() for c in pos.columns]  # trims column name whitespace\n",
        "\n",
        "# --- Required columns ---\n",
        "required = {\"Name\", \"Team_Abbreviation\"}\n",
        "missing = required - set(pos.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Mapping CSV missing required columns: {missing}. Found: {pos.columns.tolist()}\")\n",
        "\n",
        "# Find a Position column (flexible)\n",
        "pos_col = next((c for c in pos.columns if c.strip().lower() in {\"position\", \"pos\"}), None)\n",
        "if not pos_col:\n",
        "    raise ValueError(\n",
        "        f\"Mapping CSV must include a Position column (Position or Pos). Found: {pos.columns.tolist()}\"\n",
        "    )\n",
        "\n",
        "# Use df_all if it exists (by-season), else df (raw)\n",
        "df_use = df_all if \"df_all\" in globals() and isinstance(df_all, pd.DataFrame) else df\n",
        "\n",
        "# Confirm pbp column exists\n",
        "if \"TeamAbbreviation\" not in df_use.columns:\n",
        "    raise ValueError(f\"PBP DF missing TeamAbbreviation. Found columns: {df_use.columns.tolist()[:50]}\")\n",
        "\n",
        "# Normalize join keys\n",
        "df_use = df_use.copy()\n",
        "df_use[\"Name_norm\"] = df_use[\"Name\"].apply(norm_name)\n",
        "df_use[\"TeamAbbr_norm\"] = df_use[\"TeamAbbreviation\"].apply(norm_team_abbr)\n",
        "\n",
        "pos = pos.copy()\n",
        "pos[\"Name_norm\"] = pos[\"Name\"].apply(norm_name)\n",
        "pos[\"TeamAbbr_norm\"] = pos[\"Team_Abbreviation\"].apply(norm_team_abbr)\n",
        "\n",
        "# Merge\n",
        "merged = df_use.merge(\n",
        "    pos[[\"Name_norm\", \"TeamAbbr_norm\", pos_col]],\n",
        "    on=[\"Name_norm\", \"TeamAbbr_norm\"],\n",
        "    how=\"left\"\n",
        ").rename(columns={pos_col: \"Position\"})\n",
        "\n",
        "print(\"✅ Missing Position %:\", merged[\"Position\"].isna().mean())\n",
        "display(\n",
        "    merged.loc[merged[\"Position\"].isna(), [\"Name\", \"TeamAbbreviation\"]]\n",
        "      .drop_duplicates()\n",
        "      .head(25)\n",
        ")\n",
        "\n",
        "# Save\n",
        "OUT_DIR = Path(\"/content/Basketball-Analytics-Course/scripts/wnba_scripts/pbpstats/processed\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "out_csv = OUT_DIR / \"pbpstats_totals_player_with_position.csv\"\n",
        "merged.to_csv(out_csv, index=False)\n",
        "print(\"✅ wrote:\", out_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "eW7lD5poUKJP",
        "outputId": "818b0270-fb0a-4ab4-def8-32e2cb214be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 15) (ipython-input-4052203312.py, line 15)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4052203312.py\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    POS_MAP_PATH = Path(\"import pandas as pd\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    # strip accents safely: Koné -> kone\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    # keep letters, spaces, hyphen, apostrophe\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def norm_team_abbr(s: str) -> str:\n",
        "    return \"\" if pd.isna(s) else str(s).strip().upper()\n",
        "\n",
        "# ---- paths ----\n",
        "POS_MAP_PATH = Path(\"/content/Basketball-Analytics-Course/mapping_player_team_id_seasons.csv\")\n",
        "\n",
        "pos = pd.read_csv(POS_MAP_PATH)\n",
        "pos.columns = [c.strip() for c in pos.columns]\n",
        "\n",
        "# required mapping columns\n",
        "required = {\"Name\", \"Team_Abbreviation\"}\n",
        "missing = required - set(pos.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Mapping CSV missing required columns: {missing}. Found: {pos.columns.tolist()}\")\n",
        "\n",
        "pos_col = next((c for c in pos.columns if c.lower() in {\"position\", \"pos\"}), None)\n",
        "if not pos_col:\n",
        "    raise ValueError(f\"Mapping CSV must include Position or Pos. Found: {pos.columns.tolist()}\")\n",
        "\n",
        "# choose totals dataframe\n",
        "df_use = df_all if \"df_all\" in globals() and isinstance(df_all, pd.DataFrame) else df\n",
        "\n",
        "if \"TeamAbbreviation\" not in df_use.columns:\n",
        "    raise ValueError(f\"PBP DF missing TeamAbbreviation. Found: {df_use.columns.tolist()[:50]}\")\n",
        "\n",
        "# normalize keys\n",
        "df_use = df_use.copy()\n",
        "df_use[\"Name_norm\"] = df_use[\"Name\"].apply(norm_name)\n",
        "df_use[\"TeamAbbr_norm\"] = df_use[\"TeamAbbreviation\"].apply(norm_team_abbr)\n",
        "\n",
        "pos = pos.copy()\n",
        "pos[\"Name_norm\"] = pos[\"Name\"].apply(norm_name)\n",
        "pos[\"TeamAbbr_norm\"] = pos[\"Team_Abbreviation\"].apply(norm_team_abbr)\n",
        "\n",
        "# --- 1) Merge on Name + Team ---\n",
        "pos_team = (\n",
        "    pos[[\"Name_norm\", \"TeamAbbr_norm\", pos_col]]\n",
        "    .dropna(subset=[\"Name_norm\"])\n",
        "    .drop_duplicates(subset=[\"Name_norm\", \"TeamAbbr_norm\"])\n",
        ")\n",
        "m1 = df_use.merge(pos_team, on=[\"Name_norm\", \"TeamAbbr_norm\"], how=\"left\").rename(columns={pos_col: \"Position_team\"})\n",
        "\n",
        "# --- 2) Fallback merge on Name only (mode position per player) ---\n",
        "pos_name = (\n",
        "    pos.dropna(subset=[\"Name_norm\"])\n",
        "      .groupby(\"Name_norm\")[pos_col]\n",
        "      .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0])\n",
        "      .reset_index()\n",
        "      .rename(columns={pos_col: \"Position_name\"})\n",
        ")\n",
        "\n",
        "m2 = m1.merge(pos_name, on=\"Name_norm\", how=\"left\")\n",
        "\n",
        "# combine: prefer team-specific, else name-only\n",
        "m2[\"Position\"] = m2[\"Position_team\"].combine_first(m2[\"Position_name\"])\n",
        "\n",
        "print(\"Missing after Name+Team:\", m1[\"Position_team\"].isna().mean())\n",
        "print(\"Missing after fallback Name-only:\", m2[\"Position\"].isna().mean())\n",
        "\n",
        "# sanity display\n",
        "display(m2[[\"Name\", \"TeamAbbreviation\", \"Position\", \"Position_team\", \"Position_name\"]].head(20))\n",
        "\n",
        "# show a sample of still-missing\n",
        "display(\n",
        "    m2.loc[m2[\"Position\"].isna(), [\"Name\", \"TeamAbbreviation\"]]\n",
        "      .drop_duplicates()\n",
        "      .head(25)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sclBHToQVSC4",
        "outputId": "540c0839-da18-4235-9bc2-5a3d6861e22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing after Name+Team: 0.46060606060606063\n",
            "Missing after fallback Name-only: 0.1898989898989899\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 Name TeamAbbreviation Position Position_team Position_name\n",
              "0    Arike Ogunbowale              DAL        G             G             G\n",
              "1       Alyssa Thomas              CON        F           NaN             F\n",
              "2     Breanna Stewart              NYL        F             F             F\n",
              "3     Kelsey Mitchell              IND        G             G             G\n",
              "4         Jewell Loyd              SEA        G           NaN             G\n",
              "5        Ezi Magbegor              SEA     F, C          F, C          F, C\n",
              "6      Natasha Howard              DAL        F           NaN             F\n",
              "7        Chelsea Gray              LVA        G             G             G\n",
              "8        Rhyne Howard              ATL        G             G             G\n",
              "9         Kelsey Plum              LVA        G           NaN             G\n",
              "10       Jackie Young              LVA        G             G             G\n",
              "11      Satou Sabally              DAL        F           NaN             F\n",
              "12     Brittney Sykes              WAS        G           NaN             G\n",
              "13      Aliyah Boston              IND     C, F          C, F          C, F\n",
              "14       Allisha Gray              ATL        G             G             G\n",
              "15   Napheesa Collier              MIN        F             F             F\n",
              "16      Jordin Canada              LAS        G           NaN             G\n",
              "17        A'ja Wilson              LVA        C             C             C\n",
              "18      Kayla McBride              MIN        G             G             G\n",
              "19  Courtney Williams              CHI        G           NaN             G"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f046744-4169-4634-b2ae-0f2188c95854\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>TeamAbbreviation</th>\n",
              "      <th>Position</th>\n",
              "      <th>Position_team</th>\n",
              "      <th>Position_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arike Ogunbowale</td>\n",
              "      <td>DAL</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alyssa Thomas</td>\n",
              "      <td>CON</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Breanna Stewart</td>\n",
              "      <td>NYL</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kelsey Mitchell</td>\n",
              "      <td>IND</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jewell Loyd</td>\n",
              "      <td>SEA</td>\n",
              "      <td>G</td>\n",
              "      <td>NaN</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ezi Magbegor</td>\n",
              "      <td>SEA</td>\n",
              "      <td>F, C</td>\n",
              "      <td>F, C</td>\n",
              "      <td>F, C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Natasha Howard</td>\n",
              "      <td>DAL</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Chelsea Gray</td>\n",
              "      <td>LVA</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Rhyne Howard</td>\n",
              "      <td>ATL</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kelsey Plum</td>\n",
              "      <td>LVA</td>\n",
              "      <td>G</td>\n",
              "      <td>NaN</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Jackie Young</td>\n",
              "      <td>LVA</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satou Sabally</td>\n",
              "      <td>DAL</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Brittney Sykes</td>\n",
              "      <td>WAS</td>\n",
              "      <td>G</td>\n",
              "      <td>NaN</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Aliyah Boston</td>\n",
              "      <td>IND</td>\n",
              "      <td>C, F</td>\n",
              "      <td>C, F</td>\n",
              "      <td>C, F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Allisha Gray</td>\n",
              "      <td>ATL</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Napheesa Collier</td>\n",
              "      <td>MIN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Jordin Canada</td>\n",
              "      <td>LAS</td>\n",
              "      <td>G</td>\n",
              "      <td>NaN</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A'ja Wilson</td>\n",
              "      <td>LVA</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Kayla McBride</td>\n",
              "      <td>MIN</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Courtney Williams</td>\n",
              "      <td>CHI</td>\n",
              "      <td>G</td>\n",
              "      <td>NaN</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f046744-4169-4634-b2ae-0f2188c95854')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f046744-4169-4634-b2ae-0f2188c95854 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f046744-4169-4634-b2ae-0f2188c95854');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-733a7d53-1c72-4ce3-8fae-5a8062d5c6a1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-733a7d53-1c72-4ce3-8fae-5a8062d5c6a1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-733a7d53-1c72-4ce3-8fae-5a8062d5c6a1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Arike Ogunbowale\",\n          \"A'ja Wilson\",\n          \"Napheesa Collier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TeamAbbreviation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"LVA\",\n          \"DAL\",\n          \"LAS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"F\",\n          \"C\",\n          \"F, C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position_team\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"F\",\n          \"C\",\n          \"F, C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"F\",\n          \"C\",\n          \"F, C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        Name TeamAbbreviation\n",
              "21            Betnijah Laney              NYL\n",
              "32           Cheyenne Parker              ATL\n",
              "40       Crystal Dangerfield              DAL\n",
              "43              Dorka Juhász              MIN\n",
              "44            Tianna Hawkins              WAS\n",
              "54            Jordan Horston              SEA\n",
              "59            Kristy Wallace              IND\n",
              "60             Diana Taurasi              PHO\n",
              "64         Danielle Robinson              ATL\n",
              "65         Layshia Clarendon              LAS\n",
              "68          Victoria Vivians              IND\n",
              "72         Elena Delle Donne              WAS\n",
              "84                   Li Meng              WAS\n",
              "89            Nikolina Milic              MIN\n",
              "90                Queen Egbo              WAS\n",
              "91   Dulcy Fankam Mendjiadeu              SEA\n",
              "92              Ivana Dojkić              SEA\n",
              "95            Candace Parker              LVA\n",
              "98            Jasmine Thomas              LAS\n",
              "99                Awak Kuier              DAL\n",
              "100           Morgan Bertsch              CHI\n",
              "101           Asia (AD) Durr              ATL\n",
              "104             Kadi Sissoko              PHO\n",
              "113             Cayla George              LVA\n",
              "116           Amanda Zahui B              IND"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d78555a-4b61-4252-9814-ac96373d6413\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>TeamAbbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Betnijah Laney</td>\n",
              "      <td>NYL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Cheyenne Parker</td>\n",
              "      <td>ATL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Crystal Dangerfield</td>\n",
              "      <td>DAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Dorka Juhász</td>\n",
              "      <td>MIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Tianna Hawkins</td>\n",
              "      <td>WAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Jordan Horston</td>\n",
              "      <td>SEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Kristy Wallace</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Diana Taurasi</td>\n",
              "      <td>PHO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Danielle Robinson</td>\n",
              "      <td>ATL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Layshia Clarendon</td>\n",
              "      <td>LAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Victoria Vivians</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Elena Delle Donne</td>\n",
              "      <td>WAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Li Meng</td>\n",
              "      <td>WAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Nikolina Milic</td>\n",
              "      <td>MIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Queen Egbo</td>\n",
              "      <td>WAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>Dulcy Fankam Mendjiadeu</td>\n",
              "      <td>SEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Ivana Dojkić</td>\n",
              "      <td>SEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Candace Parker</td>\n",
              "      <td>LVA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Jasmine Thomas</td>\n",
              "      <td>LAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Awak Kuier</td>\n",
              "      <td>DAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>Morgan Bertsch</td>\n",
              "      <td>CHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Asia (AD) Durr</td>\n",
              "      <td>ATL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>Kadi Sissoko</td>\n",
              "      <td>PHO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Cayla George</td>\n",
              "      <td>LVA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Amanda Zahui B</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d78555a-4b61-4252-9814-ac96373d6413')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d78555a-4b61-4252-9814-ac96373d6413 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d78555a-4b61-4252-9814-ac96373d6413');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-441cee73-a4ce-478d-97e5-8753a61dea04\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-441cee73-a4ce-478d-97e5-8753a61dea04')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-441cee73-a4ce-478d-97e5-8753a61dea04 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Danielle Robinson\",\n          \"Ivana Dojki\\u0107\",\n          \"Betnijah Laney\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TeamAbbreviation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"SEA\",\n          \"NYL\",\n          \"LVA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [c for c in [\"Name\", \"TeamAbbreviation\", \"Season\"] if c in m2.columns]\n",
        "\n",
        "missing_rows = (\n",
        "    m2.loc[m2[\"Position\"].isna(), cols]\n",
        "      .dropna(subset=[\"Name\"])\n",
        "      .drop_duplicates()\n",
        "      .sort_values(cols)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(f\"Missing position rows: {len(missing_rows)}\")\n",
        "display(missing_rows.head(50))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lx9jNH6vWJps",
        "outputId": "370fce60-1acd-486a-a637-e8acc9fc5085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing position rows: 94\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       Name TeamAbbreviation  Season\n",
              "0               Abby Meyers              WAS    2023\n",
              "1             Alaina Coates              LVA    2023\n",
              "2            Amanda Zahui B              IND    2023\n",
              "3                Amy Atwell              PHO    2024\n",
              "4          Arella Guirantes              SEA    2023\n",
              "5              Ashley Joens              PHO    2023\n",
              "6            Asia (AD) Durr              ATL    2023\n",
              "7          Astou Ndour-Fall              CON    2024\n",
              "8                Awak Kuier              DAL    2023\n",
              "9           Bernadett Hatar              CON    2023\n",
              "10           Betnijah Laney              NYL    2023\n",
              "11  Betnijah Laney-Hamilton              NYL    2024\n",
              "12           Caitlin Bickle              CON    2024\n",
              "13           Candace Parker              LVA    2023\n",
              "14             Cayla George              LVA    2023\n",
              "15           Celeste Taylor              PHO    2024\n",
              "16         Charisma Osborne              PHO    2024\n",
              "17          Chennedy Carter              CHI    2024\n",
              "18          Cheyenne Parker              ATL    2023\n",
              "19          Chiney Ogwumike              LAS    2023\n",
              "20      Crystal Dangerfield              DAL    2023\n",
              "21      Crystal Dangerfield              LAS    2024\n",
              "22             Cyesha Goree              WAS    2023\n",
              "23        Danielle Robinson              ATL    2023\n",
              "24       Destanni Henderson              ATL    2024\n",
              "25       Destanni Henderson              PHO    2023\n",
              "26            DiDi Richards              WAS    2024\n",
              "27        Diamond DeShields              CHI    2024\n",
              "28            Diana Taurasi              PHO    2023\n",
              "29            Diana Taurasi              PHO    2024\n",
              "30             Dorka Juhász              MIN    2023\n",
              "31             Dorka Juhász              MIN    2024\n",
              "32  Dulcy Fankam Mendjiadeu              SEA    2023\n",
              "33  Dulcy Fankam Mendjiadeu              SEA    2024\n",
              "34             Dyaisha Fair              LVA    2024\n",
              "35        Elena Delle Donne              WAS    2023\n",
              "36         Epiphanny Prince              NYL    2023\n",
              "37          Evina Westbrook              LAS    2023\n",
              "38              Ezinne Kalu              ATL    2024\n",
              "39                   Han Xu              NYL    2023\n",
              "40             Ivana Dojkic              NYL    2024\n",
              "41             Ivana Dojkić              SEA    2023\n",
              "42       Jakia Brown-Turner              WAS    2024\n",
              "43           Jasmine Dickey              DAL    2023\n",
              "44           Jasmine Thomas              LAS    2023\n",
              "45             Jennie Simms              PHO    2023\n",
              "46           Jessika Carter              LVA    2024\n",
              "47       Jocelyn Willoughby              NYL    2023\n",
              "48           Jordan Horston              SEA    2023\n",
              "49           Jordan Horston              SEA    2024"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4bc3536-487b-4d22-b8b5-ddc0c3abdf6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>TeamAbbreviation</th>\n",
              "      <th>Season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abby Meyers</td>\n",
              "      <td>WAS</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alaina Coates</td>\n",
              "      <td>LVA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amanda Zahui B</td>\n",
              "      <td>IND</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amy Atwell</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arella Guirantes</td>\n",
              "      <td>SEA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ashley Joens</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Asia (AD) Durr</td>\n",
              "      <td>ATL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Astou Ndour-Fall</td>\n",
              "      <td>CON</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Awak Kuier</td>\n",
              "      <td>DAL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bernadett Hatar</td>\n",
              "      <td>CON</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Betnijah Laney</td>\n",
              "      <td>NYL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Betnijah Laney-Hamilton</td>\n",
              "      <td>NYL</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Caitlin Bickle</td>\n",
              "      <td>CON</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Candace Parker</td>\n",
              "      <td>LVA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Cayla George</td>\n",
              "      <td>LVA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Celeste Taylor</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Charisma Osborne</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Chennedy Carter</td>\n",
              "      <td>CHI</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Cheyenne Parker</td>\n",
              "      <td>ATL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Chiney Ogwumike</td>\n",
              "      <td>LAS</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Crystal Dangerfield</td>\n",
              "      <td>DAL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Crystal Dangerfield</td>\n",
              "      <td>LAS</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Cyesha Goree</td>\n",
              "      <td>WAS</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Danielle Robinson</td>\n",
              "      <td>ATL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Destanni Henderson</td>\n",
              "      <td>ATL</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Destanni Henderson</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>DiDi Richards</td>\n",
              "      <td>WAS</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Diamond DeShields</td>\n",
              "      <td>CHI</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Diana Taurasi</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Diana Taurasi</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Dorka Juhász</td>\n",
              "      <td>MIN</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Dorka Juhász</td>\n",
              "      <td>MIN</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Dulcy Fankam Mendjiadeu</td>\n",
              "      <td>SEA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Dulcy Fankam Mendjiadeu</td>\n",
              "      <td>SEA</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Dyaisha Fair</td>\n",
              "      <td>LVA</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Elena Delle Donne</td>\n",
              "      <td>WAS</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Epiphanny Prince</td>\n",
              "      <td>NYL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Evina Westbrook</td>\n",
              "      <td>LAS</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Ezinne Kalu</td>\n",
              "      <td>ATL</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Han Xu</td>\n",
              "      <td>NYL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Ivana Dojkic</td>\n",
              "      <td>NYL</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Ivana Dojkić</td>\n",
              "      <td>SEA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Jakia Brown-Turner</td>\n",
              "      <td>WAS</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Jasmine Dickey</td>\n",
              "      <td>DAL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Jasmine Thomas</td>\n",
              "      <td>LAS</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Jennie Simms</td>\n",
              "      <td>PHO</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Jessika Carter</td>\n",
              "      <td>LVA</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Jocelyn Willoughby</td>\n",
              "      <td>NYL</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Jordan Horston</td>\n",
              "      <td>SEA</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Jordan Horston</td>\n",
              "      <td>SEA</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4bc3536-487b-4d22-b8b5-ddc0c3abdf6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4bc3536-487b-4d22-b8b5-ddc0c3abdf6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4bc3536-487b-4d22-b8b5-ddc0c3abdf6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ad390903-20cd-40fe-b5e8-f0d4c9bfb60f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad390903-20cd-40fe-b5e8-f0d4c9bfb60f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ad390903-20cd-40fe-b5e8-f0d4c9bfb60f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(missing_rows\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"Jakia Brown-Turner\",\n          \"DiDi Richards\",\n          \"Diamond DeShields\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TeamAbbreviation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"LAS\",\n          \"CHI\",\n          \"WAS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2023,\n        \"max\": 2024,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2024,\n          2023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "BOX_PATH = Path(\"/content/player_box_2023.csv\")  # <- you said this exists in Colab\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "box = pd.read_csv(BOX_PATH)\n",
        "\n",
        "# Robust column detection (in case casing differs)\n",
        "cols = {c.lower(): c for c in box.columns}\n",
        "name_col = cols.get(\"athlete_display_name\")\n",
        "pos_col  = cols.get(\"athlete_position_abbreviation\")\n",
        "\n",
        "if not name_col or not pos_col:\n",
        "    raise ValueError(f\"Couldn't find required columns. Found columns: {box.columns.tolist()[:50]}\")\n",
        "\n",
        "# Keep only what we need\n",
        "box_small = box[[name_col, pos_col]].copy()\n",
        "box_small.columns = [\"Name\", \"PosAbbr\"]\n",
        "\n",
        "# Normalize\n",
        "box_small[\"Name_norm\"] = box_small[\"Name\"].apply(norm_name)\n",
        "box_small[\"PosAbbr\"] = box_small[\"PosAbbr\"].astype(str).str.strip().str.upper().replace({\"\": pd.NA, \"NAN\": pd.NA})\n",
        "\n",
        "# Build a single “best” position per player (mode / most frequent)\n",
        "pos_lookup_2023 = (\n",
        "    box_small.dropna(subset=[\"Name_norm\", \"PosAbbr\"])\n",
        "             .groupby(\"Name_norm\")[\"PosAbbr\"]\n",
        "             .agg(lambda s: s.value_counts().index[0])   # top frequency\n",
        "             .reset_index()\n",
        "             .rename(columns={\"PosAbbr\": \"Position_from_2023_box\"})\n",
        ")\n",
        "\n",
        "print(\"✅ Unique players in 2023 lookup:\", len(pos_lookup_2023))\n",
        "display(pos_lookup_2023.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "RvaOdRDN6HmG",
        "outputId": "8e72db1d-6150-4630-e7e9-09127d13bc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Unique players in 2023 lookup: 164\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Name_norm Position_from_2023_box\n",
              "0    a'ja wilson                      F\n",
              "1  aari mcdonald                      G\n",
              "2    abby meyers                      G\n",
              "3        ad durr                      G\n",
              "4  aerial powers                      G\n",
              "5  alaina coates                      C\n",
              "6   alanna smith                      F\n",
              "7  aliyah boston                      F\n",
              "8   allisha gray                      G\n",
              "9   alysha clark                      F"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-717af744-97a5-41e6-9858-dcfe1d7823e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name_norm</th>\n",
              "      <th>Position_from_2023_box</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a'ja wilson</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aari mcdonald</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abby meyers</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ad durr</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aerial powers</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>alaina coates</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>alanna smith</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>aliyah boston</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>allisha gray</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>alysha clark</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-717af744-97a5-41e6-9858-dcfe1d7823e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-717af744-97a5-41e6-9858-dcfe1d7823e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-717af744-97a5-41e6-9858-dcfe1d7823e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2d7e2147-3a74-458e-8164-ce428cce0bd0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d7e2147-3a74-458e-8164-ce428cce0bd0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2d7e2147-3a74-458e-8164-ce428cce0bd0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(pos_lookup_2023\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Name_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"allisha gray\",\n          \"aari mcdonald\",\n          \"alaina coates\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position_from_2023_box\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"F\",\n          \"G\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------\n",
        "# Paths (as you specified)\n",
        "# ----------------------------\n",
        "TOTALS_PATH = Path(\"/content/pbpstats_totals_cleaned.csv\")\n",
        "BOX2023_PATH = Path(\"/content/player_box_2023.csv\")\n",
        "MAP2025_PATH = Path(\"/content/mapping_player_team_id_seasons.csv\")\n",
        "\n",
        "OUT_DIR = Path(\"/content/processed_positions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_TOTALS = OUT_DIR / \"pbpstats_totals_cleaned_with_positions.csv\"\n",
        "OUT_MASTER = OUT_DIR / \"position_mapping_master.csv\"\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Normalizers\n",
        "# ----------------------------\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def pick_first_existing_col(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols_lower:\n",
        "            return cols_lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Load totals\n",
        "# ----------------------------\n",
        "totals = pd.read_csv(TOTALS_PATH)\n",
        "totals.columns = [c.strip() for c in totals.columns]\n",
        "\n",
        "name_col_totals = pick_first_existing_col(totals, [\"Name\", \"player\", \"Player\", \"athlete_display_name\"])\n",
        "if not name_col_totals:\n",
        "    raise ValueError(f\"Couldn't find a Name column in totals. Columns: {totals.columns.tolist()[:50]}\")\n",
        "\n",
        "totals = totals.rename(columns={name_col_totals: \"Name\"})\n",
        "totals[\"Name_norm\"] = totals[\"Name\"].apply(norm_name)\n",
        "\n",
        "# If totals already has Position, keep it\n",
        "pos_col_totals = pick_first_existing_col(totals, [\"Position\", \"Pos\"])\n",
        "if pos_col_totals and pos_col_totals != \"Position\":\n",
        "    totals = totals.rename(columns={pos_col_totals: \"Position\"})\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Build lookup from 2023 box scores\n",
        "# ----------------------------\n",
        "box = pd.read_csv(BOX2023_PATH)\n",
        "box.columns = [c.strip() for c in box.columns]\n",
        "\n",
        "name_col_box = pick_first_existing_col(box, [\"athlete_display_name\"])\n",
        "pos_col_box  = pick_first_existing_col(box, [\"athlete_position_abbreviation\"])\n",
        "\n",
        "if not name_col_box or not pos_col_box:\n",
        "    raise ValueError(\n",
        "        \"player_box_2023.csv must have athlete_display_name and athlete_position_abbreviation. \"\n",
        "        f\"Found: {box.columns.tolist()[:50]}\"\n",
        "    )\n",
        "\n",
        "box_small = box[[name_col_box, pos_col_box]].copy()\n",
        "box_small.columns = [\"Name\", \"PosAbbr\"]\n",
        "box_small[\"Name_norm\"] = box_small[\"Name\"].apply(norm_name)\n",
        "box_small[\"PosAbbr\"] = (\n",
        "    box_small[\"PosAbbr\"].astype(str).str.strip().str.upper().replace({\"\": pd.NA, \"NAN\": pd.NA})\n",
        ")\n",
        "\n",
        "# Most frequent position per player\n",
        "lookup_2023 = (\n",
        "    box_small.dropna(subset=[\"Name_norm\", \"PosAbbr\"])\n",
        "             .groupby(\"Name_norm\")[\"PosAbbr\"]\n",
        "             .agg(lambda s: s.value_counts().index[0])\n",
        "             .reset_index()\n",
        "             .rename(columns={\"PosAbbr\": \"Position_from_2023\"})\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Build lookup from 2025 mapping file\n",
        "# ----------------------------\n",
        "mp = pd.read_csv(MAP2025_PATH)\n",
        "mp.columns = [c.strip() for c in mp.columns]\n",
        "\n",
        "name_col_map = pick_first_existing_col(mp, [\"Name\", \"player\", \"Player\", \"athlete_display_name\"])\n",
        "if not name_col_map:\n",
        "    raise ValueError(f\"Couldn't find Name column in mapping file. Columns: {mp.columns.tolist()[:50]}\")\n",
        "\n",
        "pos_col_map = pick_first_existing_col(mp, [\"Position\", \"Pos\"])\n",
        "if not pos_col_map:\n",
        "    raise ValueError(\n",
        "        f\"Couldn't find Position/Pos column in mapping file. Columns: {mp.columns.tolist()[:50]}\"\n",
        "    )\n",
        "\n",
        "mp_small = mp[[name_col_map, pos_col_map]].copy()\n",
        "mp_small.columns = [\"Name\", \"Position_from_2025\"]\n",
        "mp_small[\"Name_norm\"] = mp_small[\"Name\"].apply(norm_name)\n",
        "\n",
        "# If multiple entries per player, use mode\n",
        "lookup_2025 = (\n",
        "    mp_small.dropna(subset=[\"Name_norm\", \"Position_from_2025\"])\n",
        "            .groupby(\"Name_norm\")[\"Position_from_2025\"]\n",
        "            .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0])\n",
        "            .reset_index()\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Combine lookups -> master\n",
        "# Priority: 2025 mapping overrides 2023 if conflict\n",
        "# ----------------------------\n",
        "master = lookup_2023.merge(lookup_2025, on=\"Name_norm\", how=\"outer\")\n",
        "\n",
        "master[\"Position_master\"] = master[\"Position_from_2025\"].combine_first(master[\"Position_from_2023\"])\n",
        "\n",
        "# Optional: keep a representative display Name for readability (prefer 2025)\n",
        "name_ref_2025 = mp_small.dropna(subset=[\"Name_norm\"]).drop_duplicates(\"Name_norm\")[[\"Name_norm\", \"Name\"]].rename(columns={\"Name\": \"Name_ref_2025\"})\n",
        "name_ref_2023 = box_small.dropna(subset=[\"Name_norm\"]).drop_duplicates(\"Name_norm\")[[\"Name_norm\", \"Name\"]].rename(columns={\"Name\": \"Name_ref_2023\"})\n",
        "\n",
        "master = master.merge(name_ref_2025, on=\"Name_norm\", how=\"left\").merge(name_ref_2023, on=\"Name_norm\", how=\"left\")\n",
        "master[\"Name\"] = master[\"Name_ref_2025\"].combine_first(master[\"Name_ref_2023\"])\n",
        "\n",
        "master_export = master[[\"Name_norm\", \"Name\", \"Position_master\", \"Position_from_2025\", \"Position_from_2023\"]].copy()\n",
        "master_export = master_export.sort_values([\"Position_master\", \"Name\"]).reset_index(drop=True)\n",
        "\n",
        "# Export master mapping\n",
        "master_export.to_csv(OUT_MASTER, index=False)\n",
        "print(\"✅ Wrote master mapping:\", OUT_MASTER)\n",
        "print(\"Master mapping coverage:\", master_export[\"Position_master\"].notna().mean())\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Apply master mapping to totals\n",
        "# Priority: existing totals Position > master mapping\n",
        "# ----------------------------\n",
        "totals2 = totals.merge(\n",
        "    master_export[[\"Name_norm\", \"Position_master\"]],\n",
        "    on=\"Name_norm\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# If totals already had Position, keep it; else fill from master\n",
        "if \"Position\" in totals2.columns:\n",
        "    totals2[\"Position\"] = totals2[\"Position\"].combine_first(totals2[\"Position_master\"])\n",
        "else:\n",
        "    totals2[\"Position\"] = totals2[\"Position_master\"]\n",
        "\n",
        "totals2 = totals2.drop(columns=[\"Position_master\"])\n",
        "\n",
        "# Report missing after fill\n",
        "missing_pct = totals2[\"Position\"].isna().mean()\n",
        "missing_n = totals2[\"Position\"].isna().sum()\n",
        "print(f\"✅ Totals rows: {len(totals2)}\")\n",
        "print(f\"✅ Missing Position after fill: {missing_n} ({missing_pct:.1%})\")\n",
        "\n",
        "# Export updated totals\n",
        "totals2.to_csv(OUT_TOTALS, index=False)\n",
        "print(\"✅ Wrote updated totals:\", OUT_TOTALS)\n",
        "\n",
        "# Also give you the remaining missing names to patch later\n",
        "missing_names = (\n",
        "    totals2.loc[totals2[\"Position\"].isna(), \"Name\"]\n",
        "           .dropna()\n",
        "           .drop_duplicates()\n",
        "           .sort_values()\n",
        "           .tolist()\n",
        ")\n",
        "print(f\"\\nPlayers still missing Position: {len(missing_names)}\")\n",
        "print(missing_names[:50])  # preview first 50\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbxGMg4H9njG",
        "outputId": "bb826371-3a72-49ba-ac78-5da975f92fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote master mapping: /content/processed_positions/position_mapping_master.csv\n",
            "Master mapping coverage: 1.0\n",
            "✅ Totals rows: 257\n",
            "✅ Missing Position after fill: 20 (7.8%)\n",
            "✅ Wrote updated totals: /content/processed_positions/pbpstats_totals_cleaned_with_positions.csv\n",
            "\n",
            "Players still missing Position: 20\n",
            "['Amy Atwell', 'Asia (AD) Durr', 'Astou Ndour-Fall', 'Betnijah Laney-Hamilton', 'Caitlin Bickle', 'Celeste Taylor', 'Charisma Osborne', 'Chennedy Carter', 'Cyesha Goree', 'DiDi Richards', 'Dyaisha Fair', 'Ezinne Kalu', 'Jakia Brown-Turner', 'Jessika Carter', 'Kaela Davis', 'Kysre Gondrezick', 'Mikiah Herbert Harrigan', 'Nika Mühl', 'Olivia Époupa', 'Stephanie Soares']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "TOTALS_BY_SEASON_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season.csv\")\n",
        "MASTER_MAP_PATH       = Path(\"/content/processed_positions/position_mapping_master.csv\")\n",
        "\n",
        "OUT_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions.csv\")\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "# ----------------------------\n",
        "# Load data\n",
        "# ----------------------------\n",
        "df = pd.read_csv(TOTALS_BY_SEASON_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "mp = pd.read_csv(MASTER_MAP_PATH)\n",
        "mp.columns = [c.strip() for c in mp.columns]\n",
        "\n",
        "# Ensure expected columns\n",
        "if \"Name\" not in df.columns:\n",
        "    raise ValueError(f\"Totals file missing Name. Found: {df.columns.tolist()[:50]}\")\n",
        "if \"Season\" not in df.columns:\n",
        "    raise ValueError(f\"Totals file missing Season. Found: {df.columns.tolist()[:50]}\")\n",
        "\n",
        "# Normalize join keys\n",
        "df = df.copy()\n",
        "df[\"Name_norm\"] = df[\"Name\"].apply(norm_name)\n",
        "\n",
        "mp = mp.copy()\n",
        "if \"Name_norm\" not in mp.columns:\n",
        "    if \"Name\" not in mp.columns:\n",
        "        raise ValueError(f\"Mapping missing Name/Name_norm. Found: {mp.columns.tolist()[:50]}\")\n",
        "    mp[\"Name_norm\"] = mp[\"Name\"].apply(norm_name)\n",
        "\n",
        "# Identify which position column exists in the mapping\n",
        "pos_col = None\n",
        "for cand in [\"Position_master\", \"Position\", \"Pos\"]:\n",
        "    if cand in mp.columns:\n",
        "        pos_col = cand\n",
        "        break\n",
        "if not pos_col:\n",
        "    raise ValueError(f\"Mapping missing a position column (Position_master/Position/Pos). Found: {mp.columns.tolist()[:50]}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Season-aware merge if possible\n",
        "# (only if mapping has Season)\n",
        "# ----------------------------\n",
        "if \"Season\" in mp.columns:\n",
        "    # Best case: map by Name_norm + Season\n",
        "    mp_season = (\n",
        "        mp.dropna(subset=[\"Name_norm\", pos_col, \"Season\"])\n",
        "          .drop_duplicates(subset=[\"Name_norm\", \"Season\"])\n",
        "          [[\"Name_norm\", \"Season\", pos_col]]\n",
        "          .rename(columns={pos_col: \"Position_from_map\"})\n",
        "    )\n",
        "\n",
        "    merged = df.merge(mp_season, on=[\"Name_norm\", \"Season\"], how=\"left\")\n",
        "\n",
        "    # Fallback to Name-only (in case season-specific is missing)\n",
        "    mp_name = (\n",
        "        mp.dropna(subset=[\"Name_norm\", pos_col])\n",
        "          .groupby(\"Name_norm\")[pos_col]\n",
        "          .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0])\n",
        "          .reset_index()\n",
        "          .rename(columns={pos_col: \"Position_from_map_name\"})\n",
        "    )\n",
        "\n",
        "    merged = merged.merge(mp_name, on=\"Name_norm\", how=\"left\")\n",
        "    merged[\"Position\"] = merged[\"Position_from_map\"].combine_first(merged[\"Position_from_map_name\"])\n",
        "    merged = merged.drop(columns=[\"Position_from_map\", \"Position_from_map_name\"])\n",
        "\n",
        "else:\n",
        "    # Map by Name_norm only (your current master mapping)\n",
        "    mp_name = (\n",
        "        mp.dropna(subset=[\"Name_norm\", pos_col])\n",
        "          .drop_duplicates(subset=[\"Name_norm\"])\n",
        "          [[\"Name_norm\", pos_col]]\n",
        "          .rename(columns={pos_col: \"Position\"})\n",
        "    )\n",
        "    merged = df.merge(mp_name, on=\"Name_norm\", how=\"left\")\n",
        "\n",
        "# ----------------------------\n",
        "# Reporting\n",
        "# ----------------------------\n",
        "missing_n = merged[\"Position\"].isna().sum()\n",
        "missing_pct = merged[\"Position\"].isna().mean()\n",
        "\n",
        "print(f\"✅ Rows: {len(merged)}\")\n",
        "print(f\"✅ Missing Position: {missing_n} ({missing_pct:.1%})\")\n",
        "\n",
        "# Who is still missing? (unique names + how many seasons affected)\n",
        "missing_summary = (\n",
        "    merged.loc[merged[\"Position\"].isna(), [\"Name\", \"Season\"]]\n",
        "          .drop_duplicates()\n",
        "          .groupby(\"Name\")[\"Season\"]\n",
        "          .agg([\"count\", lambda s: sorted(s.unique())])\n",
        "          .reset_index()\n",
        ")\n",
        "missing_summary.columns = [\"Name\", \"Seasons_missing_count\", \"Seasons_missing_list\"]\n",
        "\n",
        "display(missing_summary.sort_values([\"Seasons_missing_count\", \"Name\"], ascending=[False, True]).head(50))\n",
        "\n",
        "# Save output\n",
        "merged.to_csv(OUT_PATH, index=False)\n",
        "print(\"✅ Wrote:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "Va5giGKmB4We",
        "outputId": "579b4701-e16c-4f40-ec30-d1f7821f93b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Rows: 495\n",
            "✅ Missing Position: 20 (4.0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       Name  Seasons_missing_count Seasons_missing_list\n",
              "0                Amy Atwell                      1               [2024]\n",
              "1            Asia (AD) Durr                      1               [2023]\n",
              "2          Astou Ndour-Fall                      1               [2024]\n",
              "3   Betnijah Laney-Hamilton                      1               [2024]\n",
              "4            Caitlin Bickle                      1               [2024]\n",
              "5            Celeste Taylor                      1               [2024]\n",
              "6          Charisma Osborne                      1               [2024]\n",
              "7           Chennedy Carter                      1               [2024]\n",
              "8              Cyesha Goree                      1               [2023]\n",
              "9             DiDi Richards                      1               [2024]\n",
              "10             Dyaisha Fair                      1               [2024]\n",
              "11              Ezinne Kalu                      1               [2024]\n",
              "12       Jakia Brown-Turner                      1               [2024]\n",
              "13           Jessika Carter                      1               [2024]\n",
              "14              Kaela Davis                      1               [2024]\n",
              "15         Kysre Gondrezick                      1               [2024]\n",
              "16  Mikiah Herbert Harrigan                      1               [2024]\n",
              "17                Nika Mühl                      1               [2024]\n",
              "18            Olivia Époupa                      1               [2024]\n",
              "19         Stephanie Soares                      1               [2024]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a82aca3-58f2-4628-8a64-64d232a9b97e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Seasons_missing_count</th>\n",
              "      <th>Seasons_missing_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amy Atwell</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Asia (AD) Durr</td>\n",
              "      <td>1</td>\n",
              "      <td>[2023]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Astou Ndour-Fall</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Betnijah Laney-Hamilton</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Caitlin Bickle</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Celeste Taylor</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Charisma Osborne</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Chennedy Carter</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Cyesha Goree</td>\n",
              "      <td>1</td>\n",
              "      <td>[2023]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>DiDi Richards</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Dyaisha Fair</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Ezinne Kalu</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Jakia Brown-Turner</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Jessika Carter</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Kaela Davis</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Kysre Gondrezick</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Mikiah Herbert Harrigan</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Nika Mühl</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Olivia Époupa</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Stephanie Soares</td>\n",
              "      <td>1</td>\n",
              "      <td>[2024]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a82aca3-58f2-4628-8a64-64d232a9b97e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a82aca3-58f2-4628-8a64-64d232a9b97e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a82aca3-58f2-4628-8a64-64d232a9b97e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-409c9f97-2414-401b-a844-c0421c43231a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-409c9f97-2414-401b-a844-c0421c43231a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-409c9f97-2414-401b-a844-c0421c43231a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Wrote:\\\", OUT_PATH)\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Amy Atwell\",\n          \"Nika M\\u00fchl\",\n          \"Kysre Gondrezick\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seasons_missing_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seasons_missing_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote: /content/processed_positions/pbpstats_totals_player_by_season_with_positions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "IN_PATH  = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions.csv\")\n",
        "OUT_PATH = Path(\"/content/processed_positions/missing_positions_summary.csv\")\n",
        "\n",
        "df = pd.read_csv(IN_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Detect GP column name (PBPStats sometimes varies)\n",
        "gp_col = None\n",
        "for cand in [\"GamesPlayed\", \"GP\", \"games_played\"]:\n",
        "    if cand in df.columns:\n",
        "        gp_col = cand\n",
        "        break\n",
        "if not gp_col:\n",
        "    raise ValueError(f\"Couldn't find a games played column. Columns include: {df.columns.tolist()[:40]}\")\n",
        "\n",
        "# Ensure Position exists\n",
        "if \"Position\" not in df.columns:\n",
        "    raise ValueError(\"Expected a 'Position' column in the merged file.\")\n",
        "\n",
        "# Filter missing positions\n",
        "miss = df[df[\"Position\"].isna()].copy()\n",
        "\n",
        "# (optional) make GP numeric\n",
        "miss[gp_col] = pd.to_numeric(miss[gp_col], errors=\"coerce\")\n",
        "\n",
        "# Table of missing rows (name + season + GP)\n",
        "missing_rows = (\n",
        "    miss[[\"Name\", \"Season\", gp_col]]\n",
        "      .drop_duplicates()\n",
        "      .sort_values([\"Name\", \"Season\"])\n",
        "      .rename(columns={gp_col: \"GamesPlayed\"})\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Summary per player:\n",
        "# - list of seasons missing\n",
        "# - list of games played in those seasons (aligned)\n",
        "# - total GP across missing seasons (nice for triage)\n",
        "summary = (\n",
        "    missing_rows.groupby(\"Name\")\n",
        "    .agg(\n",
        "        Seasons_missing_list=(\"Season\", lambda s: sorted(s.tolist())),\n",
        "        GamesPlayed_by_season=(\"GamesPlayed\", lambda s: s.fillna(0).astype(int).tolist()),\n",
        "        TotalGamesPlayed_missing=(\"GamesPlayed\", lambda s: int(s.fillna(0).sum())),\n",
        "        Seasons_missing_count=(\"Season\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values([\"TotalGamesPlayed_missing\", \"Seasons_missing_count\", \"Name\"], ascending=[True, False, True])\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "display(summary)\n",
        "\n",
        "# Quick “likely safe to ignore” check: total GP == 0\n",
        "zero_gp = summary[summary[\"TotalGamesPlayed_missing\"] == 0]\n",
        "print(f\"Players missing Position with 0 GP in missing seasons: {len(zero_gp)} / {len(summary)}\")\n",
        "\n",
        "# Export\n",
        "summary.to_csv(OUT_PATH, index=False)\n",
        "print(\"✅ wrote:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZtWC71VJDk6I",
        "outputId": "ebd717d3-05a8-4f53-95c9-19a2aca82d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       Name Seasons_missing_list GamesPlayed_by_season  \\\n",
              "0              Dyaisha Fair               [2024]                   [1]   \n",
              "1               Ezinne Kalu               [2024]                   [1]   \n",
              "2          Charisma Osborne               [2024]                   [2]   \n",
              "3        Jakia Brown-Turner               [2024]                   [2]   \n",
              "4            Jessika Carter               [2024]                   [2]   \n",
              "5               Kaela Davis               [2024]                   [4]   \n",
              "6          Kysre Gondrezick               [2024]                   [5]   \n",
              "7                Amy Atwell               [2024]                   [6]   \n",
              "8            Caitlin Bickle               [2024]                   [8]   \n",
              "9              Cyesha Goree               [2023]                  [10]   \n",
              "10                Nika Mühl               [2024]                  [16]   \n",
              "11            Olivia Époupa               [2024]                  [17]   \n",
              "12            DiDi Richards               [2024]                  [20]   \n",
              "13         Astou Ndour-Fall               [2024]                  [22]   \n",
              "14           Celeste Taylor               [2024]                  [22]   \n",
              "15         Stephanie Soares               [2024]                  [22]   \n",
              "16  Betnijah Laney-Hamilton               [2024]                  [28]   \n",
              "17  Mikiah Herbert Harrigan               [2024]                  [31]   \n",
              "18          Chennedy Carter               [2024]                  [33]   \n",
              "19           Asia (AD) Durr               [2023]                  [36]   \n",
              "\n",
              "    TotalGamesPlayed_missing  Seasons_missing_count  \n",
              "0                          1                      1  \n",
              "1                          1                      1  \n",
              "2                          2                      1  \n",
              "3                          2                      1  \n",
              "4                          2                      1  \n",
              "5                          4                      1  \n",
              "6                          5                      1  \n",
              "7                          6                      1  \n",
              "8                          8                      1  \n",
              "9                         10                      1  \n",
              "10                        16                      1  \n",
              "11                        17                      1  \n",
              "12                        20                      1  \n",
              "13                        22                      1  \n",
              "14                        22                      1  \n",
              "15                        22                      1  \n",
              "16                        28                      1  \n",
              "17                        31                      1  \n",
              "18                        33                      1  \n",
              "19                        36                      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e193d2ad-b094-4cb4-b911-316517b11330\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Seasons_missing_list</th>\n",
              "      <th>GamesPlayed_by_season</th>\n",
              "      <th>TotalGamesPlayed_missing</th>\n",
              "      <th>Seasons_missing_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dyaisha Fair</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ezinne Kalu</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Charisma Osborne</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[2]</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jakia Brown-Turner</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[2]</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jessika Carter</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[2]</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kaela Davis</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[4]</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kysre Gondrezick</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[5]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Amy Atwell</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[6]</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Caitlin Bickle</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[8]</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Cyesha Goree</td>\n",
              "      <td>[2023]</td>\n",
              "      <td>[10]</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Nika Mühl</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[16]</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Olivia Époupa</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[17]</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>DiDi Richards</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[20]</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Astou Ndour-Fall</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[22]</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Celeste Taylor</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[22]</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Stephanie Soares</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[22]</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Betnijah Laney-Hamilton</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[28]</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Mikiah Herbert Harrigan</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[31]</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Chennedy Carter</td>\n",
              "      <td>[2024]</td>\n",
              "      <td>[33]</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Asia (AD) Durr</td>\n",
              "      <td>[2023]</td>\n",
              "      <td>[36]</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e193d2ad-b094-4cb4-b911-316517b11330')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e193d2ad-b094-4cb4-b911-316517b11330 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e193d2ad-b094-4cb4-b911-316517b11330');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4273bacb-05d4-4902-8948-4deb0dd78f66\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4273bacb-05d4-4902-8948-4deb0dd78f66')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4273bacb-05d4-4902-8948-4deb0dd78f66 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_89ecb24b-1f3f-43da-af2a-2540fd7864cd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_89ecb24b-1f3f-43da-af2a-2540fd7864cd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Dyaisha Fair\",\n          \"Mikiah Herbert Harrigan\",\n          \"Stephanie Soares\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seasons_missing_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GamesPlayed_by_season\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalGamesPlayed_missing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1,\n        \"max\": 36,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          20,\n          28,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seasons_missing_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Players missing Position with 0 GP in missing seasons: 0 / 20\n",
            "✅ wrote: /content/processed_positions/missing_positions_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions.csv\")\n",
        "MAP_PATH  = Path(\"/content/processed_positions/position_mapping_master.csv\")\n",
        "\n",
        "OUT_PATH  = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions_exactpatch.csv\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "mp = pd.read_csv(MAP_PATH)\n",
        "\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "mp.columns = [c.strip() for c in mp.columns]\n",
        "\n",
        "# Detect mapping name + position columns (flexible)\n",
        "name_col_map = \"Name\" if \"Name\" in mp.columns else None\n",
        "if not name_col_map:\n",
        "    raise ValueError(f\"Mapping file doesn't have a 'Name' column. Found: {mp.columns.tolist()[:40]}\")\n",
        "\n",
        "pos_col_map = None\n",
        "for cand in [\"Position_master\", \"Position\", \"Pos\"]:\n",
        "    if cand in mp.columns:\n",
        "        pos_col_map = cand\n",
        "        break\n",
        "if not pos_col_map:\n",
        "    raise ValueError(f\"Mapping file doesn't have a position column. Found: {mp.columns.tolist()[:40]}\")\n",
        "\n",
        "# 1) find missing names in df\n",
        "missing_names = (\n",
        "    df.loc[df[\"Position\"].isna(), \"Name\"]\n",
        "      .dropna()\n",
        "      .drop_duplicates()\n",
        "      .tolist()\n",
        ")\n",
        "\n",
        "print(f\"Missing names (unique): {len(missing_names)}\")\n",
        "\n",
        "# 2) create a mapping dict using ONLY exact Name (no normalization)\n",
        "mp_exact = (\n",
        "    mp.dropna(subset=[name_col_map, pos_col_map])\n",
        "      .drop_duplicates(subset=[name_col_map])\n",
        "      [[name_col_map, pos_col_map]]\n",
        "      .rename(columns={name_col_map: \"Name\", pos_col_map: \"Position_exact\"})\n",
        ")\n",
        "\n",
        "exact_map = dict(zip(mp_exact[\"Name\"], mp_exact[\"Position_exact\"]))\n",
        "\n",
        "# 3) apply only to rows where Position is missing AND Name is in the missing list\n",
        "mask = df[\"Position\"].isna() & df[\"Name\"].isin(missing_names)\n",
        "before = df.loc[mask, \"Position\"].isna().sum()\n",
        "\n",
        "df.loc[mask, \"Position\"] = df.loc[mask, \"Name\"].map(exact_map)\n",
        "\n",
        "after = df.loc[mask, \"Position\"].isna().sum()\n",
        "\n",
        "print(f\"✅ Exact-patch filled: {before - after} rows (of {before} missing rows)\")\n",
        "\n",
        "# 4) show who is still missing (unique names)\n",
        "still_missing = (\n",
        "    df.loc[df[\"Position\"].isna(), \"Name\"]\n",
        "      .dropna()\n",
        "      .drop_duplicates()\n",
        "      .sort_values()\n",
        "      .tolist()\n",
        ")\n",
        "\n",
        "print(f\"Still missing after exact patch: {len(still_missing)}\")\n",
        "print(still_missing)\n",
        "\n",
        "# Save output\n",
        "df.to_csv(OUT_PATH, index=False)\n",
        "print(\"✅ wrote:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy_376OlElr5",
        "outputId": "b160d0de-fc84-46c8-9219-41009cef972e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing names (unique): 20\n",
            "✅ Exact-patch filled: 0 rows (of 20 missing rows)\n",
            "Still missing after exact patch: 20\n",
            "['Amy Atwell', 'Asia (AD) Durr', 'Astou Ndour-Fall', 'Betnijah Laney-Hamilton', 'Caitlin Bickle', 'Celeste Taylor', 'Charisma Osborne', 'Chennedy Carter', 'Cyesha Goree', 'DiDi Richards', 'Dyaisha Fair', 'Ezinne Kalu', 'Jakia Brown-Turner', 'Jessika Carter', 'Kaela Davis', 'Kysre Gondrezick', 'Mikiah Herbert Harrigan', 'Nika Mühl', 'Olivia Époupa', 'Stephanie Soares']\n",
            "✅ wrote: /content/processed_positions/pbpstats_totals_player_by_season_with_positions_exactpatch.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "IN_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions.csv\")\n",
        "OUT_DIR = Path(\"/content/processed_positions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_CLEAN = OUT_DIR / \"pbpstats_totals_player_by_season_cleaned_pre_percentiles.csv\"\n",
        "OUT_RENAME_MAP = OUT_DIR / \"pbpstats_column_rename_map.csv\"\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def to_snake(name: str) -> str:\n",
        "    s = str(name).strip().lower()\n",
        "    s = re.sub(r\"[^\\w]+\", \"_\", s)          # non-word -> underscore\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")  # collapse underscores\n",
        "    if re.match(r\"^\\d\", s):               # can't start with a digit in some SQL engines\n",
        "        s = f\"c_{s}\"\n",
        "    return s\n",
        "\n",
        "def make_unique(cols):\n",
        "    seen = {}\n",
        "    out = []\n",
        "    for c in cols:\n",
        "        if c not in seen:\n",
        "            seen[c] = 0\n",
        "            out.append(c)\n",
        "        else:\n",
        "            seen[c] += 1\n",
        "            out.append(f\"{c}_{seen[c]}\")\n",
        "    return out\n",
        "\n",
        "def first_existing(df, candidates):\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in lower:\n",
        "            return lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "# -------------------------\n",
        "# Load\n",
        "# -------------------------\n",
        "df = pd.read_csv(IN_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Basic required columns (flexible)\n",
        "name_col   = first_existing(df, [\"Name\", \"Player\", \"player\"])\n",
        "season_col = first_existing(df, [\"Season\"])\n",
        "team_col   = first_existing(df, [\"TeamAbbreviation\", \"Team_Abbreviation\", \"Team\"])\n",
        "gp_col     = first_existing(df, [\"GamesPlayed\", \"GP\"])\n",
        "\n",
        "if not name_col or not season_col:\n",
        "    raise ValueError(f\"Missing required columns. Found columns: {df.columns.tolist()[:40]}\")\n",
        "\n",
        "# Normalize core column names (keep originals for now)\n",
        "rename_core = {name_col: \"Name\", season_col: \"Season\"}\n",
        "if team_col: rename_core[team_col] = \"TeamAbbreviation\"\n",
        "if gp_col: rename_core[gp_col] = \"GamesPlayed\"\n",
        "df = df.rename(columns=rename_core)\n",
        "\n",
        "# Ensure Season numeric\n",
        "df[\"Season\"] = pd.to_numeric(df[\"Season\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "# Strip string columns\n",
        "for c in df.columns:\n",
        "    if df[c].dtype == \"object\":\n",
        "        df[c] = df[c].astype(str).str.strip().replace({\"\": pd.NA, \"nan\": pd.NA, \"None\": pd.NA})\n",
        "\n",
        "# -------------------------\n",
        "# Convert numerics\n",
        "# -------------------------\n",
        "# Keep these as non-numeric explicitly\n",
        "non_numeric = {\"Name\", \"TeamAbbreviation\", \"Position\", \"Name_norm\"}\n",
        "for c in df.columns:\n",
        "    if c in non_numeric:\n",
        "        continue\n",
        "    # Try numeric conversion; if it creates a lot of NaNs, keep original\n",
        "    if df[c].dtype == \"object\":\n",
        "        converted = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        # If at least 70% of non-null values become numeric, accept it\n",
        "        non_null = df[c].notna().sum()\n",
        "        became_num = converted.notna().sum()\n",
        "        if non_null == 0 or (became_num / max(non_null, 1) >= 0.70):\n",
        "            df[c] = converted\n",
        "\n",
        "# -------------------------\n",
        "# Dedupe (optional but helpful)\n",
        "# -------------------------\n",
        "dedupe_keys = [\"Name\", \"Season\"]\n",
        "if \"TeamAbbreviation\" in df.columns:\n",
        "    dedupe_keys.append(\"TeamAbbreviation\")\n",
        "\n",
        "before = len(df)\n",
        "df = df.drop_duplicates(subset=dedupe_keys, keep=\"first\")\n",
        "after = len(df)\n",
        "\n",
        "# -------------------------\n",
        "# “Standard” helper calcs (safe + low drama)\n",
        "# -------------------------\n",
        "if \"Minutes\" in df.columns and \"GamesPlayed\" in df.columns:\n",
        "    df[\"minutes_per_game\"] = np.where(\n",
        "        (df[\"GamesPlayed\"].fillna(0) > 0),\n",
        "        df[\"Minutes\"] / df[\"GamesPlayed\"],\n",
        "        np.nan\n",
        "    )\n",
        "\n",
        "# -------------------------\n",
        "# Percent / rate rounding (3 decimals)\n",
        "# Also convert 0–100 -> 0–1 when it looks like percentages\n",
        "# -------------------------\n",
        "pct_keywords = (\"pct\", \"percent\", \"percentage\")\n",
        "rate_keywords = (\"rate\", \"ppp\", \"per_poss\", \"perposs\", \"per100\", \"per_100\")\n",
        "\n",
        "def is_pct_like(colname: str) -> bool:\n",
        "    s = colname.lower()\n",
        "    return any(k in s for k in pct_keywords) or s.endswith(\"%\")\n",
        "\n",
        "def is_rate_like(colname: str) -> bool:\n",
        "    s = colname.lower()\n",
        "    return any(k in s for k in rate_keywords)\n",
        "\n",
        "for c in df.columns:\n",
        "    if c in non_numeric:\n",
        "        continue\n",
        "    if not (is_pct_like(c) or is_rate_like(c)):\n",
        "        continue\n",
        "    if not pd.api.types.is_numeric_dtype(df[c]):\n",
        "        continue\n",
        "\n",
        "    s = df[c].astype(float)\n",
        "\n",
        "    # If it looks like 0–100 percentages, convert to 0–1\n",
        "    mx = s.dropna().max() if s.notna().any() else np.nan\n",
        "    mn = s.dropna().min() if s.notna().any() else np.nan\n",
        "    if pd.notna(mx) and pd.notna(mn) and mn >= 0 and mx <= 100 and mx > 1.5:\n",
        "        s = s / 100.0\n",
        "\n",
        "    df[c] = s.round(3)\n",
        "\n",
        "# -------------------------\n",
        "# BigQuery-friendly column names (snake_case)\n",
        "# -------------------------\n",
        "snake_cols = [to_snake(c) for c in df.columns]\n",
        "snake_cols = make_unique(snake_cols)\n",
        "\n",
        "rename_map = pd.DataFrame({\"original_column\": df.columns.tolist(), \"clean_column\": snake_cols})\n",
        "df.columns = snake_cols\n",
        "\n",
        "# -------------------------\n",
        "# Save outputs\n",
        "# -------------------------\n",
        "df.to_csv(OUT_CLEAN, index=False)\n",
        "rename_map.to_csv(OUT_RENAME_MAP, index=False)\n",
        "\n",
        "print(\"✅ Input rows:\", before)\n",
        "print(\"✅ Output rows (after dedupe):\", after)\n",
        "print(\"✅ Wrote cleaned file:\", OUT_CLEAN)\n",
        "print(\"✅ Wrote rename map:\", OUT_RENAME_MAP)\n",
        "\n",
        "# Quick sanity checks\n",
        "pos_col = \"position\" if \"position\" in df.columns else None\n",
        "if pos_col:\n",
        "    print(\"✅ Missing position %:\", float(pd.isna(df[pos_col]).mean()))\n",
        "if \"gamesplayed\" in df.columns:\n",
        "    print(\"✅ Rows with 0 games:\", int((df[\"gamesplayed\"].fillna(0) == 0).sum()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lLGaXdtI3bf",
        "outputId": "5730e820-3d29-4126-94ff-a4ef44101b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Input rows: 495\n",
            "✅ Output rows (after dedupe): 495\n",
            "✅ Wrote cleaned file: /content/processed_positions/pbpstats_totals_player_by_season_cleaned_pre_percentiles.csv\n",
            "✅ Wrote rename map: /content/processed_positions/pbpstats_column_rename_map.csv\n",
            "✅ Missing position %: 0.04040404040404041\n",
            "✅ Rows with 0 games: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###############################################\n",
        "# 2. Aggregation / Cleaning\n",
        "###############################################\n",
        "\n",
        "################ OKAY TO OMIT THIS SECTION below WHEN USING PBPSTATS DATA? ###########\n",
        "\n",
        "# We aggregate game-log level data into season totals for each player\n",
        "player_season_stats <- raw_box %>%\n",
        "  # Ensure minutes are numeric (sometimes they come as strings)\n",
        "  mutate(minutes = as.numeric(minutes)) %>%\n",
        "  group_by(athlete_id, athlete_display_name, team_short_display_name, athlete_position_abbreviation, season) %>% # Added 'season' here\n",
        "  summarise(\n",
        "    games_played  = n(),\n",
        "    games_started = sum(starter, na.rm = TRUE),\n",
        "    minutes_total = sum(minutes, na.rm = TRUE),\n",
        "\n",
        "    # Counting stats\n",
        "    pts_total     = sum(points, na.rm = TRUE),\n",
        "    reb_total     = sum(rebounds, na.rm = TRUE),\n",
        "    oreb_total    = sum(offensive_rebounds, na.rm = TRUE),\n",
        "    dreb_total    = sum(defensive_rebounds, na.rm = TRUE),\n",
        "    ast_total     = sum(assists, na.rm = TRUE),\n",
        "    stl_total     = sum(steals, na.rm = TRUE),\n",
        "    blk_total     = sum(blocks, na.rm = TRUE),\n",
        "    tov_total     = sum(turnovers, na.rm = TRUE),\n",
        "\n",
        "    # Shooting totals\n",
        "    fgm  = sum(field_goals_made, na.rm = TRUE),\n",
        "    fga  = sum(field_goals_attempted, na.rm = TRUE),\n",
        "    fg3m = sum(three_point_field_goals_made, na.rm = TRUE),\n",
        "    fg3a = sum(three_point_goals_attempted, na.rm = TRUE),\n",
        "    ftm  = sum(free_throws_made, na.rm = TRUE),\n",
        "    fta  = sum(free_throws_attempted, na.rm = TRUE),\n",
        "\n",
        "    .groups = \"drop\"\n",
        "  ) %>%\n",
        "\n",
        "################ OKAY TO OMIT THIS SECTION above WHEN USING PBPSTATS DATA? ###########\n",
        "\n",
        "# Basic per-game and per-40 calculations\n",
        "  mutate(\n",
        "    mpg = minutes_total / games_played,\n",
        "    ppg = pts_total / games_played,\n",
        "    rpg = reb_total / games_played,\n",
        "    apg = ast_total / games_played,\n",
        "    spg = stl_total / games_played,\n",
        "    bpg = blk_total / games_played,\n",
        "    tovpg = tov_total / games_played,\n",
        "\n",
        "    # Per 40 Mins (Normalize for playing time)\n",
        "    # Avoid division by zero with pmax\n",
        "    pts_per_40  = (pts_total / pmax(minutes_total, 1)) * 40,\n",
        "    reb_per_40  = (reb_total / pmax(minutes_total, 1)) * 40,\n",
        "    oreb_per_40 = (oreb_total / pmax(minutes_total, 1)) * 40,\n",
        "    dreb_per_40 = (dreb_total / pmax(minutes_total, 1)) * 40,\n",
        "    ast_per_40  = (ast_total / pmax(minutes_total, 1)) * 40,\n",
        "    stl_per_40  = (stl_total / pmax(minutes_total, 1)) * 40,\n",
        "    blk_per_40  = (blk_total / pmax(minutes_total, 1)) * 40,\n",
        "    tov_per_40  = (tov_total / pmax(minutes_total, 1)) * 40\n",
        "  ) %>%n  # Efficiency & Advanced Metrics\n",
        "  mutate(\n",
        "    # Shooting Percentages\n",
        "    fg_pct  = ifelse(fga > 0, fgm / fga, 0),\n",
        "    fg3_pct = ifelse(fg3a > 0, fg3m / fg3a, 0),\n",
        "    ft_pct  = ifelse(fta > 0, ftm / fta, 0),\n",
        "\n",
        "    # Three Point Attempt Rate\n",
        "    threepar = ifelse(fga > 0, fg3a / fga, 0),\n",
        "\n",
        "    # Free Throw Attempt Rate\n",
        "    fta_rate = ifelse(fga > 0, fta / fga, 0),\n",
        "\n",
        "    # Effective Field Goal %\n",
        "    efg_pct = ifelse(fga > 0, (fgm + 0.5 * fg3m) / fga, 0),\n",
        "\n",
        "    # True Shooting %\n",
        "    # Approximation: TSA = FGA + 0.44 * FTA\n",
        "    ts_pct = ifelse((fga + 0.44 * fta) > 0,\n",
        "                    pts_total / (2 * (fga + 0.44 * fta)), 0),\n",
        "\n",
        "    # Usage Rate (Approximate Version)\n",
        "    # Basic Formula: (FGA + 0.44*FTA + TOV) / (Minutes) * (Team Minutes / 5)\n",
        "    # Since we don't have team totals here, we calculate \"Usage Load\"\n",
        "    # and will treat it as a proxy or raw usage volume.\n",
        "    usage_load = (fga + 0.44 * fta + tov_total),\n",
        "    usage      = usage_load / pmax(minutes_total, 1), # possessions used per minute\n",
        "\n",
        "    # Ratio Stats\n",
        "    ast_to_tov = ifelse(tov_total > 0, ast_total / tov_total, ast_total),\n",
        "\n",
        "    # Estimated percentages (Simplified without team totals)\n",
        "    # e.g., ast_pct ~ Ast / (FGA + 0.44*FTA + Ast + TOV)\n",
        "    # This is a 'player-based' approximation often used when team totals aren't joined.\n",
        "    possessions_estimated = fga + 0.44 * fta + tov_total + ast_total,\n",
        "    ast_pct  = ifelse(possessions_estimated > 0, ast_total / possessions_estimated, 0),\n",
        "    tov_pct  = ifelse(possessions_estimated > 0, tov_total / possessions_estimated, 0),\n",
        "\n",
        "    # Rebounding Shares (Approximation using per-40/position baselines is common if team totals missing)\n",
        "    # Here we will just stick to the per-40 or total counts unless we join team data.\n",
        "    # For the lab, we'll create simple ratios:\n",
        "    oreb_pct = oreb_total / pmax(reb_total, 1), # % of player's rebs that were offensive\n",
        "    dreb_pct = dreb_total / pmax(reb_total, 1)  # % of player's rebs that were defensive\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "JFPi2STbJyg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# PBPStats Totals (by season) -> Derived Metrics\n",
        "#   - per game\n",
        "#   - per 40 minutes\n",
        "#   - per 100 possessions (if possessions exists; else uses an estimated possessions proxy)\n",
        "#   - shooting %s, 3PAr, FTr, eFG%, TS%, AST:TOV\n",
        "#\n",
        "# Input (you specified):\n",
        "#   /content/processed_positions/pbpstats_totals_player_by_season_cleaned_pre_percentiles.csv\n",
        "# Outputs:\n",
        "#   /content/processed_positions/pbpstats_totals_player_by_season_derived_pre_percentiles.csv\n",
        "#   /content/processed_positions/pbpstats_derived_column_rename_map.csv\n",
        "# ---------------------------------------------\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "IN_PATH  = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_cleaned_pre_percentiles.csv\")\n",
        "OUT_DIR  = Path(\"/content/processed_positions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_DATA = OUT_DIR / \"pbpstats_totals_player_by_season_derived_pre_percentiles.csv\"\n",
        "OUT_RENAME_MAP = OUT_DIR / \"pbpstats_derived_column_rename_map.csv\"\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def to_snake(name: str) -> str:\n",
        "    s = str(name).strip()\n",
        "    s = re.sub(r\"[^\\w]+\", \"_\", s)        # non-word -> underscore\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    s = s.lower()\n",
        "    if re.match(r\"^\\d\", s):\n",
        "        s = f\"c_{s}\"\n",
        "    return s\n",
        "\n",
        "def make_unique(cols):\n",
        "    seen = {}\n",
        "    out = []\n",
        "    for c in cols:\n",
        "        if c not in seen:\n",
        "            seen[c] = 0\n",
        "            out.append(c)\n",
        "        else:\n",
        "            seen[c] += 1\n",
        "            out.append(f\"{c}_{seen[c]}\")\n",
        "    return out\n",
        "\n",
        "def first_existing(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in lower:\n",
        "            return lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def safe_div(numer, denom):\n",
        "    denom = denom.replace(0, np.nan) if isinstance(denom, pd.Series) else (np.nan if denom == 0 else denom)\n",
        "    return numer / denom\n",
        "\n",
        "# -------------------------\n",
        "# 1) Load\n",
        "# -------------------------\n",
        "df_raw = pd.read_csv(IN_PATH)\n",
        "df_raw.columns = [c.strip() for c in df_raw.columns]\n",
        "\n",
        "# -------------------------\n",
        "# 2) Normalize column names to snake_case (BigQuery-friendly)\n",
        "# -------------------------\n",
        "rename_map = pd.DataFrame({\n",
        "    \"original_column\": df_raw.columns,\n",
        "    \"clean_column\": make_unique([to_snake(c) for c in df_raw.columns])\n",
        "})\n",
        "df = df_raw.copy()\n",
        "df.columns = rename_map[\"clean_column\"].tolist()\n",
        "\n",
        "rename_map.to_csv(OUT_RENAME_MAP, index=False)\n",
        "print(\"✅ wrote rename map:\", OUT_RENAME_MAP)\n",
        "\n",
        "# -------------------------\n",
        "# 3) Identify core columns (robust/flexible)\n",
        "# -------------------------\n",
        "# Required-ish identifiers\n",
        "col_name   = first_existing(df, [\"name\"])\n",
        "col_season = first_existing(df, [\"season\"])\n",
        "col_team   = first_existing(df, [\"teamabbreviation\", \"team_abbreviation\", \"team\"])\n",
        "col_pos    = first_existing(df, [\"position\", \"pos\"])\n",
        "\n",
        "# Common totals columns (best-effort matching)\n",
        "col_gp     = first_existing(df, [\"gamesplayed\", \"gp\", \"games_played\"])\n",
        "col_min    = first_existing(df, [\"minutes\", \"min\", \"minutes_total\"])\n",
        "\n",
        "# Box-style totals (some PBPStats exports use these; others use different labels)\n",
        "col_pts    = first_existing(df, [\"points\", \"pts\"])\n",
        "col_reb    = first_existing(df, [\"rebounds\", \"reb\", \"totalrebounds\", \"trb\"])\n",
        "col_oreb   = first_existing(df, [\"offensiverebounds\", \"oreb\"])\n",
        "col_dreb   = first_existing(df, [\"defensiverebounds\", \"dreb\"])\n",
        "col_ast    = first_existing(df, [\"assists\", \"ast\"])\n",
        "col_stl    = first_existing(df, [\"steals\", \"stl\"])\n",
        "col_blk    = first_existing(df, [\"blocks\", \"blk\"])\n",
        "col_tov    = first_existing(df, [\"turnovers\", \"tov\"])\n",
        "col_pf     = first_existing(df, [\"personalfouls\", \"pf\", \"fouls\"])\n",
        "\n",
        "# Shooting totals\n",
        "col_fgm    = first_existing(df, [\"fieldgoalsmade\", \"fgm\"])\n",
        "col_fga    = first_existing(df, [\"fieldgoalsattempted\", \"fga\"])\n",
        "col_fg3m   = first_existing(df, [\"threepointfieldgoalsmade\", \"fg3m\", \"3pm\"])\n",
        "col_fg3a   = first_existing(df, [\"threepointgoalsattempted\", \"fg3a\", \"3pa\"])\n",
        "col_ftm    = first_existing(df, [\"freethrowsmade\", \"ftm\"])\n",
        "col_fta    = first_existing(df, [\"freethrowsattempted\", \"fta\"])\n",
        "\n",
        "# Possessions (may or may not exist in your PBP totals export)\n",
        "col_poss   = first_existing(df, [\"possessions\", \"poss\", \"playerpossessions\", \"offensivepossessions\"])\n",
        "\n",
        "core_report = {\n",
        "    \"name\": col_name, \"season\": col_season, \"team\": col_team, \"position\": col_pos,\n",
        "    \"games_played\": col_gp, \"minutes\": col_min, \"possessions\": col_poss,\n",
        "    \"pts\": col_pts, \"reb\": col_reb, \"oreb\": col_oreb, \"dreb\": col_dreb,\n",
        "    \"ast\": col_ast, \"stl\": col_stl, \"blk\": col_blk, \"tov\": col_tov, \"pf\": col_pf,\n",
        "    \"fgm\": col_fgm, \"fga\": col_fga, \"fg3m\": col_fg3m, \"fg3a\": col_fg3a, \"ftm\": col_ftm, \"fta\": col_fta\n",
        "}\n",
        "missing_core = [k for k,v in core_report.items() if v is None and k in (\"name\",\"season\")]\n",
        "if missing_core:\n",
        "    raise ValueError(f\"Missing required columns after snake_case: {missing_core}. \"\n",
        "                     f\"Available columns (sample): {df.columns.tolist()[:40]}\")\n",
        "\n",
        "print(\"✅ column matching (None means not found):\")\n",
        "for k,v in core_report.items():\n",
        "    print(f\"  {k:>12}: {v}\")\n",
        "\n",
        "# -------------------------\n",
        "# 4) Coerce numerics (best-effort)\n",
        "# -------------------------\n",
        "id_like = {c for c in [col_name, col_team, col_pos] if c}\n",
        "for c in df.columns:\n",
        "    if c in id_like:\n",
        "        continue\n",
        "    if df[c].dtype == \"object\":\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
        "\n",
        "# Force key numeric columns if present\n",
        "for c in [col_gp, col_min, col_poss, col_pts, col_reb, col_oreb, col_dreb, col_ast, col_stl, col_blk, col_tov,\n",
        "          col_fgm, col_fga, col_fg3m, col_fg3a, col_ftm, col_fta, col_pf]:\n",
        "    if c and c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Per-game\n",
        "# -------------------------\n",
        "if col_gp and col_gp in df.columns:\n",
        "    gp = df[col_gp].fillna(0)\n",
        "    if col_min and col_min in df.columns:\n",
        "        df[\"mpg\"] = np.where(gp > 0, df[col_min] / gp, np.nan)\n",
        "\n",
        "    per_game_stats = {\n",
        "        \"ppg\": col_pts, \"rpg\": col_reb, \"orpg\": col_oreb, \"drpg\": col_dreb,\n",
        "        \"apg\": col_ast, \"spg\": col_stl, \"bpg\": col_blk, \"tovpg\": col_tov, \"pfpg\": col_pf\n",
        "    }\n",
        "    for newc, src in per_game_stats.items():\n",
        "        if src and src in df.columns:\n",
        "            df[newc] = np.where(gp > 0, df[src] / gp, np.nan)\n",
        "\n",
        "# -------------------------\n",
        "# 6) Per-40 minutes\n",
        "# -------------------------\n",
        "if col_min and col_min in df.columns:\n",
        "    mins = df[col_min].fillna(0)\n",
        "    denom = mins.replace(0, np.nan)\n",
        "\n",
        "    per40_stats = {\n",
        "        \"pts_per_40\": col_pts, \"reb_per_40\": col_reb, \"oreb_per_40\": col_oreb, \"dreb_per_40\": col_dreb,\n",
        "        \"ast_per_40\": col_ast, \"stl_per_40\": col_stl, \"blk_per_40\": col_blk, \"tov_per_40\": col_tov, \"pf_per_40\": col_pf,\n",
        "        \"fgm_per_40\": col_fgm, \"fga_per_40\": col_fga, \"fg3m_per_40\": col_fg3m, \"fg3a_per_40\": col_fg3a,\n",
        "        \"ftm_per_40\": col_ftm, \"fta_per_40\": col_fta\n",
        "    }\n",
        "    for newc, src in per40_stats.items():\n",
        "        if src and src in df.columns:\n",
        "            df[newc] = (df[src] / denom) * 40\n",
        "\n",
        "# -------------------------\n",
        "# 7) Per-100 possessions\n",
        "# -------------------------\n",
        "# If possessions isn't available, we create a proxy estimate:\n",
        "#   poss_est = FGA + 0.44*FTA + TOV\n",
        "# (This is a common approximation; when you have true possessions, prefer those.)\n",
        "if col_poss and col_poss in df.columns:\n",
        "    poss = df[col_poss].fillna(0).replace(0, np.nan)\n",
        "    df[\"possessions_used_for_per100\"] = df[col_poss]\n",
        "else:\n",
        "    # build poss_est only if the ingredients exist\n",
        "    if (col_fga and col_fga in df.columns) or (col_fta and col_fta in df.columns) or (col_tov and col_tov in df.columns):\n",
        "        fga = df[col_fga] if col_fga and col_fga in df.columns else 0\n",
        "        fta = df[col_fta] if col_fta and col_fta in df.columns else 0\n",
        "        tov = df[col_tov] if col_tov and col_tov in df.columns else 0\n",
        "        df[\"poss_est\"] = (fga.fillna(0) + 0.44 * fta.fillna(0) + tov.fillna(0))\n",
        "        poss = df[\"poss_est\"].replace(0, np.nan)\n",
        "        df[\"possessions_used_for_per100\"] = df[\"poss_est\"]\n",
        "        print(\"⚠️ possessions column not found; using poss_est = FGA + 0.44*FTA + TOV for per-100 rates.\")\n",
        "    else:\n",
        "        poss = None\n",
        "        print(\"⚠️ possessions column not found and cannot estimate (missing FGA/FTA/TOV). Skipping per-100 rates.\")\n",
        "\n",
        "if poss is not None:\n",
        "    per100_stats = {\n",
        "        \"pts_per_100\": col_pts, \"reb_per_100\": col_reb, \"oreb_per_100\": col_oreb, \"dreb_per_100\": col_dreb,\n",
        "        \"ast_per_100\": col_ast, \"stl_per_100\": col_stl, \"blk_per_100\": col_blk, \"tov_per_100\": col_tov, \"pf_per_100\": col_pf,\n",
        "        \"fgm_per_100\": col_fgm, \"fga_per_100\": col_fga, \"fg3m_per_100\": col_fg3m, \"fg3a_per_100\": col_fg3a,\n",
        "        \"ftm_per_100\": col_ftm, \"fta_per_100\": col_fta\n",
        "    }\n",
        "    for newc, src in per100_stats.items():\n",
        "        if src and src in df.columns:\n",
        "            df[newc] = (df[src] / poss) * 100\n",
        "\n",
        "# -------------------------\n",
        "# 8) Shooting / efficiency metrics\n",
        "# -------------------------\n",
        "# Shooting %\n",
        "if col_fga and col_fgm and col_fga in df.columns and col_fgm in df.columns:\n",
        "    df[\"fg_pct\"] = np.where(df[col_fga] > 0, df[col_fgm] / df[col_fga], np.nan)\n",
        "\n",
        "if col_fg3a and col_fg3m and col_fg3a in df.columns and col_fg3m in df.columns:\n",
        "    df[\"fg3_pct\"] = np.where(df[col_fg3a] > 0, df[col_fg3m] / df[col_fg3a], np.nan)\n",
        "\n",
        "if col_fta and col_ftm and col_fta in df.columns and col_ftm in df.columns:\n",
        "    df[\"ft_pct\"] = np.where(df[col_fta] > 0, df[col_ftm] / df[col_fta], np.nan)\n",
        "\n",
        "# Attempt rates\n",
        "if col_fga and col_fg3a and col_fga in df.columns and col_fg3a in df.columns:\n",
        "    df[\"threepar\"] = np.where(df[col_fga] > 0, df[col_fg3a] / df[col_fga], np.nan)  # 3PA rate\n",
        "\n",
        "if col_fga and col_fta and col_fga in df.columns and col_fta in df.columns:\n",
        "    df[\"fta_rate\"] = np.where(df[col_fga] > 0, df[col_fta] / df[col_fga], np.nan)   # FT attempt rate\n",
        "\n",
        "# eFG% and TS%\n",
        "if col_fga and col_fgm and col_fg3m and col_fga in df.columns and col_fgm in df.columns and col_fg3m in df.columns:\n",
        "    df[\"efg_pct\"] = np.where(df[col_fga] > 0, (df[col_fgm] + 0.5 * df[col_fg3m]) / df[col_fga], np.nan)\n",
        "\n",
        "if col_pts and col_fga and col_fta and col_pts in df.columns and col_fga in df.columns and col_fta in df.columns:\n",
        "    tsa = (df[col_fga].fillna(0) + 0.44 * df[col_fta].fillna(0))\n",
        "    df[\"ts_pct\"] = np.where(tsa > 0, df[col_pts] / (2 * tsa), np.nan)\n",
        "\n",
        "# AST:TOV (simple)\n",
        "if col_ast and col_tov and col_ast in df.columns and col_tov in df.columns:\n",
        "    df[\"ast_to_tov\"] = np.where(df[col_tov] > 0, df[col_ast] / df[col_tov], np.nan)\n",
        "\n",
        "# Usage proxy (volume, not true USG% without team totals)\n",
        "if col_fga and col_fta and col_tov:\n",
        "    if col_fga in df.columns and col_fta in df.columns and col_tov in df.columns:\n",
        "        df[\"usage_load\"] = (df[col_fga].fillna(0) + 0.44 * df[col_fta].fillna(0) + df[col_tov].fillna(0))\n",
        "        if col_min and col_min in df.columns:\n",
        "            df[\"usage_per_min\"] = np.where(df[col_min] > 0, df[\"usage_load\"] / df[col_min], np.nan)\n",
        "\n",
        "# OREB / DREB shares (within-player rebound mix)\n",
        "if col_reb and col_oreb and col_dreb and col_reb in df.columns and col_oreb in df.columns and col_dreb in df.columns:\n",
        "    df[\"oreb_share_of_reb\"] = np.where(df[col_reb] > 0, df[col_oreb] / df[col_reb], np.nan)\n",
        "    df[\"dreb_share_of_reb\"] = np.where(df[col_reb] > 0, df[col_dreb] / df[col_reb], np.nan)\n",
        "\n",
        "# -------------------------\n",
        "# 9) Round “rate-like” columns to 3 decimals (keep counts untouched)\n",
        "# -------------------------\n",
        "rate_cols = [c for c in df.columns if any(\n",
        "    c.endswith(suf) for suf in (\"_pct\", \"_rate\")\n",
        ") or c in (\n",
        "    \"threepar\", \"efg_pct\", \"ts_pct\", \"ast_to_tov\", \"usage_per_min\",\n",
        "    \"oreb_share_of_reb\", \"dreb_share_of_reb\"\n",
        ")]\n",
        "for c in rate_cols:\n",
        "    if pd.api.types.is_numeric_dtype(df[c]):\n",
        "        df[c] = df[c].round(3)\n",
        "\n",
        "# per-game / per-40 / per-100: nice to keep 2–3 decimals\n",
        "derived_prefixes = (\"ppg\",\"rpg\",\"apg\",\"spg\",\"bpg\",\"tovpg\",\"pfpg\",\"mpg\")\n",
        "for c in df.columns:\n",
        "    if c.startswith(derived_prefixes) and pd.api.types.is_numeric_dtype(df[c]):\n",
        "        df[c] = df[c].round(3)\n",
        "    if c.endswith(\"_per_40\") and pd.api.types.is_numeric_dtype(df[c]):\n",
        "        df[c] = df[c].round(3)\n",
        "    if c.endswith(\"_per_100\") and pd.api.types.is_numeric_dtype(df[c]):\n",
        "        df[c] = df[c].round(3)\n",
        "\n",
        "# -------------------------\n",
        "# 10) Save\n",
        "# -------------------------\n",
        "df.to_csv(OUT_DATA, index=False)\n",
        "print(\"✅ wrote derived dataset:\", OUT_DATA)\n",
        "\n",
        "# Quick sanity\n",
        "if col_pos and col_pos in df.columns:\n",
        "    print(\"✅ missing position %:\", float(df[col_pos].isna().mean()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "0l9CfLRzNDz9",
        "outputId": "621f14ad-e37b-4c84-b6d3-7d4b5b95993b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ wrote rename map: /content/processed_positions/pbpstats_derived_column_rename_map.csv\n",
            "✅ column matching (None means not found):\n",
            "          name: name\n",
            "        season: season\n",
            "          team: teamabbreviation\n",
            "      position: position\n",
            "  games_played: gamesplayed\n",
            "       minutes: minutes\n",
            "   possessions: None\n",
            "           pts: points\n",
            "           reb: rebounds\n",
            "          oreb: None\n",
            "          dreb: None\n",
            "           ast: assists\n",
            "           stl: steals\n",
            "           blk: blocks\n",
            "           tov: turnovers\n",
            "            pf: fouls\n",
            "           fgm: None\n",
            "           fga: None\n",
            "          fg3m: fg3m\n",
            "          fg3a: fg3a\n",
            "           ftm: None\n",
            "           fta: fta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3459090288.py:142: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'fillna'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3459090288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mfta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_fta\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol_fta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcol_fta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mtov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_tov\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol_tov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcol_tov\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"poss_est\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.44\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mposs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"poss_est\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"possessions_used_for_per100\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"poss_est\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'fillna'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "IN_PATH  = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_cleaned_pre_percentiles.csv\")\n",
        "OUT_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_derived_pre_percentiles.csv\")\n",
        "\n",
        "df = pd.read_csv(IN_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# -----------------------------\n",
        "# helpers\n",
        "# -----------------------------\n",
        "def pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols_lower:\n",
        "            return cols_lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def series_or_zeros(df: pd.DataFrame, col: str | None, dtype=float) -> pd.Series:\n",
        "    \"\"\"Always returns a Series aligned to df.index (fixes the int.fillna() issue).\"\"\"\n",
        "    if col is None or col not in df.columns:\n",
        "        return pd.Series(0, index=df.index, dtype=dtype)\n",
        "    s = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    return s.fillna(0).astype(dtype)\n",
        "\n",
        "def safe_div(num: pd.Series, den: pd.Series, default=0.0) -> pd.Series:\n",
        "    den0 = den.replace(0, np.nan)\n",
        "    out = num / den0\n",
        "    return out.fillna(default)\n",
        "\n",
        "# -----------------------------\n",
        "# locate key columns (flexible)\n",
        "# -----------------------------\n",
        "name_col   = pick_col(df, [\"Name\"])\n",
        "season_col = pick_col(df, [\"Season\"])\n",
        "team_col   = pick_col(df, [\"TeamAbbreviation\", \"Team_Abbreviation\", \"Team\"])\n",
        "pos_col    = pick_col(df, [\"Position\", \"Pos\"])\n",
        "gp_col     = pick_col(df, [\"GamesPlayed\", \"GP\"])\n",
        "min_col    = pick_col(df, [\"Minutes\", \"minutes_total\", \"Min\"])\n",
        "\n",
        "pts_col = pick_col(df, [\"Points\", \"PTS\", \"pts_total\"])\n",
        "reb_col = pick_col(df, [\"Rebounds\", \"REB\", \"reb_total\"])\n",
        "ast_col = pick_col(df, [\"Assists\", \"AST\", \"ast_total\"])\n",
        "stl_col = pick_col(df, [\"Steals\", \"STL\", \"stl_total\"])\n",
        "blk_col = pick_col(df, [\"Blocks\", \"BLK\", \"blk_total\"])\n",
        "tov_col = pick_col(df, [\"Turnovers\", \"TOV\", \"tov_total\"])\n",
        "\n",
        "# your provided mappings + common variants\n",
        "poss_col = pick_col(df, [\"TotalPoss\", \"total_poss\", \"possessions\", \"poss\"])\n",
        "oreb_col = pick_col(df, [\"OffRebounds\", \"OReb\", \"oreb_total\", \"off_rebounds\"])\n",
        "dreb_col = pick_col(df, [\"DefRebounds\", \"DReb\", \"dreb_total\", \"def_rebounds\"])\n",
        "\n",
        "fg2m_col = pick_col(df, [\"FG2M\", \"fg2m\"])\n",
        "fg2a_col = pick_col(df, [\"FG2A\", \"fg2a\"])\n",
        "fg3m_col = pick_col(df, [\"FG3M\", \"3PM\", \"fg3m\"])\n",
        "fg3a_col = pick_col(df, [\"FG3A\", \"3PA\", \"fg3a\"])\n",
        "ftm_col  = pick_col(df, [\"FTM\", \"ftm\"])\n",
        "fta_col  = pick_col(df, [\"FTA\", \"fta\"])\n",
        "\n",
        "# -----------------------------\n",
        "# build Series (ALWAYS Series)\n",
        "# -----------------------------\n",
        "gp   = series_or_zeros(df, gp_col, dtype=float)\n",
        "mins = series_or_zeros(df, min_col, dtype=float)\n",
        "\n",
        "pts = series_or_zeros(df, pts_col, dtype=float)\n",
        "reb = series_or_zeros(df, reb_col, dtype=float)\n",
        "ast = series_or_zeros(df, ast_col, dtype=float)\n",
        "stl = series_or_zeros(df, stl_col, dtype=float)\n",
        "blk = series_or_zeros(df, blk_col, dtype=float)\n",
        "tov = series_or_zeros(df, tov_col, dtype=float)\n",
        "\n",
        "poss = series_or_zeros(df, poss_col, dtype=float)\n",
        "oreb = series_or_zeros(df, oreb_col, dtype=float)\n",
        "dreb = series_or_zeros(df, dreb_col, dtype=float)\n",
        "\n",
        "fg2m = series_or_zeros(df, fg2m_col, dtype=float)\n",
        "fg2a = series_or_zeros(df, fg2a_col, dtype=float)\n",
        "fg3m = series_or_zeros(df, fg3m_col, dtype=float)\n",
        "fg3a = series_or_zeros(df, fg3a_col, dtype=float)\n",
        "ftm  = series_or_zeros(df, ftm_col,  dtype=float)\n",
        "fta  = series_or_zeros(df, fta_col,  dtype=float)\n",
        "\n",
        "fga = fg2a + fg3a\n",
        "fgm = fg2m + fg3m\n",
        "\n",
        "# -----------------------------\n",
        "# derived stats (teacher R logic adapted)\n",
        "# -----------------------------\n",
        "out = df.copy()\n",
        "\n",
        "# per-game\n",
        "out[\"mpg\"]   = safe_div(mins, gp, default=np.nan)\n",
        "out[\"ppg\"]   = safe_div(pts,  gp, default=np.nan)\n",
        "out[\"rpg\"]   = safe_div(reb,  gp, default=np.nan)\n",
        "out[\"apg\"]   = safe_div(ast,  gp, default=np.nan)\n",
        "out[\"spg\"]   = safe_div(stl,  gp, default=np.nan)\n",
        "out[\"bpg\"]   = safe_div(blk,  gp, default=np.nan)\n",
        "out[\"tovpg\"] = safe_div(tov,  gp, default=np.nan)\n",
        "\n",
        "# per-40 mins\n",
        "min_den = mins.replace(0, np.nan)\n",
        "out[\"pts_per_40\"]  = (pts  / min_den) * 40\n",
        "out[\"reb_per_40\"]  = (reb  / min_den) * 40\n",
        "out[\"oreb_per_40\"] = (oreb / min_den) * 40\n",
        "out[\"dreb_per_40\"] = (dreb / min_den) * 40\n",
        "out[\"ast_per_40\"]  = (ast  / min_den) * 40\n",
        "out[\"stl_per_40\"]  = (stl  / min_den) * 40\n",
        "out[\"blk_per_40\"]  = (blk  / min_den) * 40\n",
        "out[\"tov_per_40\"]  = (tov  / min_den) * 40\n",
        "\n",
        "# per-100 possessions (use PBPStats TotalPoss if present)\n",
        "poss_den = poss.replace(0, np.nan)\n",
        "out[\"pts_per_100\"]  = (pts  / poss_den) * 100\n",
        "out[\"reb_per_100\"]  = (reb  / poss_den) * 100\n",
        "out[\"oreb_per_100\"] = (oreb / poss_den) * 100\n",
        "out[\"dreb_per_100\"] = (dreb / poss_den) * 100\n",
        "out[\"ast_per_100\"]  = (ast  / poss_den) * 100\n",
        "out[\"stl_per_100\"]  = (stl  / poss_den) * 100\n",
        "out[\"blk_per_100\"]  = (blk  / poss_den) * 100\n",
        "out[\"tov_per_100\"]  = (tov  / poss_den) * 100\n",
        "\n",
        "# shooting %\n",
        "out[\"fg2_pct\"] = safe_div(fg2m, fg2a, default=0.0)\n",
        "out[\"fg3_pct\"] = safe_div(fg3m, fg3a, default=0.0)\n",
        "out[\"ft_pct\"]  = safe_div(ftm,  fta,  default=0.0)\n",
        "out[\"fg_pct\"]  = safe_div(fgm,  fga,  default=0.0)\n",
        "\n",
        "# rate stats / advanced\n",
        "out[\"threepar\"]  = safe_div(fg3a, fga, default=0.0)              # 3PA rate\n",
        "out[\"fta_rate\"]  = safe_div(fta,  fga, default=0.0)              # FTA per FGA\n",
        "out[\"efg_pct\"]   = safe_div((fgm + 0.5 * fg3m), fga, default=0.0)\n",
        "\n",
        "tsa = fga + 0.44 * fta\n",
        "out[\"ts_pct\"]    = safe_div(pts, 2 * tsa, default=0.0)\n",
        "\n",
        "out[\"usage_load\"] = fga + 0.44 * fta + tov\n",
        "out[\"usage\"]      = safe_div(out[\"usage_load\"], mins, default=0.0)  # possessions-used per minute proxy\n",
        "\n",
        "out[\"ast_to_tov\"] = np.where(tov > 0, safe_div(ast, tov, default=0.0), ast)\n",
        "\n",
        "# teacher's player-only poss estimate for ast% / tov% (not true team-based AST%)\n",
        "poss_est = fga + 0.44 * fta + tov + ast\n",
        "out[\"possessions_estimated\"] = poss_est\n",
        "out[\"ast_pct\"] = safe_div(ast, poss_est, default=0.0)\n",
        "out[\"tov_pct\"] = safe_div(tov, poss_est, default=0.0)\n",
        "\n",
        "out[\"oreb_pct\"] = safe_div(oreb, reb.replace(0, np.nan), default=0.0)\n",
        "out[\"dreb_pct\"] = safe_div(dreb, reb.replace(0, np.nan), default=0.0)\n",
        "\n",
        "# -----------------------------\n",
        "# rounding (3 decimals for rates/%)\n",
        "# -----------------------------\n",
        "rate_like = [c for c in out.columns if any(k in c.lower() for k in [\"_pct\", \"rate\", \"threepar\", \"usage\", \"_per_40\", \"_per_100\"])]\n",
        "for c in rate_like:\n",
        "    if pd.api.types.is_numeric_dtype(out[c]):\n",
        "        out[c] = pd.to_numeric(out[c], errors=\"coerce\").round(3)\n",
        "\n",
        "out.to_csv(OUT_PATH, index=False)\n",
        "print(\"✅ wrote:\", OUT_PATH)\n",
        "\n",
        "# quick sanity: show what columns were found for your key mappings\n",
        "print(\"\\nDetected columns:\")\n",
        "print(\"possessions:\", poss_col, \"| oreb:\", oreb_col, \"| dreb:\", dreb_col, \"| fg2m:\", fg2m_col, \"| fg2a:\", fg2a_col)\n",
        "print(\"fg3m:\", fg3m_col, \"| fg3a:\", fg3a_col, \"| ftm:\", ftm_col, \"| fta:\", fta_col)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ldbat8iXOoJ",
        "outputId": "86d5175e-c569-40ba-abe7-d31f03dfbe41"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ wrote: /content/processed_positions/pbpstats_totals_player_by_season_derived_pre_percentiles.csv\n",
            "\n",
            "Detected columns:\n",
            "possessions: totalposs | oreb: offrebounds | dreb: defrebounds | fg2m: fg2m | fg2a: fg2a\n",
            "fg3m: fg3m | fg3a: fg3a | ftm: None | fta: fta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "MASTER_MAP_PATH = Path(\"/content/processed_positions/position_mapping_master.csv\")\n",
        "TOTALS_PATH     = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions.csv\")\n",
        "\n",
        "OUT_MAP_PATH    = Path(\"/content/processed_positions/position_mapping_master_v2_manualpatch.csv\")\n",
        "OUT_TOTALS_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions_manualpatch.csv\")\n",
        "\n",
        "# ----------------------------\n",
        "# Normalizer (same idea as before)\n",
        "# ----------------------------\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "# ----------------------------\n",
        "# Manual position list (tab-separated)\n",
        "# ----------------------------\n",
        "manual_txt = \"\"\"Name\\tPosition\n",
        "Amy Atwell\\tF\n",
        "Asia (AD) Durr\\tG\n",
        "Astou Ndour-Fall\\tC\n",
        "Betnijah Laney-Hamilton\\tF\n",
        "Caitlin Bickle\\tF\n",
        "Celeste Taylor\\tG\n",
        "Charisma Osborne\\tG\n",
        "Chennedy Carter\\tG\n",
        "Cyesha Goree\\tF\n",
        "DiDi Richards\\tG\n",
        "Dyaisha Fair\\tG\n",
        "Ezinne Kalu\\tG\n",
        "Jakia Brown-Turner\\tG\n",
        "Jessika Carter\\tF\n",
        "Kaela Davis\\tF\n",
        "Kysre Gondrezick\\tG\n",
        "Mikiah Herbert Harrigan\\tF\n",
        "Nika Mühl\\tG\n",
        "Olivia Époupa\\tG\n",
        "Stephanie Soares\\tC\n",
        "\"\"\"\n",
        "\n",
        "manual = pd.read_csv(pd.io.common.StringIO(manual_txt), sep=\"\\t\")\n",
        "manual[\"Name\"] = manual[\"Name\"].astype(str).str.strip()\n",
        "manual[\"Position\"] = manual[\"Position\"].astype(str).str.strip().str.upper()\n",
        "manual[\"Name_norm\"] = manual[\"Name\"].apply(norm_name)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Update the master mapping (reusable asset)\n",
        "# ----------------------------\n",
        "mp = pd.read_csv(MASTER_MAP_PATH)\n",
        "mp.columns = [c.strip() for c in mp.columns]\n",
        "\n",
        "# Ensure Name_norm exists in mapping\n",
        "if \"Name_norm\" not in mp.columns:\n",
        "    if \"Name\" not in mp.columns:\n",
        "        raise ValueError(f\"Mapping file missing Name and Name_norm. Columns: {mp.columns.tolist()[:50]}\")\n",
        "    mp[\"Name_norm\"] = mp[\"Name\"].apply(norm_name)\n",
        "\n",
        "# Choose / create a \"Position_master\" column\n",
        "pos_master_col = \"Position_master\" if \"Position_master\" in mp.columns else None\n",
        "if not pos_master_col:\n",
        "    # Fall back: if mapping already has Position, use it as base\n",
        "    if \"Position\" in mp.columns:\n",
        "        mp[\"Position_master\"] = mp[\"Position\"]\n",
        "    else:\n",
        "        mp[\"Position_master\"] = pd.NA\n",
        "    pos_master_col = \"Position_master\"\n",
        "\n",
        "# Upsert the manual positions into mapping (by Name_norm)\n",
        "mp = mp.copy()\n",
        "mp[\"_manual_pos\"] = mp[\"Name_norm\"].map(dict(zip(manual[\"Name_norm\"], manual[\"Position\"])))\n",
        "mp[pos_master_col] = mp[pos_master_col].combine_first(mp[\"_manual_pos\"])\n",
        "\n",
        "# Optional: store provenance\n",
        "if \"Position_manual\" not in mp.columns:\n",
        "    mp[\"Position_manual\"] = pd.NA\n",
        "mp[\"Position_manual\"] = mp[\"Position_manual\"].combine_first(mp[\"_manual_pos\"])\n",
        "\n",
        "mp = mp.drop(columns=[\"_manual_pos\"])\n",
        "\n",
        "mp.to_csv(OUT_MAP_PATH, index=False)\n",
        "print(f\"✅ Wrote updated master mapping: {OUT_MAP_PATH}\")\n",
        "print(f\"✅ Master mapping missing Position_master %: {mp[pos_master_col].isna().mean():.2%}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Patch the totals-by-season file\n",
        "# ----------------------------\n",
        "df = pd.read_csv(TOTALS_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "if \"Name\" not in df.columns:\n",
        "    raise ValueError(f\"Totals file missing Name. Columns: {df.columns.tolist()[:50]}\")\n",
        "\n",
        "# Make sure Position column exists\n",
        "if \"Position\" not in df.columns:\n",
        "    df[\"Position\"] = pd.NA\n",
        "\n",
        "# Exact-name patch first (keeps diacritics/parentheses as-is)\n",
        "exact_map = dict(zip(manual[\"Name\"], manual[\"Position\"]))\n",
        "mask_missing = df[\"Position\"].isna()\n",
        "df.loc[mask_missing, \"Position\"] = df.loc[mask_missing, \"Name\"].map(exact_map).combine_first(df.loc[mask_missing, \"Position\"])\n",
        "\n",
        "# Norm-name patch second (catches name formatting differences)\n",
        "df[\"Name_norm\"] = df[\"Name\"].apply(norm_name)\n",
        "norm_map = dict(zip(manual[\"Name_norm\"], manual[\"Position\"]))\n",
        "mask_missing = df[\"Position\"].isna()\n",
        "df.loc[mask_missing, \"Position\"] = df.loc[mask_missing, \"Name_norm\"].map(norm_map)\n",
        "\n",
        "df.to_csv(OUT_TOTALS_PATH, index=False)\n",
        "print(f\"✅ Wrote patched totals file: {OUT_TOTALS_PATH}\")\n",
        "print(f\"✅ Remaining missing Position rows: {df['Position'].isna().sum()} (of {len(df)})\")\n",
        "\n",
        "# If anything is still missing, list unique names\n",
        "if df[\"Position\"].isna().any():\n",
        "    still = (df.loc[df[\"Position\"].isna(), \"Name\"].dropna().drop_duplicates().sort_values().tolist())\n",
        "    print(\"Still missing names:\", still)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFzv09UcfRsZ",
        "outputId": "589eaf7f-aa33-40fb-ef56-a714b892ffa1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote updated master mapping: /content/processed_positions/position_mapping_master_v2_manualpatch.csv\n",
            "✅ Master mapping missing Position_master %: 0.00%\n",
            "✅ Wrote patched totals file: /content/processed_positions/pbpstats_totals_player_by_season_with_positions_manualpatch.csv\n",
            "✅ Remaining missing Position rows: 0 (of 495)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# Paths (edit if you want)\n",
        "# -----------------------------\n",
        "IN_DATA = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_derived_pre_percentiles.csv\")\n",
        "\n",
        "# Optional: re-fill Position from this mapping (recommended)\n",
        "# Uses Name_norm join, so it works even if names have accents/parentheses\n",
        "MASTER_MAP = Path(\"/content/processed_positions/position_mapping_master_v2_manualpatch.csv\")\n",
        "\n",
        "OUT_ALL = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_percentiles_ALL.csv\")\n",
        "OUT_FINAL = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_percentiles_MIN50.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def pick_col(df: pd.DataFrame, candidates):\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols_lower:\n",
        "            return cols_lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def weighted_percentile_rank(values: pd.Series, weights: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Returns a percentile rank (0-100) for each value, weighted by weights.\n",
        "    Ties get the same percentile using the tie group's midpoint cumulative weight.\n",
        "    \"\"\"\n",
        "    out = pd.Series(np.nan, index=values.index, dtype=float)\n",
        "\n",
        "    v = pd.to_numeric(values, errors=\"coerce\")\n",
        "    w = pd.to_numeric(weights, errors=\"coerce\").fillna(0)\n",
        "    mask = v.notna() & (w > 0)\n",
        "\n",
        "    if mask.sum() == 0:\n",
        "        return out\n",
        "\n",
        "    tmp = pd.DataFrame({\"v\": v[mask], \"w\": w[mask]})\n",
        "\n",
        "    total_w = tmp[\"w\"].sum()\n",
        "    if total_w <= 0:\n",
        "        return out\n",
        "\n",
        "    # Aggregate weights by unique value to handle ties cleanly\n",
        "    agg = (\n",
        "        tmp.groupby(\"v\", as_index=False)[\"w\"]\n",
        "           .sum()\n",
        "           .sort_values(\"v\")\n",
        "           .reset_index(drop=True)\n",
        "    )\n",
        "    agg[\"cum_w\"] = agg[\"w\"].cumsum()\n",
        "    agg[\"mid_w\"] = agg[\"cum_w\"] - 0.5 * agg[\"w\"]\n",
        "    agg[\"pct\"] = 100.0 * agg[\"mid_w\"] / total_w\n",
        "\n",
        "    pct_map = dict(zip(agg[\"v\"], agg[\"pct\"]))\n",
        "    out.loc[mask] = v.loc[mask].map(pct_map)\n",
        "\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Load\n",
        "# -----------------------------\n",
        "df = pd.read_csv(IN_DATA)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Identify key columns (flexible)\n",
        "name_col = pick_col(df, [\"Name\", \"player\"])\n",
        "pos_col  = pick_col(df, [\"Position\", \"athlete_position_abbreviation\", \"pos\"])\n",
        "min_col  = pick_col(df, [\"Minutes\", \"minutes_total\", \"min\"])\n",
        "season_col = pick_col(df, [\"Season\", \"season\"])\n",
        "\n",
        "if not name_col or not min_col:\n",
        "    raise ValueError(f\"Missing required columns. Found name={name_col}, minutes={min_col}. \"\n",
        "                     f\"Columns sample: {df.columns.tolist()[:40]}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) (Optional) Re-fill Position from master mapping\n",
        "# -----------------------------\n",
        "if (pos_col is None) or df[pos_col].isna().any():\n",
        "    if MASTER_MAP.exists():\n",
        "        mp = pd.read_csv(MASTER_MAP)\n",
        "        mp.columns = [c.strip() for c in mp.columns]\n",
        "\n",
        "        # Ensure mapping has Name_norm and Position_master\n",
        "        if \"Name_norm\" not in mp.columns:\n",
        "            if \"Name\" not in mp.columns:\n",
        "                raise ValueError(\"Master mapping missing Name and Name_norm.\")\n",
        "            mp[\"Name_norm\"] = mp[\"Name\"].apply(norm_name)\n",
        "\n",
        "        pos_master_col = \"Position_master\" if \"Position_master\" in mp.columns else (\n",
        "            \"Position\" if \"Position\" in mp.columns else None\n",
        "        )\n",
        "        if pos_master_col is None:\n",
        "            raise ValueError(\"Master mapping missing Position_master/Position.\")\n",
        "\n",
        "        if \"Name_norm\" not in df.columns:\n",
        "            df[\"Name_norm\"] = df[name_col].apply(norm_name)\n",
        "\n",
        "        df = df.merge(\n",
        "            mp[[\"Name_norm\", pos_master_col]].rename(columns={pos_master_col: \"Position_from_map\"}),\n",
        "            on=\"Name_norm\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        if pos_col is None:\n",
        "            df[\"Position\"] = df[\"Position_from_map\"]\n",
        "            pos_col = \"Position\"\n",
        "        else:\n",
        "            df[pos_col] = df[pos_col].combine_first(df[\"Position_from_map\"])\n",
        "\n",
        "        df = df.drop(columns=[\"Position_from_map\"])\n",
        "        print(\"✅ Re-filled Position from master mapping.\")\n",
        "    else:\n",
        "        print(\"⚠️ MASTER_MAP not found — skipping Position refill.\")\n",
        "\n",
        "if pos_col is None:\n",
        "    raise ValueError(\"No Position column found (and could not create one).\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Compute weighted percentiles by Position (weights = minutes)\n",
        "# -----------------------------\n",
        "# Metrics to percentile (R script equivalents)\n",
        "metrics = {\n",
        "    \"usage_pctile_pos\": \"usage\",\n",
        "    \"ts_pctile_pos\": \"ts_pct\",\n",
        "    \"efg_pctile_pos\": \"efg_pct\",\n",
        "    \"ast_pctile_pos\": \"ast_per_40\",\n",
        "    \"tov_pctile_pos\": \"tov_per_40\",\n",
        "    \"stl_pctile_pos\": \"stl_per_40\",\n",
        "    \"blk_pctile_pos\": \"blk_per_40\",\n",
        "    \"reb_pctile_pos\": \"reb_per_40\",\n",
        "}\n",
        "\n",
        "# Verify which source cols exist (skip gracefully if missing)\n",
        "available = {new: src for new, src in metrics.items() if src in df.columns}\n",
        "missing = {new: src for new, src in metrics.items() if src not in df.columns}\n",
        "\n",
        "if missing:\n",
        "    print(\"⚠️ Skipping missing metric columns:\")\n",
        "    for new, src in missing.items():\n",
        "        print(f\"   - {new} (source '{src}' not found)\")\n",
        "\n",
        "weights = pd.to_numeric(df[min_col], errors=\"coerce\").fillna(0)\n",
        "\n",
        "for new_col, src_col in available.items():\n",
        "    df[new_col] = (\n",
        "        df.groupby(pos_col, group_keys=False)\n",
        "          .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
        "    )\n",
        "\n",
        "# Nice rounding for percentiles\n",
        "for c in available.keys():\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").round(1)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Filter minutes_total >= 50 (same as your R flow)\n",
        "# -----------------------------\n",
        "mins = pd.to_numeric(df[min_col], errors=\"coerce\").fillna(0)\n",
        "df_all = df.copy()\n",
        "df_min50 = df.loc[mins >= 50].copy()\n",
        "\n",
        "print(f\"✅ Rows (all): {len(df_all)}\")\n",
        "print(f\"✅ Rows (minutes>=50): {len(df_min50)}\")\n",
        "print(f\"✅ Missing Position % (all): {df_all[pos_col].isna().mean():.2%}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Export\n",
        "# -----------------------------\n",
        "df_all.to_csv(OUT_ALL, index=False)\n",
        "df_min50.to_csv(OUT_FINAL, index=False)\n",
        "\n",
        "print(\"✅ Wrote:\", OUT_ALL)\n",
        "print(\"✅ Wrote:\", OUT_FINAL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOQRDEKzgp0S",
        "outputId": "0b1279bf-8be1-4202-fd91-51ddd88dbb76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Re-filled Position from master mapping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n",
            "/tmp/ipython-input-2320006165.py:160: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[src_col], g[min_col]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Rows (all): 495\n",
            "✅ Rows (minutes>=50): 449\n",
            "✅ Missing Position % (all): 4.04%\n",
            "✅ Wrote: /content/processed_positions/pbpstats_totals_player_by_season_with_pos_percentiles_ALL.csv\n",
            "✅ Wrote: /content/processed_positions/pbpstats_totals_player_by_season_with_pos_percentiles_MIN50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# Paths (edit if you want)\n",
        "# -----------------------------\n",
        "IN_DATA   = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_derived_pre_percentiles.csv\")\n",
        "MASTER_MAP = Path(\"/content/processed_positions/position_mapping_master_v2_manualpatch.csv\")\n",
        "\n",
        "OUT_ALL   = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_and_season_percentiles_ALL.csv\")\n",
        "OUT_MIN50 = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_and_season_percentiles_MIN50.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def pick_col(df: pd.DataFrame, candidates):\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols_lower:\n",
        "            return cols_lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = \"\" if pd.isna(s) else str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = re.sub(r\"[^a-z\\s\\-']\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def weighted_percentile_rank(values: pd.Series, weights: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Percentile rank (0-100), weighted by weights.\n",
        "    Ties share the same percentile using the tie group's midpoint cumulative weight.\n",
        "    \"\"\"\n",
        "    out = pd.Series(np.nan, index=values.index, dtype=float)\n",
        "    v = pd.to_numeric(values, errors=\"coerce\")\n",
        "    w = pd.to_numeric(weights, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    mask = v.notna() & (w > 0)\n",
        "    if mask.sum() == 0:\n",
        "        return out\n",
        "\n",
        "    tmp = pd.DataFrame({\"v\": v[mask], \"w\": w[mask]})\n",
        "    total_w = tmp[\"w\"].sum()\n",
        "    if total_w <= 0:\n",
        "        return out\n",
        "\n",
        "    agg = (\n",
        "        tmp.groupby(\"v\", as_index=False)[\"w\"]\n",
        "           .sum()\n",
        "           .sort_values(\"v\")\n",
        "           .reset_index(drop=True)\n",
        "    )\n",
        "    agg[\"cum_w\"] = agg[\"w\"].cumsum()\n",
        "    agg[\"mid_w\"] = agg[\"cum_w\"] - 0.5 * agg[\"w\"]\n",
        "    agg[\"pct\"] = 100.0 * agg[\"mid_w\"] / total_w\n",
        "    pct_map = dict(zip(agg[\"v\"], agg[\"pct\"]))\n",
        "\n",
        "    out.loc[mask] = v.loc[mask].map(pct_map)\n",
        "    return out\n",
        "\n",
        "def add_weighted_percentiles(df: pd.DataFrame, group_cols, metric_map, weight_col, out_suffix):\n",
        "    \"\"\"\n",
        "    Adds columns like: {metric_name}{out_suffix}\n",
        "    metric_map: {metric_name: source_col}\n",
        "    group_cols: list of col names to group by\n",
        "    \"\"\"\n",
        "    for metric_name, src_col in metric_map.items():\n",
        "        if src_col not in df.columns:\n",
        "            print(f\"⚠️ Skipping {metric_name}: source col '{src_col}' not found.\")\n",
        "            continue\n",
        "\n",
        "        out_col = f\"{metric_name}{out_suffix}\"\n",
        "        out = pd.Series(np.nan, index=df.index, dtype=float)\n",
        "\n",
        "        groups = df.groupby(group_cols, sort=False).groups\n",
        "        for _, idx in groups.items():\n",
        "            out.loc[idx] = weighted_percentile_rank(df.loc[idx, src_col], df.loc[idx, weight_col]).loc[idx]\n",
        "\n",
        "        df[out_col] = pd.to_numeric(out, errors=\"coerce\").round(1)\n",
        "\n",
        "# -----------------------------\n",
        "# Load\n",
        "# -----------------------------\n",
        "df = pd.read_csv(IN_DATA)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "name_col   = pick_col(df, [\"Name\", \"player\"])\n",
        "season_col = pick_col(df, [\"Season\", \"season\"])\n",
        "pos_col    = pick_col(df, [\"Position\", \"athlete_position_abbreviation\", \"pos\"])\n",
        "min_col    = pick_col(df, [\"Minutes\", \"minutes_total\", \"min\", \"minutes\"])\n",
        "\n",
        "if not season_col or not min_col:\n",
        "    raise ValueError(f\"Missing required columns: season={season_col}, minutes={min_col}. \"\n",
        "                     f\"Columns sample: {df.columns.tolist()[:40]}\")\n",
        "\n",
        "# -----------------------------\n",
        "# (Optional) Re-fill Position from master mapping\n",
        "# -----------------------------\n",
        "if (pos_col is None) or df[pos_col].isna().any():\n",
        "    if MASTER_MAP.exists():\n",
        "        mp = pd.read_csv(MASTER_MAP)\n",
        "        mp.columns = [c.strip() for c in mp.columns]\n",
        "        if \"Name_norm\" not in mp.columns:\n",
        "            mp[\"Name_norm\"] = mp[\"Name\"].apply(norm_name)\n",
        "\n",
        "        pos_master_col = \"Position_master\" if \"Position_master\" in mp.columns else (\"Position\" if \"Position\" in mp.columns else None)\n",
        "        if pos_master_col is None:\n",
        "            raise ValueError(\"Master mapping missing Position_master/Position.\")\n",
        "\n",
        "        if \"Name_norm\" not in df.columns:\n",
        "            df[\"Name_norm\"] = df[name_col].apply(norm_name)\n",
        "\n",
        "        df = df.merge(\n",
        "            mp[[\"Name_norm\", pos_master_col]].rename(columns={pos_master_col: \"Position_from_map\"}),\n",
        "            on=\"Name_norm\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        if pos_col is None:\n",
        "            df[\"Position\"] = df[\"Position_from_map\"]\n",
        "            pos_col = \"Position\"\n",
        "        else:\n",
        "            df[pos_col] = df[pos_col].combine_first(df[\"Position_from_map\"])\n",
        "\n",
        "        df = df.drop(columns=[\"Position_from_map\"])\n",
        "        print(\"✅ Re-filled Position from master mapping.\")\n",
        "    else:\n",
        "        print(\"⚠️ MASTER_MAP not found — skipping Position refill.\")\n",
        "\n",
        "if pos_col is None:\n",
        "    raise ValueError(\"No Position column found (and could not create one).\")\n",
        "\n",
        "# Ensure minutes numeric\n",
        "df[min_col] = pd.to_numeric(df[min_col], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# -----------------------------\n",
        "# Metrics to percentile (your R equivalents)\n",
        "# -----------------------------\n",
        "metrics = {\n",
        "    \"usage_pctile\": \"usage\",\n",
        "    \"ts_pctile\":    \"ts_pct\",\n",
        "    \"efg_pctile\":   \"efg_pct\",\n",
        "    \"ast_pctile\":   \"ast_per_40\",\n",
        "    \"tov_pctile\":   \"tov_per_40\",\n",
        "    \"stl_pctile\":   \"stl_per_40\",\n",
        "    \"blk_pctile\":   \"blk_per_40\",\n",
        "    \"reb_pctile\":   \"reb_per_40\",\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# A) Position percentiles across ALL seasons (what you already had)\n",
        "#    Group: Position\n",
        "# -----------------------------\n",
        "add_weighted_percentiles(\n",
        "    df=df,\n",
        "    group_cols=[pos_col],\n",
        "    metric_map=metrics,\n",
        "    weight_col=min_col,\n",
        "    out_suffix=\"_pos_all\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# B) Season percentiles (league-wide within season)\n",
        "#    Group: Season\n",
        "# -----------------------------\n",
        "add_weighted_percentiles(\n",
        "    df=df,\n",
        "    group_cols=[season_col],\n",
        "    metric_map=metrics,\n",
        "    weight_col=min_col,\n",
        "    out_suffix=\"_season\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# C) Season + Position percentiles (positional peers within same season)\n",
        "#    Group: Season, Position\n",
        "# -----------------------------\n",
        "add_weighted_percentiles(\n",
        "    df=df,\n",
        "    group_cols=[season_col, pos_col],\n",
        "    metric_map=metrics,\n",
        "    weight_col=min_col,\n",
        "    out_suffix=\"_pos_season\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Filter minutes >= 50 (same as your R pipeline)\n",
        "# -----------------------------\n",
        "df_all = df.copy()\n",
        "df_min50 = df.loc[df[min_col] >= 50].copy()\n",
        "\n",
        "# -----------------------------\n",
        "# Export\n",
        "# -----------------------------\n",
        "df_all.to_csv(OUT_ALL, index=False)\n",
        "df_min50.to_csv(OUT_MIN50, index=False)\n",
        "\n",
        "print(\"✅ Wrote ALL:  \", OUT_ALL)\n",
        "print(\"✅ Wrote MIN50:\", OUT_MIN50)\n",
        "print(\"Rows ALL:\", len(df_all), \"| Rows MIN50:\", len(df_min50))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrhig4RpiSlG",
        "outputId": "3af80d2f-c078-4797-a7e6-30af5dbb1581"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Re-filled Position from master mapping.\n",
            "✅ Wrote ALL:   /content/processed_positions/pbpstats_totals_player_by_season_with_pos_and_season_percentiles_ALL.csv\n",
            "✅ Wrote MIN50: /content/processed_positions/pbpstats_totals_player_by_season_with_pos_and_season_percentiles_MIN50.csv\n",
            "Rows ALL: 495 | Rows MIN50: 449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "IN_ALL   = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_and_season_percentiles_ALL.csv\")\n",
        "IN_MIN50 = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_and_season_percentiles_MIN50.csv\")\n",
        "\n",
        "OUT_ALL_WIDE   = Path(\"/content/processed_positions/pbpstats_player_by_season_flags_WIDE_ALL.csv\")\n",
        "OUT_MIN50_WIDE = Path(\"/content/processed_positions/pbpstats_player_by_season_flags_WIDE_MIN50.csv\")\n",
        "\n",
        "OUT_ALL_LONG   = Path(\"/content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL.csv\")\n",
        "OUT_MIN50_LONG = Path(\"/content/processed_positions/pbpstats_player_by_season_signals_LONG_MIN50.csv\")\n",
        "\n",
        "\n",
        "LENS_SUFFIXES = [\"pos_all\", \"season\", \"pos_season\"]\n",
        "\n",
        "# Map percentile lens -> recommended playbook lens\n",
        "LENS_TO_PLAYBOOK = {\n",
        "    \"season\": \"Contract/Valuation\",\n",
        "    \"pos_season\": \"Scouting\",\n",
        "    \"pos_all\": \"Lineup Optimization\",  # useful “stable baseline”; feel free to rename\n",
        "}\n",
        "\n",
        "# Map metric -> stat category (customize later when you auto-tag ALL pbpstats columns)\n",
        "METRIC_TO_CATEGORY = {\n",
        "    \"usage\": \"Scoring / Role\",\n",
        "    \"ts\": \"Scoring / Efficiency\",\n",
        "    \"efg\": \"Scoring / Efficiency\",\n",
        "    \"ast\": \"Assists\",\n",
        "    \"tov\": \"Turnovers\",\n",
        "    \"stl\": \"Defense / Activity\",\n",
        "    \"blk\": \"Defense / Activity\",\n",
        "    \"reb\": \"Rebounds\",\n",
        "}\n",
        "\n",
        "def find_percentile_cols(df: pd.DataFrame) -> list[str]:\n",
        "    # catches: usage_pctile_season, ts_pctile_pos_season, etc.\n",
        "    cols = []\n",
        "    for c in df.columns:\n",
        "        if \"pctile\" in c.lower() and any(c.lower().endswith(sfx) for sfx in LENS_SUFFIXES):\n",
        "            cols.append(c)\n",
        "    return cols\n",
        "\n",
        "def thresholds_for_col(series: pd.Series):\n",
        "    \"\"\"Handles either 0–1 or 0–100 percentile scales safely.\"\"\"\n",
        "    s = pd.to_numeric(series, errors=\"coerce\")\n",
        "    mx = s.dropna().max() if s.notna().any() else np.nan\n",
        "    if pd.notna(mx) and mx <= 1.00001:\n",
        "        return 0.90, 0.15  # proportions\n",
        "    return 90.0, 15.0     # percentile points\n",
        "\n",
        "def parse_metric_and_lens(col: str):\n",
        "    c = col.lower()\n",
        "    lens = next((sfx for sfx in LENS_SUFFIXES if c.endswith(sfx)), None)\n",
        "    metric = c.split(\"_pctile_\")[0] if \"_pctile_\" in c else c.split(\"pctile\")[0].rstrip(\"_\")\n",
        "    return metric, lens\n",
        "\n",
        "def add_flags_wide(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    pct_cols = find_percentile_cols(df)\n",
        "\n",
        "    for col in pct_cols:\n",
        "        hi, lo = thresholds_for_col(df[col])\n",
        "        df[f\"{col}_elite90\"] = (pd.to_numeric(df[col], errors=\"coerce\") >= hi).astype(\"Int64\")\n",
        "        df[f\"{col}_low15\"]   = (pd.to_numeric(df[col], errors=\"coerce\") <= lo).astype(\"Int64\")\n",
        "\n",
        "    # Optional: summary counts per lens (nice for quick filtering)\n",
        "    for lens in LENS_SUFFIXES:\n",
        "        lens_cols = [c for c in pct_cols if c.lower().endswith(lens)]\n",
        "        elite_cols = [f\"{c}_elite90\" for c in lens_cols]\n",
        "        low_cols   = [f\"{c}_low15\" for c in lens_cols]\n",
        "        if elite_cols:\n",
        "            df[f\"elite_count_{lens}\"] = df[elite_cols].sum(axis=1).astype(\"Int64\")\n",
        "        if low_cols:\n",
        "            df[f\"low_count_{lens}\"] = df[low_cols].sum(axis=1).astype(\"Int64\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def build_signals_long(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    pct_cols = find_percentile_cols(df)\n",
        "\n",
        "    id_cols = [c for c in [\"Name\", \"Season\", \"TeamAbbreviation\", \"Position\", \"Minutes\", \"GamesPlayed\"] if c in df.columns]\n",
        "    base = df[id_cols].copy()\n",
        "\n",
        "    rows = []\n",
        "    for col in pct_cols:\n",
        "        metric, lens = parse_metric_and_lens(col)\n",
        "        hi, lo = thresholds_for_col(df[col])\n",
        "\n",
        "        tmp = base.copy()\n",
        "        tmp[\"metric\"] = metric\n",
        "        tmp[\"lens\"] = lens\n",
        "        tmp[\"percentile\"] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        tmp[\"elite90_flag\"] = (tmp[\"percentile\"] >= hi).astype(\"Int64\")\n",
        "        tmp[\"low15_flag\"]   = (tmp[\"percentile\"] <= lo).astype(\"Int64\")\n",
        "\n",
        "        tmp[\"playbook_lens\"] = LENS_TO_PLAYBOOK.get(lens, \"General\")\n",
        "        tmp[\"stat_category\"] = METRIC_TO_CATEGORY.get(metric, \"Uncategorized\")\n",
        "\n",
        "        # One more “human-friendly” label\n",
        "        tmp[\"signal\"] = np.select(\n",
        "            [tmp[\"elite90_flag\"] == 1, tmp[\"low15_flag\"] == 1],\n",
        "            [\"ELITE (>=90th)\", \"CONCERN (<=15th)\"],\n",
        "            default=\"Neutral\"\n",
        "        )\n",
        "\n",
        "        rows.append(tmp)\n",
        "\n",
        "    long_df = pd.concat(rows, ignore_index=True)\n",
        "\n",
        "    # Optional: keep only “signals” (reduces noise a ton for Notion views)\n",
        "    # long_df = long_df[long_df[\"signal\"].isin([\"ELITE (>=90th)\", \"CONCERN (<=15th)\"])].copy()\n",
        "\n",
        "    return long_df\n",
        "\n",
        "\n",
        "def run(in_path: Path, out_wide: Path, out_long: Path):\n",
        "    df = pd.read_csv(in_path)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    df = add_flags_wide(df)\n",
        "    df.to_csv(out_wide, index=False)\n",
        "\n",
        "    long_df = build_signals_long(df)\n",
        "    long_df.to_csv(out_long, index=False)\n",
        "\n",
        "    print(\"✅ Wrote WIDE:\", out_wide)\n",
        "    print(\"✅ Wrote LONG:\", out_long)\n",
        "    print(\"WIDE shape:\", df.shape, \"| LONG shape:\", long_df.shape)\n",
        "\n",
        "\n",
        "run(IN_ALL, OUT_ALL_WIDE, OUT_ALL_LONG)\n",
        "run(IN_MIN50, OUT_MIN50_WIDE, OUT_MIN50_LONG)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNqYqJhTssy_",
        "outputId": "83e23c00-0ccf-4e39-d4cc-0b15c9ff6c5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote WIDE: /content/processed_positions/pbpstats_player_by_season_flags_WIDE_ALL.csv\n",
            "✅ Wrote LONG: /content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL.csv\n",
            "WIDE shape: (495, 370) | LONG shape: (11880, 8)\n",
            "✅ Wrote WIDE: /content/processed_positions/pbpstats_player_by_season_flags_WIDE_MIN50.csv\n",
            "✅ Wrote LONG: /content/processed_positions/pbpstats_player_by_season_signals_LONG_MIN50.csv\n",
            "WIDE shape: (449, 370) | LONG shape: (10776, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "IN_ALL   = Path(\"/content/processed_positions/pbpstats_player_by_season_flags_WIDE_ALL.csv\")\n",
        "IN_MIN50 = Path(\"/content/processed_positions/pbpstats_player_by_season_flags_WIDE_MIN50.csv\")\n",
        "\n",
        "OUT_ALL_LONG_FIXED   = Path(\"/content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL_FIXED.csv\")\n",
        "OUT_MIN50_LONG_FIXED = Path(\"/content/processed_positions/pbpstats_player_by_season_signals_LONG_MIN50_FIXED.csv\")\n",
        "\n",
        "LENS_SUFFIXES = [\"pos_all\", \"season\", \"pos_season\"]\n",
        "\n",
        "LENS_TO_PLAYBOOK = {\n",
        "    \"season\": \"Contract/Valuation\",\n",
        "    \"pos_season\": \"Scouting\",\n",
        "    \"pos_all\": \"Lineup Optimization\",\n",
        "}\n",
        "\n",
        "METRIC_TO_CATEGORY = {\n",
        "    \"usage\": \"Scoring / Role\",\n",
        "    \"ts\": \"Scoring / Efficiency\",\n",
        "    \"efg\": \"Scoring / Efficiency\",\n",
        "    \"ast\": \"Assists / Creation\",\n",
        "    \"tov\": \"Turnovers\",\n",
        "    \"stl\": \"Defense / Activity\",\n",
        "    \"blk\": \"Defense / Activity\",\n",
        "    \"reb\": \"Rebounds\",\n",
        "    \"oreb\": \"Second Chance\",\n",
        "    \"dreb\": \"Rebounds\",\n",
        "}\n",
        "\n",
        "def pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols_lower:\n",
        "            return cols_lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def find_percentile_cols(df: pd.DataFrame) -> list[str]:\n",
        "    out = []\n",
        "    for c in df.columns:\n",
        "        cl = c.lower()\n",
        "        if \"pctile\" in cl and any(cl.endswith(sfx) for sfx in LENS_SUFFIXES):\n",
        "            out.append(c)\n",
        "    return out\n",
        "\n",
        "def thresholds_for_col(series: pd.Series):\n",
        "    s = pd.to_numeric(series, errors=\"coerce\")\n",
        "    mx = s.dropna().max() if s.notna().any() else np.nan\n",
        "    if pd.notna(mx) and mx <= 1.00001:\n",
        "        return 0.90, 0.15\n",
        "    return 90.0, 15.0\n",
        "\n",
        "def parse_metric_and_lens(col: str):\n",
        "    c = col.lower()\n",
        "    lens = next((sfx for sfx in LENS_SUFFIXES if c.endswith(sfx)), None)\n",
        "    # usage_pctile_pos_all -> \"usage\"\n",
        "    metric = c.split(\"_pctile_\")[0] if \"_pctile_\" in c else c.split(\"pctile\")[0].rstrip(\"_\")\n",
        "    return metric, lens\n",
        "\n",
        "def build_signals_long(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    pct_cols = find_percentile_cols(df)\n",
        "\n",
        "    # Robust ID detection (handles Name vs name vs player, etc.)\n",
        "    c_player = pick_col(df, [\"Name\", \"player\", \"athlete_display_name\"])\n",
        "    c_season = pick_col(df, [\"Season\", \"season\"])\n",
        "    c_team   = pick_col(df, [\"TeamAbbreviation\", \"teamabbreviation\", \"team_abbreviation\", \"team\"])\n",
        "    c_pos    = pick_col(df, [\"Position\", \"position\", \"athlete_position_abbreviation\", \"pos\"])\n",
        "    c_min    = pick_col(df, [\"Minutes\", \"minutes\", \"minutes_total\", \"min\"])\n",
        "    c_gp     = pick_col(df, [\"GamesPlayed\", \"gamesplayed\", \"gp\", \"games_played\"])\n",
        "    c_id     = pick_col(df, [\"athlete_id\", \"player_id\", \"id\"])\n",
        "\n",
        "    base = pd.DataFrame(index=df.index)\n",
        "    if c_id:     base[\"athlete_id\"]   = df[c_id]\n",
        "    if c_player: base[\"player\"]       = df[c_player]\n",
        "    if c_season: base[\"season\"]       = df[c_season]\n",
        "    if c_team:   base[\"team\"]         = df[c_team]\n",
        "    if c_pos:    base[\"position\"]     = df[c_pos]\n",
        "    if c_min:    base[\"minutes\"]      = pd.to_numeric(df[c_min], errors=\"coerce\")\n",
        "    if c_gp:     base[\"games_played\"] = pd.to_numeric(df[c_gp], errors=\"coerce\")\n",
        "\n",
        "    rows = []\n",
        "    for col in pct_cols:\n",
        "        metric, lens = parse_metric_and_lens(col)\n",
        "        hi, lo = thresholds_for_col(df[col])\n",
        "\n",
        "        tmp = base.copy()\n",
        "        tmp[\"metric\"] = metric\n",
        "        tmp[\"lens\"] = lens\n",
        "        tmp[\"percentile\"] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "        tmp[\"elite90_flag\"] = (tmp[\"percentile\"] >= hi).astype(\"Int64\")\n",
        "        tmp[\"low15_flag\"]   = (tmp[\"percentile\"] <= lo).astype(\"Int64\")\n",
        "\n",
        "        tmp[\"playbook_lens\"] = LENS_TO_PLAYBOOK.get(lens, \"General\")\n",
        "        tmp[\"stat_category\"] = METRIC_TO_CATEGORY.get(metric, \"Uncategorized\")\n",
        "\n",
        "        tmp[\"signal\"] = np.select(\n",
        "            [tmp[\"elite90_flag\"] == 1, tmp[\"low15_flag\"] == 1],\n",
        "            [\"ELITE (>=90th)\", \"CONCERN (<=15th)\"],\n",
        "            default=\"Neutral\"\n",
        "        )\n",
        "\n",
        "        rows.append(tmp)\n",
        "\n",
        "    long_df = pd.concat(rows, ignore_index=True)\n",
        "\n",
        "    # OPTIONAL: uncomment to keep only “signals” (makes Notion views cleaner)\n",
        "    # long_df = long_df[long_df[\"signal\"].isin([\"ELITE (>=90th)\", \"CONCERN (<=15th)\"])].copy()\n",
        "\n",
        "    return long_df\n",
        "\n",
        "def run(in_path: Path, out_long: Path):\n",
        "    df = pd.read_csv(in_path)\n",
        "    long_df = build_signals_long(df)\n",
        "    long_df.to_csv(out_long, index=False)\n",
        "    print(\"✅ Wrote LONG (fixed):\", out_long)\n",
        "    print(\"LONG shape:\", long_df.shape)\n",
        "    print(\"Columns:\", long_df.columns.tolist())\n",
        "\n",
        "run(IN_ALL, OUT_ALL_LONG_FIXED)\n",
        "run(IN_MIN50, OUT_MIN50_LONG_FIXED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue38a7Sb75aC",
        "outputId": "c6e5df47-7b3a-49d4-ec38-72d51b4c6a82"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote LONG (fixed): /content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL_FIXED.csv\n",
            "LONG shape: (11880, 14)\n",
            "Columns: ['player', 'season', 'team', 'position', 'minutes', 'games_played', 'metric', 'lens', 'percentile', 'elite90_flag', 'low15_flag', 'playbook_lens', 'stat_category', 'signal']\n",
            "✅ Wrote LONG (fixed): /content/processed_positions/pbpstats_player_by_season_signals_LONG_MIN50_FIXED.csv\n",
            "LONG shape: (10776, 14)\n",
            "Columns: ['player', 'season', 'team', 'position', 'minutes', 'games_played', 'metric', 'lens', 'percentile', 'elite90_flag', 'low15_flag', 'playbook_lens', 'stat_category', 'signal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "IN_PATH = Path(\"/content/processed_positions/pbpstats_totals_player_by_season_with_positions_manualpatch.csv\")\n",
        "OUT_DIR = Path(\"/content/processed_positions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_WIDE = OUT_DIR / \"pbpstats_totals_player_by_season_with_pos_percentiles_v2_ALL.csv\"\n",
        "OUT_LONG = OUT_DIR / \"pbpstats_player_by_season_signals_LONG_v2_ALL.csv\"\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers: robust column picking\n",
        "# ----------------------------\n",
        "def pick_col(df, candidates):\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols:\n",
        "            return cols[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def ensure_numeric(df, col):\n",
        "    if col is None:\n",
        "        return\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "# ----------------------------\n",
        "# Weighted percentile rank (0-1)\n",
        "# ----------------------------\n",
        "def weighted_percentile_rank(values: pd.Series, weights: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Minutes-weighted percentile rank for each row.\n",
        "    Returns float in [0, 1].\n",
        "    \"\"\"\n",
        "    v = pd.to_numeric(values, errors=\"coerce\")\n",
        "    w = pd.to_numeric(weights, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    out = pd.Series(np.nan, index=values.index, dtype=\"float64\")\n",
        "    m = v.notna() & (w > 0)\n",
        "    if m.sum() == 0:\n",
        "        return out\n",
        "\n",
        "    vv = v[m]\n",
        "    ww = w[m]\n",
        "\n",
        "    arr = vv.to_numpy()\n",
        "    order = np.argsort(arr, kind=\"mergesort\")  # stable\n",
        "    vv_s = vv.iloc[order]\n",
        "    ww_s = ww.iloc[order]\n",
        "\n",
        "    cumw = ww_s.cumsum()\n",
        "    totalw = ww_s.sum()\n",
        "\n",
        "    # percentile position at mid-weight point\n",
        "    pct = (cumw - 0.5 * ww_s) / totalw\n",
        "    pct = pct.clip(0, 1)\n",
        "\n",
        "    # map back to original index\n",
        "    out.loc[vv_s.index] = pct.to_numpy()\n",
        "    return out\n",
        "\n",
        "def add_weighted_percentiles(df, group_cols, metric_cols, weight_col, suffix):\n",
        "    for mc in metric_cols:\n",
        "        if mc not in df.columns:\n",
        "            print(f\"⚠️ Missing metric column (skipping): {mc}\")\n",
        "            continue\n",
        "        df[f\"{mc}_pctile_{suffix}\"] = (\n",
        "            df.groupby(group_cols, group_keys=False)\n",
        "              .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# ----------------------------\n",
        "# Load\n",
        "# ----------------------------\n",
        "df = pd.read_csv(IN_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Core columns (handle naming differences)\n",
        "name_col   = pick_col(df, [\"Name\", \"player\", \"Player\"])\n",
        "season_col = pick_col(df, [\"Season\", \"season\"])\n",
        "team_col   = pick_col(df, [\"TeamAbbreviation\", \"teamabbreviation\", \"Team_Abbreviation\", \"team\"])\n",
        "pos_col    = pick_col(df, [\"Position\", \"athlete_position_abbreviation\", \"position\"])\n",
        "min_col    = pick_col(df, [\"Minutes\", \"minutes\", \"minutes_total\"])\n",
        "gp_col     = pick_col(df, [\"GamesPlayed\", \"games_played\", \"GP\", \"gp\"])\n",
        "poss_col   = pick_col(df, [\"TotalPoss\", \"totalposs\", \"possessions\", \"Possessions\"])\n",
        "\n",
        "if not (name_col and season_col and pos_col and min_col):\n",
        "    raise ValueError(\n",
        "        \"Missing required columns. Need at least Name, Season, Position, Minutes.\\n\"\n",
        "        f\"Found: name={name_col}, season={season_col}, position={pos_col}, minutes={min_col}\"\n",
        "    )\n",
        "\n",
        "# Normalize key column names for downstream steps\n",
        "rename = {name_col:\"Name\", season_col:\"Season\", pos_col:\"Position\", min_col:\"Minutes\"}\n",
        "if team_col: rename[team_col] = \"TeamAbbreviation\"\n",
        "if gp_col: rename[gp_col] = \"GamesPlayed\"\n",
        "if poss_col: rename[poss_col] = \"TotalPoss\"\n",
        "\n",
        "df = df.rename(columns=rename)\n",
        "\n",
        "# numeric sanity\n",
        "ensure_numeric(df, \"Season\")\n",
        "ensure_numeric(df, \"Minutes\")\n",
        "if \"GamesPlayed\" in df.columns: ensure_numeric(df, \"GamesPlayed\")\n",
        "if \"TotalPoss\" in df.columns: ensure_numeric(df, \"TotalPoss\")\n",
        "\n",
        "# ----------------------------\n",
        "# (Optional) derive shot distribution frequencies if raw columns exist\n",
        "# ----------------------------\n",
        "# We try multiple likely PBPStats column names; if none exist, we skip gracefully.\n",
        "\n",
        "def first_existing(cands):\n",
        "    return pick_col(df, cands)\n",
        "\n",
        "# total FGA candidates\n",
        "fg2a = first_existing([\"FG2A\", \"fg2a\", \"FGA2\", \"fg2a_total\"])\n",
        "fg3a = first_existing([\"FG3A\", \"fg3a\", \"3PA\", \"fg3a_total\"])\n",
        "\n",
        "if fg2a and fg3a:\n",
        "    df[\"FGA_total\"] = pd.to_numeric(df[fg2a], errors=\"coerce\") + pd.to_numeric(df[fg3a], errors=\"coerce\")\n",
        "else:\n",
        "    df[\"FGA_total\"] = np.nan\n",
        "\n",
        "# rim attempts candidates (very site-dependent)\n",
        "rim_fga = first_existing([\"RimFGA\", \"rim_fga\", \"AtRimFGA\", \"atrim_fga\", \"Rim_FGA\"])\n",
        "corner3_fga = first_existing([\"Corner3FGA\", \"corner3_fga\", \"Corner3PA\", \"corner_3_fga\"])\n",
        "arc3_fga = first_existing([\"Arc3FGA\", \"arc3_fga\", \"NonCorner3FGA\", \"noncorner3_fga\"])\n",
        "\n",
        "# if we can, compute rim and 3 frequencies\n",
        "if rim_fga and df[\"FGA_total\"].notna().any():\n",
        "    df[\"rim_freq\"] = (pd.to_numeric(df[rim_fga], errors=\"coerce\") / df[\"FGA_total\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "if fg3a and df[\"FGA_total\"].notna().any():\n",
        "    df[\"three_freq\"] = (pd.to_numeric(df[fg3a], errors=\"coerce\") / df[\"FGA_total\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "if corner3_fga and df[\"FGA_total\"].notna().any():\n",
        "    df[\"corner3_freq\"] = (pd.to_numeric(df[corner3_fga], errors=\"coerce\") / df[\"FGA_total\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "if arc3_fga and df[\"FGA_total\"].notna().any():\n",
        "    df[\"arc3_freq\"] = (pd.to_numeric(df[arc3_fga], errors=\"coerce\") / df[\"FGA_total\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# ----------------------------\n",
        "# Ensure key “basic per-game” stats exist (for league averages)\n",
        "# ----------------------------\n",
        "# Try common totals columns; if not found, skip.\n",
        "pts = pick_col(df, [\"Points\", \"PTS\", \"pts_total\", \"pts\"])\n",
        "reb = pick_col(df, [\"Rebounds\", \"REB\", \"reb_total\", \"reb\"])\n",
        "ast = pick_col(df, [\"Assists\", \"AST\", \"ast_total\", \"ast\"])\n",
        "tov = pick_col(df, [\"Turnovers\", \"TOV\", \"tov_total\", \"tov\"])\n",
        "stl = pick_col(df, [\"Steals\", \"STL\", \"stl_total\", \"stl\"])\n",
        "blk = pick_col(df, [\"Blocks\", \"BLK\", \"blk_total\", \"blk\"])\n",
        "\n",
        "if \"GamesPlayed\" in df.columns:\n",
        "    gp = \"GamesPlayed\"\n",
        "    for col, outname in [(pts, \"ppg\"), (reb, \"rpg\"), (ast, \"apg\"), (tov, \"tovpg\"), (stl, \"spg\"), (blk, \"bpg\")]:\n",
        "        if col and outname not in df.columns:\n",
        "            df[outname] = pd.to_numeric(df[col], errors=\"coerce\") / df[gp].replace({0: np.nan})\n",
        "    if \"mpg\" not in df.columns:\n",
        "        df[\"mpg\"] = df[\"Minutes\"] / df[gp].replace({0: np.nan})\n",
        "\n",
        "# ----------------------------\n",
        "# Define metrics you requested for position percentiles\n",
        "# ----------------------------\n",
        "# These names must exist as columns in df; we include a few derived ones above (rim_freq, three_freq).\n",
        "\n",
        "requested_metrics = []\n",
        "\n",
        "def add_if_exists(colname):\n",
        "    if colname in df.columns:\n",
        "        requested_metrics.append(colname)\n",
        "\n",
        "# OREB%, DREB% (common names)\n",
        "for c in [\"oreb_pct\", \"dreb_pct\", \"reb_per_40\"]:\n",
        "    add_if_exists(c)\n",
        "\n",
        "# turnover + assist rates (common names)\n",
        "for c in [\"tov_pct\", \"ast_pct\", \"usage\", \"ts_pct\", \"efg_pct\"]:\n",
        "    add_if_exists(c)\n",
        "\n",
        "# creation-ish rates you might have\n",
        "for c in [\"ast_per_40\", \"tov_per_40\", \"ast_per_100\", \"tov_per_100\"]:\n",
        "    add_if_exists(c)\n",
        "\n",
        "# shot distribution\n",
        "for c in [\"rim_freq\", \"three_freq\", \"corner3_freq\", \"arc3_freq\"]:\n",
        "    add_if_exists(c)\n",
        "\n",
        "# If you expected columns but they aren't here, print a clue\n",
        "print(\"✅ Metrics to percentile:\", requested_metrics)\n",
        "\n",
        "# ----------------------------\n",
        "# Compute weighted percentiles by position\n",
        "# ----------------------------\n",
        "# Best practice: use Position-within-season (\"pos_season\") for most comparisons.\n",
        "# We'll also compute Position-across-all-seasons (\"pos_all\") because it’s useful as a stable baseline.\n",
        "\n",
        "df = add_weighted_percentiles(\n",
        "    df, group_cols=[\"Position\"], metric_cols=requested_metrics, weight_col=\"Minutes\", suffix=\"pos_all\"\n",
        ")\n",
        "\n",
        "df = add_weighted_percentiles(\n",
        "    df, group_cols=[\"Season\", \"Position\"], metric_cols=requested_metrics, weight_col=\"Minutes\", suffix=\"pos_season\"\n",
        ")\n",
        "\n",
        "# Optional: league-wide within season (not position-adjusted, but useful)\n",
        "df = add_weighted_percentiles(\n",
        "    df, group_cols=[\"Season\"], metric_cols=requested_metrics, weight_col=\"Minutes\", suffix=\"season\"\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# League averages by season (weighted)\n",
        "# ----------------------------\n",
        "def pick_weight_for_metric(metric):\n",
        "    m = metric.lower()\n",
        "    if \"per_40\" in m:\n",
        "        return \"Minutes\"\n",
        "    if (\"per_100\" in m or \"per100\" in m or \"per_poss\" in m) and (\"TotalPoss\" in df.columns):\n",
        "        return \"TotalPoss\"\n",
        "    # for % rates + frequencies: minutes weighting is usually fine in player-season tables\n",
        "    return \"Minutes\"\n",
        "\n",
        "league_avg_frames = []\n",
        "for m in requested_metrics + [x for x in [\"ppg\",\"rpg\",\"apg\",\"tovpg\",\"spg\",\"bpg\",\"mpg\"] if x in df.columns]:\n",
        "    wcol = pick_weight_for_metric(m)\n",
        "    if wcol not in df.columns:\n",
        "        continue\n",
        "    tmp = df[[\"Season\", m, wcol]].copy()\n",
        "    tmp[m] = pd.to_numeric(tmp[m], errors=\"coerce\")\n",
        "    tmp[wcol] = pd.to_numeric(tmp[wcol], errors=\"coerce\").fillna(0)\n",
        "    tmp = tmp.dropna(subset=[m])\n",
        "    if tmp.empty:\n",
        "        continue\n",
        "\n",
        "    # weighted mean by season\n",
        "    agg = (\n",
        "        tmp.groupby(\"Season\")\n",
        "           .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
        "           .rename(f\"league_avg_{m}\")\n",
        "           .reset_index()\n",
        "    )\n",
        "    league_avg_frames.append(agg)\n",
        "\n",
        "league_avgs = league_avg_frames[0]\n",
        "for a in league_avg_frames[1:]:\n",
        "    league_avgs = league_avgs.merge(a, on=\"Season\", how=\"outer\")\n",
        "\n",
        "df = df.merge(league_avgs, on=\"Season\", how=\"left\")\n",
        "\n",
        "# ----------------------------\n",
        "# Build Signals LONG (ALL)\n",
        "# ----------------------------\n",
        "def thresholds_for_series(s: pd.Series):\n",
        "    s = pd.to_numeric(s, errors=\"coerce\")\n",
        "    mx = s.dropna().max() if s.notna().any() else np.nan\n",
        "    # handle 0–1 vs 0–100 percentiles\n",
        "    if pd.notna(mx) and mx <= 1.00001:\n",
        "        return 0.90, 0.15\n",
        "    return 90.0, 15.0\n",
        "\n",
        "id_cols = [c for c in [\"Name\",\"Season\",\"TeamAbbreviation\",\"Position\",\"Minutes\",\"GamesPlayed\"] if c in df.columns]\n",
        "\n",
        "rows = []\n",
        "lenses = [\"pos_all\", \"pos_season\", \"season\"]\n",
        "\n",
        "# We'll include both percentiles AND league average comparisons for the metric value.\n",
        "for metric in requested_metrics + [x for x in [\"ppg\",\"rpg\",\"apg\",\"tovpg\",\"spg\",\"bpg\",\"mpg\"] if x in df.columns]:\n",
        "    league_col = f\"league_avg_{metric}\" if f\"league_avg_{metric}\" in df.columns else None\n",
        "\n",
        "    for lens in lenses:\n",
        "        pct_col = f\"{metric}_pctile_{lens}\"\n",
        "        if pct_col not in df.columns:\n",
        "            continue\n",
        "\n",
        "        hi, lo = thresholds_for_series(df[pct_col])\n",
        "\n",
        "        tmp = df[id_cols].copy()\n",
        "        tmp[\"metric\"] = metric\n",
        "        tmp[\"lens\"] = lens\n",
        "        tmp[\"value\"] = pd.to_numeric(df[metric], errors=\"coerce\")\n",
        "        tmp[\"percentile\"] = pd.to_numeric(df[pct_col], errors=\"coerce\")\n",
        "\n",
        "        tmp[\"elite90_flag\"] = (tmp[\"percentile\"] >= hi).astype(\"Int64\")\n",
        "        tmp[\"low15_flag\"]   = (tmp[\"percentile\"] <= lo).astype(\"Int64\")\n",
        "\n",
        "        if league_col:\n",
        "            tmp[\"league_avg\"] = pd.to_numeric(df[league_col], errors=\"coerce\")\n",
        "            tmp[\"delta_vs_league\"] = tmp[\"value\"] - tmp[\"league_avg\"]\n",
        "        else:\n",
        "            tmp[\"league_avg\"] = np.nan\n",
        "            tmp[\"delta_vs_league\"] = np.nan\n",
        "\n",
        "        tmp[\"signal\"] = np.select(\n",
        "            [tmp[\"elite90_flag\"] == 1, tmp[\"low15_flag\"] == 1],\n",
        "            [\"ELITE (>=90th)\", \"CONCERN (<=15th)\"],\n",
        "            default=\"Neutral\"\n",
        "        )\n",
        "        rows.append(tmp)\n",
        "\n",
        "signals_long = pd.concat(rows, ignore_index=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Save outputs\n",
        "# ----------------------------\n",
        "df.to_csv(OUT_WIDE, index=False)\n",
        "signals_long.to_csv(OUT_LONG, index=False)\n",
        "\n",
        "print(\"✅ Wrote WIDE:\", OUT_WIDE)\n",
        "print(\"✅ Wrote LONG:\", OUT_LONG)\n",
        "print(\"WIDE shape:\", df.shape, \"| LONG shape:\", signals_long.shape)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "IN_ALL   = Path(\"/content/processed_positions/pbpstats_player_by_season_flags_WIDE_ALL.csv\")\n",
        "IN_MIN50 = Path(\"/content/processed_positions/pbpstats_player_by_season_flags_WIDE_MIN50.csv\")\n",
        "\n",
        "OUT_ALL_LONG   = Path(\"/content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL.csv\")\n",
        "OUT_MIN50_LONG = Path(\"/content/processed_positions/pbpstats_player_by_season_signals_LONG_MIN50.csv\")\n",
        "\n",
        "LENS_SUFFIXES = [\"pos_all\", \"season\", \"pos_season\"]\n",
        "\n",
        "LENS_TO_PLAYBOOK = {\n",
        "    \"season\": \"Contract/Valuation\",\n",
        "    \"pos_season\": \"Scouting\",\n",
        "    \"pos_all\": \"Lineup Optimization\",\n",
        "}\n",
        "\n",
        "# Optional: extend these as you expand your metric set\n",
        "METRIC_TO_CATEGORY = {\n",
        "    \"usage\": \"Scoring / Role\",\n",
        "    \"ts\": \"Scoring / Efficiency\",\n",
        "    \"efg\": \"Scoring / Efficiency\",\n",
        "    \"ast\": \"Assists / Creation\",\n",
        "    \"tov\": \"Turnovers\",\n",
        "    \"stl\": \"Defense / Activity\",\n",
        "    \"blk\": \"Defense / Activity\",\n",
        "    \"reb\": \"Rebounds\",\n",
        "    \"oreb\": \"Second Chance\",\n",
        "    \"dreb\": \"Rebounds\",\n",
        "    \"rim_freq\": \"Shot Distribution\",\n",
        "    \"three_freq\": \"Shot Distribution\",\n",
        "}\n",
        "\n",
        "def pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols_lower:\n",
        "            return cols_lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def find_percentile_cols(df: pd.DataFrame) -> list[str]:\n",
        "    out = []\n",
        "    for c in df.columns:\n",
        "        cl = c.lower()\n",
        "        if \"pctile\" in cl and any(cl.endswith(sfx) for sfx in LENS_SUFFIXES):\n",
        "            out.append(c)\n",
        "    return out\n",
        "\n",
        "def thresholds_for_col(series: pd.Series):\n",
        "    \"\"\"Handles both 0–1 and 0–100 percentile scales.\"\"\"\n",
        "    s = pd.to_numeric(series, errors=\"coerce\")\n",
        "    mx = s.dropna().max() if s.notna().any() else np.nan\n",
        "    if pd.notna(mx) and mx <= 1.00001:\n",
        "        return 0.90, 0.15\n",
        "    return 90.0, 15.0\n",
        "\n",
        "def parse_metric_and_lens(col: str):\n",
        "    c = col.lower()\n",
        "    lens = next((sfx for sfx in LENS_SUFFIXES if c.endswith(sfx)), None)\n",
        "    metric = c.split(\"_pctile_\")[0] if \"_pctile_\" in c else c.split(\"pctile\")[0].rstrip(\"_\")\n",
        "    return metric, lens\n",
        "\n",
        "def _lc_map(df: pd.DataFrame) -> dict[str, str]:\n",
        "    \"\"\"lowercase -> original column name\"\"\"\n",
        "    return {c.lower(): c for c in df.columns}\n",
        "\n",
        "def resolve_metric_value_col(df: pd.DataFrame, metric: str) -> str | None:\n",
        "    \"\"\"\n",
        "    Try to find the \"value\" column corresponding to a metric name.\n",
        "    Example: metric='ast' -> prefer ast_per_40, then ast_per_100, then ast_pg, then ast.\n",
        "    \"\"\"\n",
        "    lower_map = _lc_map(df)\n",
        "\n",
        "    # High-confidence candidate patterns\n",
        "    candidates = [\n",
        "        f\"{metric}_per_40\",\n",
        "        f\"{metric}_per40\",\n",
        "        f\"{metric}_per_100\",\n",
        "        f\"{metric}_per100\",\n",
        "        f\"{metric}_per_game\",\n",
        "        f\"{metric}_pg\",\n",
        "        metric,\n",
        "    ]\n",
        "\n",
        "    # Some common aliases / special cases (extend freely)\n",
        "    alias_candidates = {\n",
        "        \"ts\": [\"ts_pct\", \"true_shooting\", \"true_shooting_pct\", \"ts\"],\n",
        "        \"efg\": [\"efg_pct\", \"effective_fg_pct\", \"efg\"],\n",
        "        \"usage\": [\"usage\", \"usg\", \"usg_pct\", \"usage_rate\"],\n",
        "        \"tov\": [\"tov_per_40\", \"tov_per_100\", \"tov_pg\", \"tov\", \"turnovers\"],\n",
        "        \"ast\": [\"ast_per_40\", \"ast_per_100\", \"ast_pg\", \"ast\", \"assists\"],\n",
        "        \"reb\": [\"reb_per_40\", \"reb_per_100\", \"reb_pg\", \"reb\", \"rebounds\"],\n",
        "        \"oreb\": [\"oreb_per_40\", \"oreb_pg\", \"oreb\", \"off_reb\", \"offreb\"],\n",
        "        \"dreb\": [\"dreb_per_40\", \"dreb_pg\", \"dreb\", \"def_reb\", \"defreb\"],\n",
        "    }\n",
        "\n",
        "    search_list = alias_candidates.get(metric, []) + candidates\n",
        "\n",
        "    for cand in search_list:\n",
        "        if cand.lower() in lower_map:\n",
        "            return lower_map[cand.lower()]\n",
        "\n",
        "    # Fallback: try \"contains\" match (careful but helpful)\n",
        "    metric_l = metric.lower()\n",
        "    contains = [c for c in df.columns if metric_l in c.lower() and \"pctile\" not in c.lower()]\n",
        "    if len(contains) == 1:\n",
        "        return contains[0]\n",
        "\n",
        "    return None\n",
        "\n",
        "def build_signals_long(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    pct_cols = find_percentile_cols(df)\n",
        "\n",
        "    # Robust ID detection\n",
        "    c_player = pick_col(df, [\"Name\", \"player\", \"athlete_display_name\"])\n",
        "    c_season = pick_col(df, [\"Season\", \"season\"])\n",
        "    c_team   = pick_col(df, [\"TeamAbbreviation\", \"teamabbreviation\", \"team_abbreviation\", \"team\"])\n",
        "    c_pos    = pick_col(df, [\"Position\", \"position\", \"athlete_position_abbreviation\", \"pos\"])\n",
        "    c_min    = pick_col(df, [\"Minutes\", \"minutes\", \"minutes_total\", \"min\"])\n",
        "    c_gp     = pick_col(df, [\"GamesPlayed\", \"gamesplayed\", \"gp\", \"games_played\"])\n",
        "    c_id     = pick_col(df, [\"athlete_id\", \"player_id\", \"id\"])\n",
        "\n",
        "    base = pd.DataFrame(index=df.index)\n",
        "    if c_id:     base[\"athlete_id\"]   = df[c_id]\n",
        "    if c_player: base[\"player\"]       = df[c_player]\n",
        "    if c_season: base[\"season\"]       = df[c_season]\n",
        "    if c_team:   base[\"team\"]         = df[c_team]\n",
        "    if c_pos:    base[\"position\"]     = df[c_pos]\n",
        "    if c_min:    base[\"minutes\"]      = pd.to_numeric(df[c_min], errors=\"coerce\")\n",
        "    if c_gp:     base[\"games_played\"] = pd.to_numeric(df[c_gp], errors=\"coerce\")\n",
        "\n",
        "    # Cache metric -> value column resolution\n",
        "    metric_value_col_cache: dict[str, str | None] = {}\n",
        "\n",
        "    rows = []\n",
        "    for col in pct_cols:\n",
        "        metric, lens = parse_metric_and_lens(col)\n",
        "        hi, lo = thresholds_for_col(df[col])\n",
        "\n",
        "        # resolve metric value column once per metric\n",
        "        if metric not in metric_value_col_cache:\n",
        "            metric_value_col_cache[metric] = resolve_metric_value_col(df, metric)\n",
        "\n",
        "        value_col = metric_value_col_cache[metric]\n",
        "\n",
        "        tmp = base.copy()\n",
        "        tmp[\"metric\"] = metric\n",
        "        tmp[\"lens\"] = lens\n",
        "        tmp[\"percentile\"] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "        # NEW: metric value alongside percentile\n",
        "        tmp[\"metric_value\"] = (\n",
        "            pd.to_numeric(df[value_col], errors=\"coerce\") if value_col else np.nan\n",
        "        )\n",
        "        tmp[\"metric_value_col\"] = value_col  # helpful for debugging / trust\n",
        "\n",
        "        tmp[\"elite90_flag\"] = (tmp[\"percentile\"] >= hi).astype(\"Int64\")\n",
        "        tmp[\"low15_flag\"]   = (tmp[\"percentile\"] <= lo).astype(\"Int64\")\n",
        "\n",
        "        tmp[\"playbook_lens\"] = LENS_TO_PLAYBOOK.get(lens, \"General\")\n",
        "        tmp[\"stat_category\"] = METRIC_TO_CATEGORY.get(metric, \"Uncategorized\")\n",
        "\n",
        "        tmp[\"signal\"] = np.select(\n",
        "            [tmp[\"elite90_flag\"] == 1, tmp[\"low15_flag\"] == 1],\n",
        "            [\"ELITE (>=90th)\", \"CONCERN (<=15th)\"],\n",
        "            default=\"Neutral\"\n",
        "        )\n",
        "\n",
        "        rows.append(tmp)\n",
        "\n",
        "    long_df = pd.concat(rows, ignore_index=True)\n",
        "\n",
        "    # OPTIONAL: keep only signals (reduces noise)\n",
        "    # long_df = long_df[long_df[\"signal\"].isin([\"ELITE (>=90th)\", \"CONCERN (<=15th)\"])].copy()\n",
        "\n",
        "    return long_df\n",
        "\n",
        "def run(in_path: Path, out_path: Path):\n",
        "    df = pd.read_csv(in_path)\n",
        "    long_df = build_signals_long(df)\n",
        "    long_df.to_csv(out_path, index=False)\n",
        "    print(\"✅ Wrote LONG with metric_value:\", out_path)\n",
        "    print(\"LONG shape:\", long_df.shape)\n",
        "\n",
        "    # Quick sanity check: how many metrics failed to map a value col?\n",
        "    unmapped = long_df[\"metric_value_col\"].isna().mean()\n",
        "    print(f\"ℹ️ metric_value_value_col missing rate: {unmapped:.1%}\")\n",
        "\n",
        "run(IN_ALL, OUT_ALL_LONG)\n",
        "run(IN_MIN50, OUT_MIN50_LONG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTh721zQ9zxH",
        "outputId": "71545d0b-8c32-4645-a157-66f5a2bece60"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Metrics to percentile: ['rim_freq', 'three_freq', 'corner3_freq', 'arc3_freq']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: weighted_percentile_rank(g[mc], g[weight_col]))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n",
            "/tmp/ipython-input-1972564539.py:241: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: np.average(g[m], weights=np.clip(g[wcol].to_numpy(), 0, None)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote WIDE: /content/processed_positions/pbpstats_totals_player_by_season_with_pos_percentiles_v2_ALL.csv\n",
            "✅ Wrote LONG: /content/processed_positions/pbpstats_player_by_season_signals_LONG_v2_ALL.csv\n",
            "WIDE shape: (495, 287) | LONG shape: (5940, 15)\n",
            "✅ Wrote LONG with metric_value: /content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL.csv\n",
            "LONG shape: (11880, 16)\n",
            "ℹ️ metric_value_value_col missing rate: 0.0%\n",
            "✅ Wrote LONG with metric_value: /content/processed_positions/pbpstats_player_by_season_signals_LONG_MIN50.csv\n",
            "LONG shape: (10776, 16)\n",
            "ℹ️ metric_value_value_col missing rate: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "BASE = Path(\"/content/processed_positions\")\n",
        "\n",
        "# ✅ Point this at the WIDE dataset that already contains percentiles (pos/season)\n",
        "IN_WIDE = BASE / \"/content/processed_positions/pbpstats_totals_player_by_season_with_pos_percentiles_v2_ALL.csv\"\n",
        "\n",
        "# ✅ Output\n",
        "OUT_LONG = BASE / \"pbpstats_player_by_season_signals_LONG_ALL_with_metric_value.csv\"\n",
        "\n",
        "df = pd.read_csv(IN_WIDE)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "def first_existing(cols, candidates):\n",
        "    lower = {c.lower(): c for c in cols}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in lower:\n",
        "            return lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "# --- core id columns (keep player name from getting dropped) ---\n",
        "player_col  = first_existing(df.columns, [\"player\", \"name\"])\n",
        "season_col  = first_existing(df.columns, [\"season\"])\n",
        "team_col    = first_existing(df.columns, [\"teamabbreviation\", \"team\"])\n",
        "pos_col     = first_existing(df.columns, [\"position\"])\n",
        "min_col     = first_existing(df.columns, [\"minutes_total\", \"minutes\"])\n",
        "\n",
        "id_vars = [c for c in [player_col, season_col, team_col, pos_col] if c is not None]\n",
        "missing_ids = [x for x in [\"player/name\", \"season\"] if (x == \"season\" and season_col is None) or (x == \"player/name\" and player_col is None)]\n",
        "if missing_ids:\n",
        "    raise ValueError(f\"Missing required id columns: {missing_ids}. Found columns sample: {df.columns[:40].tolist()}\")\n",
        "\n",
        "# --- detect percentile columns ---\n",
        "pctile_cols = [c for c in df.columns if re.search(r\"(pctile|percentile)\", c, flags=re.I)]\n",
        "if not pctile_cols:\n",
        "    raise ValueError(\"No percentile columns found. Expected columns containing 'pctile' or 'percentile'.\")\n",
        "\n",
        "# --- parse pctile column -> (metric_stub, lens) ---\n",
        "def parse_pctile_col(col: str):\n",
        "    c = col.lower()\n",
        "    lens = \"unknown\"\n",
        "    stub = col\n",
        "    for suffix, l in [\n",
        "        (\"_pctile_pos\", \"pos\"),\n",
        "        (\"_pctile_position\", \"pos\"),\n",
        "        (\"_pctile_season\", \"season\"),\n",
        "        (\"_percentile_pos\", \"pos\"),\n",
        "        (\"_percentile_season\", \"season\"),\n",
        "    ]:\n",
        "        if c.endswith(suffix):\n",
        "            lens = l\n",
        "            stub = col[: -len(suffix)]\n",
        "            return stub, lens\n",
        "    # fallback: strip first occurrence of _pctile/_percentile and anything after\n",
        "    stub = re.split(r\"_(pctile|percentile)\", col, flags=re.I)[0]\n",
        "    return stub, lens\n",
        "\n",
        "# --- map metric_stub -> metric_value_col (so LONG has the actual stat value next to the percentile) ---\n",
        "SPECIAL = {\n",
        "    \"ast\": \"ast_per_40\",\n",
        "    \"tov\": \"tov_per_40\",\n",
        "    \"reb\": \"reb_per_40\",\n",
        "    \"oreb\": \"oreb_per_40\",\n",
        "    \"dreb\": \"dreb_per_40\",\n",
        "    \"stl\": \"stl_per_40\",\n",
        "    \"blk\": \"blk_per_40\",\n",
        "    \"pts\": \"pts_per_40\",\n",
        "}\n",
        "\n",
        "def resolve_value_col(metric_stub: str):\n",
        "    # 1) exact match\n",
        "    if metric_stub in df.columns:\n",
        "        return metric_stub\n",
        "    # 2) special mapping (if present)\n",
        "    if metric_stub in SPECIAL and SPECIAL[metric_stub] in df.columns:\n",
        "        return SPECIAL[metric_stub]\n",
        "    # 3) try common suffixes\n",
        "    suffixes = [\"_per_40\", \"_per40\", \"_per_100\", \"_per100\", \"_rate\", \"_pct\", \"_pctg\"]\n",
        "    for suf in suffixes:\n",
        "        cand = f\"{metric_stub}{suf}\"\n",
        "        if cand in df.columns:\n",
        "            return cand\n",
        "    # 4) give up (we can still output percentile rows without metric_value)\n",
        "    return None\n",
        "\n",
        "map_rows = []\n",
        "for pc in pctile_cols:\n",
        "    stub, lens = parse_pctile_col(pc)\n",
        "    value_col = resolve_value_col(stub)\n",
        "    map_rows.append({\n",
        "        \"pctile_col\": pc,\n",
        "        \"metric_stub\": stub,\n",
        "        \"lens\": lens,\n",
        "        \"metric_value_col\": value_col\n",
        "    })\n",
        "\n",
        "map_df = pd.DataFrame(map_rows)\n",
        "\n",
        "# --- 1) melt percentiles ---\n",
        "pct_long = df[id_vars + pctile_cols].melt(\n",
        "    id_vars=id_vars,\n",
        "    var_name=\"pctile_col\",\n",
        "    value_name=\"metric_pctile\"\n",
        ")\n",
        "\n",
        "pct_long = pct_long.merge(map_df, on=\"pctile_col\", how=\"left\")\n",
        "\n",
        "# --- 2) melt metric values (only for resolvable metrics) ---\n",
        "value_cols = sorted({c for c in map_df[\"metric_value_col\"].dropna().unique().tolist() if c in df.columns})\n",
        "if value_cols:\n",
        "    val_long = df[id_vars + value_cols].melt(\n",
        "        id_vars=id_vars,\n",
        "        var_name=\"metric_value_col\",\n",
        "        value_name=\"metric_value\"\n",
        "    )\n",
        "    long = pct_long.merge(val_long, on=id_vars + [\"metric_value_col\"], how=\"left\")\n",
        "else:\n",
        "    long = pct_long.copy()\n",
        "    long[\"metric_value\"] = np.nan\n",
        "\n",
        "# --- 3) league averages (by season) for metric_value ---\n",
        "if value_cols:\n",
        "    league_avg = (\n",
        "        df.groupby(season_col)[value_cols]\n",
        "          .mean(numeric_only=True)\n",
        "          .reset_index()\n",
        "          .melt(id_vars=[season_col], var_name=\"metric_value_col\", value_name=\"league_avg_value\")\n",
        "    )\n",
        "    long = long.merge(league_avg, on=[season_col, \"metric_value_col\"], how=\"left\")\n",
        "else:\n",
        "    long[\"league_avg_value\"] = np.nan\n",
        "\n",
        "# --- 4) flags ---\n",
        "long[\"flag_elite_90\"] = long[\"metric_pctile\"].astype(float) >= 0.90\n",
        "long[\"flag_low_15\"]   = long[\"metric_pctile\"].astype(float) <= 0.15\n",
        "\n",
        "# --- 5) tidy / ordering ---\n",
        "# Keep a nice human-readable metric name too\n",
        "long[\"metric\"] = long[\"metric_stub\"]\n",
        "\n",
        "# Optional: put lens + metric up front\n",
        "front = id_vars + [\"lens\", \"metric\", \"metric_value\", \"league_avg_value\", \"metric_pctile\", \"flag_elite_90\", \"flag_low_15\"]\n",
        "rest = [c for c in long.columns if c not in front]\n",
        "long = long[front + rest]\n",
        "\n",
        "long.to_csv(OUT_LONG, index=False)\n",
        "print(\"✅ Wrote:\", OUT_LONG)\n",
        "print(\"✅ Rows:\", len(long))\n",
        "print(\"✅ Example columns:\", long.columns[:18].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEVpJcNPBHES",
        "outputId": "2b4850ee-5a01-446d-8799-6690edef9cf6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote: /content/processed_positions/pbpstats_player_by_season_signals_LONG_ALL_with_metric_value.csv\n",
            "✅ Rows: 5940\n",
            "✅ Example columns: ['Name', 'Season', 'TeamAbbreviation', 'Position', 'lens', 'metric', 'metric_value', 'league_avg_value', 'metric_pctile', 'flag_elite_90', 'flag_low_15', 'pctile_col', 'metric_stub', 'metric_value_col']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# EXPORT PACK: 4 Canonical Outputs\n",
        "#   1) WIDE_ALL\n",
        "#   2) WIDE_MIN50\n",
        "#   3) LONG_ALL\n",
        "#   4) LONG_MIN50\n",
        "# ============================================\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "BASE_DIR = Path(\"/content/processed_positions\")\n",
        "IN_WIDE_ALL = BASE_DIR / \"pbpstats_totals_player_by_season_with_pos_percentiles_v2_ALL.csv\"\n",
        "\n",
        "OUT_DIR = BASE_DIR / \"canonical\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_WIDE_ALL  = OUT_DIR / \"WIDE_ALL.csv\"\n",
        "OUT_WIDE_MIN50 = OUT_DIR / \"WIDE_MIN50.csv\"\n",
        "OUT_LONG_ALL  = OUT_DIR / \"LONG_ALL.csv\"\n",
        "OUT_LONG_MIN50 = OUT_DIR / \"LONG_MIN50.csv\"\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "def first_existing(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in lower:\n",
        "            return lower[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def build_long(df_wide: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    LONG format:\n",
        "      id cols + metric + lens + percentile + metric_value (+ league_avg_value/delta if present)\n",
        "    Percentile columns are detected via '*pctile*' naming.\n",
        "    metric_value is pulled from the base metric column (same name as metric).\n",
        "    League average is pulled if a 'league_avg_<metric>' column exists.\n",
        "    \"\"\"\n",
        "    # --- identify ID columns (keep whatever exists)\n",
        "    id_candidates = [\n",
        "        \"athlete_id\", \"player_id\",\n",
        "        \"name\", \"player\",\n",
        "        \"season\",\n",
        "        \"teamabbreviation\", \"team_abbreviation\", \"team\",\n",
        "        \"position\", \"athlete_position_abbreviation\"\n",
        "    ]\n",
        "    id_cols = [c for c in id_candidates if c in df_wide.columns]\n",
        "    if \"name\" not in id_cols and \"Name\" in df_wide.columns:\n",
        "        id_cols.append(\"Name\")\n",
        "    if \"season\" not in id_cols and \"Season\" in df_wide.columns:\n",
        "        id_cols.append(\"Season\")\n",
        "\n",
        "    # Guardrail\n",
        "    if not id_cols:\n",
        "        raise ValueError(\"Couldn't detect ID columns. Add at least ['name','season'] to id_candidates.\")\n",
        "\n",
        "    # --- percentile columns\n",
        "    pctile_cols = [c for c in df_wide.columns if \"pctile\" in c.lower()]\n",
        "    if not pctile_cols:\n",
        "        raise ValueError(\"No percentile columns found (expected columns containing 'pctile').\")\n",
        "\n",
        "    # Melt percentiles\n",
        "    long_p = df_wide[id_cols + pctile_cols].melt(\n",
        "        id_vars=id_cols,\n",
        "        var_name=\"pctile_col\",\n",
        "        value_name=\"percentile\"\n",
        "    )\n",
        "\n",
        "    # lens + metric name parsing\n",
        "    def parse_lens_and_metric(col: str) -> tuple[str, str]:\n",
        "        s = col.lower()\n",
        "        lens = \"all\"\n",
        "        if s.endswith(\"_pctile_pos\") or s.endswith(\"pctile_pos\"):\n",
        "            lens = \"pos\"\n",
        "            metric = re.sub(r\"_?pctile_pos$\", \"\", s)\n",
        "        elif s.endswith(\"_pctile_season\") or s.endswith(\"pctile_season\"):\n",
        "            lens = \"season\"\n",
        "            metric = re.sub(r\"_?pctile_season$\", \"\", s)\n",
        "        else:\n",
        "            metric = re.sub(r\"_?pctile$\", \"\", s)\n",
        "        return lens, metric\n",
        "\n",
        "    parsed = long_p[\"pctile_col\"].apply(parse_lens_and_metric)\n",
        "    long_p[\"lens\"] = parsed.apply(lambda x: x[0])\n",
        "    long_p[\"metric\"] = parsed.apply(lambda x: x[1])\n",
        "\n",
        "    # --- metric_value: melt base metric columns that exist\n",
        "    base_metrics = sorted(set(long_p[\"metric\"].unique()))\n",
        "    value_cols = [m for m in base_metrics if m in df_wide.columns]\n",
        "\n",
        "    if value_cols:\n",
        "        long_v = df_wide[id_cols + value_cols].melt(\n",
        "            id_vars=id_cols,\n",
        "            var_name=\"metric\",\n",
        "            value_name=\"metric_value\"\n",
        "        )\n",
        "        long_p = long_p.merge(long_v, on=id_cols + [\"metric\"], how=\"left\")\n",
        "    else:\n",
        "        long_p[\"metric_value\"] = np.nan\n",
        "\n",
        "    # --- league averages (optional): expect columns like league_avg_<metric>\n",
        "    league_cols = [c for c in df_wide.columns if c.lower().startswith(\"league_avg_\")]\n",
        "    if league_cols:\n",
        "        # Normalize to long with metric extracted after prefix\n",
        "        tmp = df_wide[id_cols + league_cols].copy()\n",
        "        ren = {c: c.lower() for c in league_cols}\n",
        "        tmp = tmp.rename(columns=ren)\n",
        "        league_cols_lower = [c.lower() for c in league_cols]\n",
        "\n",
        "        long_la = tmp[id_cols + league_cols_lower].melt(\n",
        "            id_vars=id_cols,\n",
        "            var_name=\"league_avg_col\",\n",
        "            value_name=\"league_avg_value\"\n",
        "        )\n",
        "        long_la[\"metric\"] = long_la[\"league_avg_col\"].str.replace(\"league_avg_\", \"\", regex=False)\n",
        "\n",
        "        long_p = long_p.merge(long_la[id_cols + [\"metric\", \"league_avg_value\"]],\n",
        "                              on=id_cols + [\"metric\"], how=\"left\")\n",
        "        long_p[\"delta_vs_league\"] = long_p[\"metric_value\"] - long_p[\"league_avg_value\"]\n",
        "    else:\n",
        "        long_p[\"league_avg_value\"] = np.nan\n",
        "        long_p[\"delta_vs_league\"] = np.nan\n",
        "\n",
        "    # Clean up\n",
        "    long_p = long_p.drop(columns=[\"pctile_col\"])\n",
        "    # Helpful ordering\n",
        "    front = id_cols + [\"metric\", \"lens\", \"metric_value\", \"percentile\", \"league_avg_value\", \"delta_vs_league\"]\n",
        "    rest = [c for c in long_p.columns if c not in front]\n",
        "    long_p = long_p[front + rest]\n",
        "\n",
        "    return long_p\n",
        "\n",
        "# ----------------------------\n",
        "# Load canonical WIDE_ALL\n",
        "# ----------------------------\n",
        "if not IN_WIDE_ALL.exists():\n",
        "    raise FileNotFoundError(f\"Missing input: {IN_WIDE_ALL}\")\n",
        "\n",
        "wide_all = pd.read_csv(IN_WIDE_ALL)\n",
        "wide_all.columns = [c.strip() for c in wide_all.columns]\n",
        "\n",
        "# ----------------------------\n",
        "# Build WIDE_MIN50\n",
        "# ----------------------------\n",
        "min_col = first_existing(wide_all, [\"minutes_total\", \"minutes\", \"Minutes\", \"min\", \"mp\"])\n",
        "if not min_col:\n",
        "    raise ValueError(\n",
        "        \"Couldn't find a minutes column for MIN50 filter. \"\n",
        "        \"Add your minutes column name to the candidates list.\"\n",
        "    )\n",
        "\n",
        "wide_min50 = wide_all.copy()\n",
        "wide_min50[min_col] = pd.to_numeric(wide_min50[min_col], errors=\"coerce\")\n",
        "wide_min50 = wide_min50[wide_min50[min_col] >= 50].reset_index(drop=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Build LONG datasets\n",
        "# ----------------------------\n",
        "# (These will include metric_value, and league avg/delta if those columns exist in WIDE)\n",
        "long_all = build_long(wide_all)\n",
        "long_min50 = build_long(wide_min50)\n",
        "\n",
        "# ----------------------------\n",
        "# Export exactly 4 files\n",
        "# ----------------------------\n",
        "wide_all.to_csv(OUT_WIDE_ALL, index=False)\n",
        "wide_min50.to_csv(OUT_WIDE_MIN50, index=False)\n",
        "long_all.to_csv(OUT_LONG_ALL, index=False)\n",
        "long_min50.to_csv(OUT_LONG_MIN50, index=False)\n",
        "\n",
        "print(\"✅ Export pack complete:\")\n",
        "print(\" -\", OUT_WIDE_ALL)\n",
        "print(\" -\", OUT_WIDE_MIN50)\n",
        "print(\" -\", OUT_LONG_ALL)\n",
        "print(\" -\", OUT_LONG_MIN50)\n",
        "\n",
        "print(\"\\nQuick sanity:\")\n",
        "print(\"WIDE_ALL rows:\", len(wide_all), \"| WIDE_MIN50 rows:\", len(wide_min50))\n",
        "print(\"LONG_ALL rows:\", len(long_all), \"| LONG_MIN50 rows:\", len(long_min50))\n",
        "print(\"Minutes col used for MIN50:\", min_col)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOpqmhtuK2uE",
        "outputId": "35ffa8cd-f66e-46bb-de96-87b0cf1afbbe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Export pack complete:\n",
            " - /content/processed_positions/canonical/WIDE_ALL.csv\n",
            " - /content/processed_positions/canonical/WIDE_MIN50.csv\n",
            " - /content/processed_positions/canonical/LONG_ALL.csv\n",
            " - /content/processed_positions/canonical/LONG_MIN50.csv\n",
            "\n",
            "Quick sanity:\n",
            "WIDE_ALL rows: 495 | WIDE_MIN50 rows: 449\n",
            "LONG_ALL rows: 5940 | LONG_MIN50 rows: 5388\n",
            "Minutes col used for MIN50: Minutes\n"
          ]
        }
      ]
    }
  ]
}